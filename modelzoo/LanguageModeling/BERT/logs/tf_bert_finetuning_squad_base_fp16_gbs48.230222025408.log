/workspaces/Deepray2/examples/LanguageModeling/BERT/run_squad.py:507: UserWarning: Flag --model_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  flags.mark_flag_as_required('model_dir')
I0222 02:54:15.103936 140521934866240 distribution_utils.py:134] Run horovod and turn off distribution strategy.
/workspaces/Deepray2/examples/LanguageModeling/BERT/run_squad.py:507: UserWarning: Flag --model_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  flags.mark_flag_as_required('model_dir')
I0222 02:54:15.118741 139694807635776 distribution_utils.py:134] Run horovod and turn off distribution strategy.
2023-02-22 02:54:15.119478: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspaces/Deepray2/examples/LanguageModeling/BERT/run_squad.py:507: UserWarning: Flag --model_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  flags.mark_flag_as_required('model_dir')
I0222 02:54:15.122258 139842431985472 distribution_utils.py:134] Run horovod and turn off distribution strategy.
/workspaces/Deepray2/examples/LanguageModeling/BERT/run_squad.py:507: UserWarning: Flag --model_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  flags.mark_flag_as_required('model_dir')
I0222 02:54:15.129160 140514811483968 distribution_utils.py:134] Run horovod and turn off distribution strategy.
2023-02-22 02:54:15.135629: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-22 02:54:15.138168: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-22 02:54:15.145607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-22 02:54:16.407176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10515 MB memory:  -> device: 1, name: NVIDIA TITAN V, pci bus id: 0000:3b:00.0, compute capability: 7.0
2023-02-22 02:54:16.527230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10515 MB memory:  -> device: 3, name: NVIDIA TITAN V, pci bus id: 0000:af:00.0, compute capability: 7.0
2023-02-22 02:54:16.541279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10515 MB memory:  -> device: 2, name: NVIDIA TITAN V, pci bus id: 0000:86:00.0, compute capability: 7.0
2023-02-22 02:54:16.578696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10515 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:18:00.0, compute capability: 7.0
I0222 02:54:21.458682 140514811483968 feature_map.py:34] File not exists: /workspaces/Deepray2/business/data/feature_map.csv
I0222 02:54:21.458915 140514811483968 distribution_utils.py:134] Run horovod and turn off distribution strategy.
decayed_learning_rate_at_crossover_point = 1.800650e-05, adjusted_init_lr = 2.221420e-05
I0222 02:54:21.467188 140514811483968 base_trainer.py:228] Checkpoint file /workspaces/bert_tf2/data/download/google_pretrained_weights/uncased_L-12_H-768_A-12/bert_model.ckpt found and restoring from initial checkpoint for core model.
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad011faf0> and <deepray.layers.self_attention_mask.SelfAttentionMask object at 0x7fcad00d8850>).
W0222 02:54:21.535566 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad011faf0> and <deepray.layers.self_attention_mask.SelfAttentionMask object at 0x7fcad00d8850>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad011f220> and <deepray.layers.transformer.Transformer object at 0x7fcad011faf0>).
W0222 02:54:21.543438 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad011f220> and <deepray.layers.transformer.Transformer object at 0x7fcad011faf0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad0058250> and <deepray.layers.transformer.Transformer object at 0x7fcad011f220>).
W0222 02:54:21.551240 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad0058250> and <deepray.layers.transformer.Transformer object at 0x7fcad011f220>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad00c9760> and <deepray.layers.transformer.Transformer object at 0x7fcad0058250>).
W0222 02:54:21.559036 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad00c9760> and <deepray.layers.transformer.Transformer object at 0x7fcad0058250>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca800884c0> and <deepray.layers.transformer.Transformer object at 0x7fcad00c9760>).
W0222 02:54:21.566826 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca800884c0> and <deepray.layers.transformer.Transformer object at 0x7fcad00c9760>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca80104760> and <deepray.layers.transformer.Transformer object at 0x7fca800884c0>).
W0222 02:54:21.574605 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca80104760> and <deepray.layers.transformer.Transformer object at 0x7fca800884c0>).
I0222 02:54:21.576441 139842431985472 feature_map.py:34] File not exists: /workspaces/Deepray2/business/data/feature_map.csv
I0222 02:54:21.576677 139842431985472 distribution_utils.py:134] Run horovod and turn off distribution strategy.
I0222 02:54:21.576820 139842431985472 base_trainer.py:134]  20230222 02:54:21 Initialize training
I0222 02:54:21.576902 139842431985472 base_trainer.py:136] 	tf.app.flags.FLAGS:
I0222 02:54:21.577182 139842431985472 base_trainer.py:138] 	?                        = False
I0222 02:54:21.577262 139842431985472 base_trainer.py:138] 	alsologtostderr          = False
I0222 02:54:21.577338 139842431985472 base_trainer.py:138] 	batch_size               = 12
I0222 02:54:21.577412 139842431985472 base_trainer.py:138] 	bds                      = test_benchmark
I0222 02:54:21.577486 139842431985472 base_trainer.py:138] 	benchmark                = False
I0222 02:54:21.577560 139842431985472 base_trainer.py:138] 	benchmark_log_dir        = None
I0222 02:54:21.577634 139842431985472 base_trainer.py:138] 	benchmark_logger_type    = BaseBenchmarkLogger
I0222 02:54:21.577707 139842431985472 base_trainer.py:138] 	benchmark_test_id        = None
I0222 02:54:21.577780 139842431985472 base_trainer.py:138] 	bert_config_file         = /workspaces/bert_tf2/data/download/google_pretrained_weights/uncased_L-12_H-768_A-12/bert_config.json
I0222 02:54:21.577854 139842431985472 base_trainer.py:138] 	bigquery_data_set        = test_benchmark
I0222 02:54:21.577927 139842431985472 base_trainer.py:138] 	bigquery_metric_table    = benchmark_metric
I0222 02:54:21.578000 139842431985472 base_trainer.py:138] 	bigquery_run_status_table= benchmark_run_status
I0222 02:54:21.578073 139842431985472 base_trainer.py:138] 	bigquery_run_table       = benchmark_run
I0222 02:54:21.578147 139842431985472 base_trainer.py:138] 	black_list               = None
I0222 02:54:21.578220 139842431985472 base_trainer.py:138] 	bld                      = None
I0222 02:54:21.578293 139842431985472 base_trainer.py:138] 	bmt                      = benchmark_metric
I0222 02:54:21.578366 139842431985472 base_trainer.py:138] 	brst                     = benchmark_run_status
I0222 02:54:21.578439 139842431985472 base_trainer.py:138] 	brt                      = benchmark_run
I0222 02:54:21.578512 139842431985472 base_trainer.py:138] 	bs                       = 12
I0222 02:54:21.578587 139842431985472 base_trainer.py:138] 	bti                      = None
I0222 02:54:21.578660 139842431985472 base_trainer.py:138] 	clean                    = False
I0222 02:54:21.578734 139842431985472 base_trainer.py:138] 	conf_file                = /workspaces/Deepray2/conf/dp.yaml
I0222 02:54:21.578807 139842431985472 base_trainer.py:138] 	data_dir                 = /tmp/movielens-data/
I0222 02:54:21.578880 139842431985472 base_trainer.py:138] 	dataset                  = None
I0222 02:54:21.578953 139842431985472 base_trainer.py:138] 	distribution_strategy    = mirrored
I0222 02:54:21.579026 139842431985472 base_trainer.py:138] 	dllog_path               = deepray_dllogger.json
I0222 02:54:21.579099 139842431985472 base_trainer.py:138] 	do_lower_case            = True
I0222 02:54:21.579172 139842431985472 base_trainer.py:138] 	download_if_missing      = True
I0222 02:54:21.579245 139842431985472 base_trainer.py:138] 	ds                       = mirrored
I0222 02:54:21.579318 139842431985472 base_trainer.py:138] 	dt                       = fp32
I0222 02:54:21.579391 139842431985472 base_trainer.py:138] 	dtype                    = fp32
I0222 02:54:21.579464 139842431985472 base_trainer.py:138] 	enable_xla               = True
I0222 02:54:21.579537 139842431985472 base_trainer.py:138] 	epochs                   = 1
I0222 02:54:21.579611 139842431985472 base_trainer.py:138] 	eval_batch_size          = None
I0222 02:54:21.579684 139842431985472 base_trainer.py:138] 	eval_script              = /workspaces/bert_tf2/data/download/squad/v1.1/evaluate-v1.1.py
I0222 02:54:21.579757 139842431985472 base_trainer.py:138] 	feature_map              = /workspaces/Deepray2/business/data/feature_map.csv
I0222 02:54:21.579830 139842431985472 base_trainer.py:138] 	fp16_implementation      = keras
I0222 02:54:21.579903 139842431985472 base_trainer.py:138] 	gcp_project              = None
I0222 02:54:21.579977 139842431985472 base_trainer.py:138] 	gp                       = None
I0222 02:54:21.580050 139842431985472 base_trainer.py:138] 	h                        = False
I0222 02:54:21.580123 139842431985472 base_trainer.py:138] 	hbm_oom_exit             = True
I0222 02:54:21.580196 139842431985472 base_trainer.py:138] 	help                     = False
I0222 02:54:21.580269 139842431985472 base_trainer.py:138] 	helpfull                 = False
I0222 02:54:21.580343 139842431985472 base_trainer.py:138] 	helpshort                = False
I0222 02:54:21.580416 139842431985472 base_trainer.py:138] 	helpxml                  = False
I0222 02:54:21.580489 139842431985472 base_trainer.py:138] 	hub_module_url           = None
I0222 02:54:21.580562 139842431985472 base_trainer.py:138] 	init_checkpoint          = /workspaces/bert_tf2/data/download/google_pretrained_weights/uncased_L-12_H-768_A-12/bert_model.ckpt
I0222 02:54:21.580635 139842431985472 base_trainer.py:138] 	input_meta_data_path     = /workspaces/bert_tf2/data/download/squad/v1.1/squad_v1.1_meta_data
I0222 02:54:21.580708 139842431985472 base_trainer.py:138] 	interleave_block         = 2
I0222 02:54:21.580781 139842431985472 base_trainer.py:138] 	interleave_cycle         = 16
I0222 02:54:21.580855 139842431985472 base_trainer.py:138] 	keras_use_ctl            = True
I0222 02:54:21.580931 139842431985472 base_trainer.py:138] 	label                    = ['click', 'play']
I0222 02:54:21.581021 139842431985472 base_trainer.py:138] 	learning_rate            = 5e-06
I0222 02:54:21.581095 139842431985472 base_trainer.py:138] 	log_dir                  = 
I0222 02:54:21.581169 139842431985472 base_trainer.py:138] 	log_steps                = 100
I0222 02:54:21.581243 139842431985472 base_trainer.py:138] 	logger_levels            = {}
I0222 02:54:21.581317 139842431985472 base_trainer.py:138] 	logtostderr              = False
I0222 02:54:21.581390 139842431985472 base_trainer.py:138] 	loss_scale               = None
I0222 02:54:21.581464 139842431985472 base_trainer.py:138] 	ls                       = None
I0222 02:54:21.581537 139842431985472 base_trainer.py:138] 	max_answer_length        = 30
I0222 02:54:21.581610 139842431985472 base_trainer.py:138] 	md                       = /results/tf_bert_finetuning_squad_base_fp16_gbs48_230222025408
I0222 02:54:21.581683 139842431985472 base_trainer.py:138] 	mode                     = train_and_predict
I0222 02:54:21.581756 139842431985472 base_trainer.py:138] 	model_dir                = /results/tf_bert_finetuning_squad_base_fp16_gbs48_230222025408
I0222 02:54:21.581829 139842431985472 base_trainer.py:138] 	model_export_path        = /results/tf_bert_finetuning_squad_base_fp16_gbs48_230222025408
I0222 02:54:21.581902 139842431985472 base_trainer.py:138] 	model_type               = bert
I0222 02:54:21.581975 139842431985472 base_trainer.py:138] 	n_best_size              = 20
I0222 02:54:21.582050 139842431985472 base_trainer.py:138] 	neg_sample_rate          = 0.0
I0222 02:54:21.582123 139842431985472 base_trainer.py:138] 	ng                       = 4
I0222 02:54:21.582196 139842431985472 base_trainer.py:138] 	num_accumulation_steps   = 1
I0222 02:54:21.582269 139842431985472 base_trainer.py:138] 	num_gpus                 = 4
I0222 02:54:21.582342 139842431985472 base_trainer.py:138] 	num_train_examples       = 88641
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad010b0d0> and <deepray.layers.transformer.Transformer object at 0x7fca80104760>).
I0222 02:54:21.582415 139842431985472 base_trainer.py:138] 	only_check_args          = False
W0222 02:54:21.582407 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcad010b0d0> and <deepray.layers.transformer.Transformer object at 0x7fca80104760>).
I0222 02:54:21.582487 139842431985472 base_trainer.py:138] 	op_conversion_fallback_to_while_loop= True
I0222 02:54:21.582560 139842431985472 base_trainer.py:138] 	optimizer_type           = adam
I0222 02:54:21.582633 139842431985472 base_trainer.py:138] 	parallel_parse           = None
I0222 02:54:21.582707 139842431985472 base_trainer.py:138] 	parallel_reads_per_file  = None
I0222 02:54:21.582781 139842431985472 base_trainer.py:138] 	pdb                      = False
I0222 02:54:21.582855 139842431985472 base_trainer.py:138] 	pdb_post_mortem          = False
I0222 02:54:21.582928 139842431985472 base_trainer.py:138] 	prebatch                 = 1
I0222 02:54:21.583001 139842431985472 base_trainer.py:138] 	predict_batch_size       = 8
I0222 02:54:21.583074 139842431985472 base_trainer.py:138] 	predict_file             = /workspaces/bert_tf2/data/download/squad/v1.1/dev-v1.1.json
I0222 02:54:21.583148 139842431985472 base_trainer.py:138] 	prefetch_buffer          = 16
I0222 02:54:21.583221 139842431985472 base_trainer.py:138] 	profile_file             = None
I0222 02:54:21.583294 139842431985472 base_trainer.py:138] 	random_seed              = 12345
I0222 02:54:21.583367 139842431985472 base_trainer.py:138] 	run_eagerly              = False
I0222 02:54:21.583441 139842431985472 base_trainer.py:138] 	run_with_pdb             = False
I0222 02:54:21.583514 139842431985472 base_trainer.py:138] 	run_with_profiling       = False
I0222 02:54:21.583588 139842431985472 base_trainer.py:138] 	runtime_oom_exit         = True
I0222 02:54:21.583661 139842431985472 base_trainer.py:138] 	save_checkpoint_steps    = 1000
I0222 02:54:21.583734 139842431985472 base_trainer.py:138] 	scale_loss               = False
I0222 02:54:21.583808 139842431985472 base_trainer.py:138] 	showprefixforinfo        = True
I0222 02:54:21.583882 139842431985472 base_trainer.py:138] 	shuffle_buffer           = None
I0222 02:54:21.583954 139842431985472 base_trainer.py:138] 	stderrthreshold          = fatal
I0222 02:54:21.584028 139842431985472 base_trainer.py:138] 	steps_per_summary        = 200
I0222 02:54:21.584101 139842431985472 base_trainer.py:138] 	task_index               = -1
I0222 02:54:21.584174 139842431985472 base_trainer.py:138] 	te                       = 1
I0222 02:54:21.584247 139842431985472 base_trainer.py:138] 	test_random_seed         = 301
I0222 02:54:21.584320 139842431985472 base_trainer.py:138] 	test_randomize_ordering_seed= 
I0222 02:54:21.584392 139842431985472 base_trainer.py:138] 	test_srcdir              = 
I0222 02:54:21.584465 139842431985472 base_trainer.py:138] 	test_tmpdir              = /tmp/absl_testing
I0222 02:54:21.584538 139842431985472 base_trainer.py:138] 	tfhub_cache_dir          = None
I0222 02:54:21.584611 139842431985472 base_trainer.py:138] 	tfhub_model_load_format  = AUTO
I0222 02:54:21.584684 139842431985472 base_trainer.py:138] 	train_data               = /workspaces/bert_tf2/data/download/squad/v1.1/squad_v1.1_train.tf_record
I0222 02:54:21.584758 139842431985472 base_trainer.py:138] 	use_cprofile_for_profiling= True
I0222 02:54:21.584831 139842431985472 base_trainer.py:138] 	use_dynamic_embedding    = False
I0222 02:54:21.584904 139842431985472 base_trainer.py:138] 	use_fp16                 = True
I0222 02:54:21.584984 139842431985472 base_trainer.py:138] 	use_horovod              = True
I0222 02:54:21.585058 139842431985472 base_trainer.py:138] 	use_keras_compile_fit    = False
I0222 02:54:21.585132 139842431985472 base_trainer.py:138] 	v                        = 0
I0222 02:54:21.585205 139842431985472 base_trainer.py:138] 	verbose_logging          = False
I0222 02:54:21.585278 139842431985472 base_trainer.py:138] 	verbosity                = 0
I0222 02:54:21.585351 139842431985472 base_trainer.py:138] 	vocab_file               = /workspaces/bert_tf2/data/download/google_pretrained_weights/uncased_L-12_H-768_A-12/vocab.txt
I0222 02:54:21.585424 139842431985472 base_trainer.py:138] 	worker_hosts             = None
I0222 02:54:21.585497 139842431985472 base_trainer.py:138] 	xml_output_file          = 
decayed_learning_rate_at_crossover_point = 1.800650e-05, adjusted_init_lr = 2.221420e-05
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca800efd90> and <deepray.layers.transformer.Transformer object at 0x7fcad010b0d0>).
W0222 02:54:21.590199 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca800efd90> and <deepray.layers.transformer.Transformer object at 0x7fcad010b0d0>).
I0222 02:54:21.595271 139842431985472 base_trainer.py:228] Checkpoint file /workspaces/bert_tf2/data/download/google_pretrained_weights/uncased_L-12_H-768_A-12/bert_model.ckpt found and restoring from initial checkpoint for core model.
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca8017f760> and <deepray.layers.transformer.Transformer object at 0x7fca800efd90>).
W0222 02:54:21.597994 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca8017f760> and <deepray.layers.transformer.Transformer object at 0x7fca800efd90>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca8018b9d0> and <deepray.layers.transformer.Transformer object at 0x7fca8017f760>).
W0222 02:54:21.605789 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca8018b9d0> and <deepray.layers.transformer.Transformer object at 0x7fca8017f760>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca800018b0> and <deepray.layers.transformer.Transformer object at 0x7fca8018b9d0>).
W0222 02:54:21.613582 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca800018b0> and <deepray.layers.transformer.Transformer object at 0x7fca8018b9d0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca80106670> and <deepray.layers.transformer.Transformer object at 0x7fca800018b0>).
W0222 02:54:21.621374 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fca80106670> and <deepray.layers.transformer.Transformer object at 0x7fca800018b0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7fca58742370> and <keras.layers.core.lambda_layer.Lambda object at 0x7fcad011fa60>).
W0222 02:54:21.632989 140514811483968 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7fca58742370> and <keras.layers.core.lambda_layer.Lambda object at 0x7fcad011fa60>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c041f70> and <deepray.layers.self_attention_mask.SelfAttentionMask object at 0x7f2e3c0638b0>).
W0222 02:54:21.662878 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c041f70> and <deepray.layers.self_attention_mask.SelfAttentionMask object at 0x7f2e3c0638b0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c041490> and <deepray.layers.transformer.Transformer object at 0x7f2e3c041f70>).
W0222 02:54:21.670663 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c041490> and <deepray.layers.transformer.Transformer object at 0x7f2e3c041f70>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df035fca0> and <deepray.layers.transformer.Transformer object at 0x7f2e3c041490>).
W0222 02:54:21.678396 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df035fca0> and <deepray.layers.transformer.Transformer object at 0x7f2e3c041490>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df024b0d0> and <deepray.layers.transformer.Transformer object at 0x7f2df035fca0>).
W0222 02:54:21.686212 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df024b0d0> and <deepray.layers.transformer.Transformer object at 0x7f2df035fca0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df036c1c0> and <deepray.layers.transformer.Transformer object at 0x7f2df024b0d0>).
W0222 02:54:21.693978 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df036c1c0> and <deepray.layers.transformer.Transformer object at 0x7f2df024b0d0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c02e5e0> and <deepray.layers.transformer.Transformer object at 0x7f2df036c1c0>).
W0222 02:54:21.701736 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c02e5e0> and <deepray.layers.transformer.Transformer object at 0x7f2df036c1c0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c063970> and <deepray.layers.transformer.Transformer object at 0x7f2e3c02e5e0>).
W0222 02:54:21.709493 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c063970> and <deepray.layers.transformer.Transformer object at 0x7f2e3c02e5e0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df0275a00> and <deepray.layers.transformer.Transformer object at 0x7f2e3c063970>).
W0222 02:54:21.717255 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df0275a00> and <deepray.layers.transformer.Transformer object at 0x7f2e3c063970>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c049460> and <deepray.layers.transformer.Transformer object at 0x7f2df0275a00>).
W0222 02:54:21.725010 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2e3c049460> and <deepray.layers.transformer.Transformer object at 0x7f2df0275a00>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df02c0c70> and <deepray.layers.transformer.Transformer object at 0x7f2e3c049460>).
W0222 02:54:21.732777 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df02c0c70> and <deepray.layers.transformer.Transformer object at 0x7f2e3c049460>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df02bea90> and <deepray.layers.transformer.Transformer object at 0x7f2df02c0c70>).
W0222 02:54:21.740534 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df02bea90> and <deepray.layers.transformer.Transformer object at 0x7f2df02c0c70>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df0135640> and <deepray.layers.transformer.Transformer object at 0x7f2df02bea90>).
W0222 02:54:21.748281 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f2df0135640> and <deepray.layers.transformer.Transformer object at 0x7f2df02bea90>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f2df0045d60> and <keras.layers.core.lambda_layer.Lambda object at 0x7f2e3c041e80>).
W0222 02:54:21.759808 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f2df0045d60> and <keras.layers.core.lambda_layer.Lambda object at 0x7f2e3c041e80>).
I0222 02:54:21.762454 139694807635776 feature_map.py:34] File not exists: /workspaces/Deepray2/business/data/feature_map.csv
I0222 02:54:21.762660 139694807635776 distribution_utils.py:134] Run horovod and turn off distribution strategy.
decayed_learning_rate_at_crossover_point = 1.800650e-05, adjusted_init_lr = 2.221420e-05
I0222 02:54:21.770972 139694807635776 base_trainer.py:228] Checkpoint file /workspaces/bert_tf2/data/download/google_pretrained_weights/uncased_L-12_H-768_A-12/bert_model.ckpt found and restoring from initial checkpoint for core model.
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b90278700> and <deepray.layers.self_attention_mask.SelfAttentionMask object at 0x7f0b901efb50>).
W0222 02:54:21.840094 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b90278700> and <deepray.layers.self_attention_mask.SelfAttentionMask object at 0x7f0b901efb50>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9027aee0> and <deepray.layers.transformer.Transformer object at 0x7f0b90278700>).
W0222 02:54:21.848058 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9027aee0> and <deepray.layers.transformer.Transformer object at 0x7f0b90278700>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b90256dc0> and <deepray.layers.transformer.Transformer object at 0x7f0b9027aee0>).
W0222 02:54:21.855978 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b90256dc0> and <deepray.layers.transformer.Transformer object at 0x7f0b9027aee0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b902293a0> and <deepray.layers.transformer.Transformer object at 0x7f0b90256dc0>).
W0222 02:54:21.863898 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b902293a0> and <deepray.layers.transformer.Transformer object at 0x7f0b90256dc0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b90075eb0> and <deepray.layers.transformer.Transformer object at 0x7f0b902293a0>).
W0222 02:54:21.871812 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b90075eb0> and <deepray.layers.transformer.Transformer object at 0x7f0b902293a0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9026d430> and <deepray.layers.transformer.Transformer object at 0x7f0b90075eb0>).
W0222 02:54:21.879724 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9026d430> and <deepray.layers.transformer.Transformer object at 0x7f0b90075eb0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9006fee0> and <deepray.layers.transformer.Transformer object at 0x7f0b9026d430>).
W0222 02:54:21.887633 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9006fee0> and <deepray.layers.transformer.Transformer object at 0x7f0b9026d430>).
I0222 02:54:21.891766 140521934866240 feature_map.py:34] File not exists: /workspaces/Deepray2/business/data/feature_map.csv
I0222 02:54:21.891980 140521934866240 distribution_utils.py:134] Run horovod and turn off distribution strategy.
decayed_learning_rate_at_crossover_point = 1.800650e-05, adjusted_init_lr = 2.221420e-05
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b902fbfa0> and <deepray.layers.transformer.Transformer object at 0x7f0b9006fee0>).
W0222 02:54:21.895538 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b902fbfa0> and <deepray.layers.transformer.Transformer object at 0x7f0b9006fee0>).
I0222 02:54:21.900527 140521934866240 base_trainer.py:228] Checkpoint file /workspaces/bert_tf2/data/download/google_pretrained_weights/uncased_L-12_H-768_A-12/bert_model.ckpt found and restoring from initial checkpoint for core model.
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b900e8d60> and <deepray.layers.transformer.Transformer object at 0x7f0b902fbfa0>).
W0222 02:54:21.903438 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b900e8d60> and <deepray.layers.transformer.Transformer object at 0x7f0b902fbfa0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9011e1f0> and <deepray.layers.transformer.Transformer object at 0x7f0b900e8d60>).
W0222 02:54:21.911336 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9011e1f0> and <deepray.layers.transformer.Transformer object at 0x7f0b900e8d60>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9012cca0> and <deepray.layers.transformer.Transformer object at 0x7f0b9011e1f0>).
W0222 02:54:21.919234 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b9012cca0> and <deepray.layers.transformer.Transformer object at 0x7f0b9011e1f0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b900bd7c0> and <deepray.layers.transformer.Transformer object at 0x7f0b9012cca0>).
W0222 02:54:21.927138 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7f0b900bd7c0> and <deepray.layers.transformer.Transformer object at 0x7f0b9012cca0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f0b686c1310> and <keras.layers.core.lambda_layer.Lambda object at 0x7f0b90278610>).
W0222 02:54:21.938901 139694807635776 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f0b686c1310> and <keras.layers.core.lambda_layer.Lambda object at 0x7f0b90278610>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc284a1af0> and <deepray.layers.self_attention_mask.SelfAttentionMask object at 0x7fcc28460490>).
W0222 02:54:21.968638 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc284a1af0> and <deepray.layers.self_attention_mask.SelfAttentionMask object at 0x7fcc28460490>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc2846c0a0> and <deepray.layers.transformer.Transformer object at 0x7fcc284a1af0>).
W0222 02:54:21.976486 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc2846c0a0> and <deepray.layers.transformer.Transformer object at 0x7fcc284a1af0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc2846c850> and <deepray.layers.transformer.Transformer object at 0x7fcc2846c0a0>).
W0222 02:54:21.984289 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc2846c850> and <deepray.layers.transformer.Transformer object at 0x7fcc2846c0a0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc28432550> and <deepray.layers.transformer.Transformer object at 0x7fcc2846c850>).
W0222 02:54:21.992170 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc28432550> and <deepray.layers.transformer.Transformer object at 0x7fcc2846c850>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc28217d90> and <deepray.layers.transformer.Transformer object at 0x7fcc28432550>).
W0222 02:54:22.000015 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc28217d90> and <deepray.layers.transformer.Transformer object at 0x7fcc28432550>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc28460e80> and <deepray.layers.transformer.Transformer object at 0x7fcc28217d90>).
W0222 02:54:22.007923 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc28460e80> and <deepray.layers.transformer.Transformer object at 0x7fcc28217d90>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc284d3a00> and <deepray.layers.transformer.Transformer object at 0x7fcc28460e80>).
W0222 02:54:22.015754 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc284d3a00> and <deepray.layers.transformer.Transformer object at 0x7fcc28460e80>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc2846f520> and <deepray.layers.transformer.Transformer object at 0x7fcc284d3a00>).
W0222 02:54:22.023590 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc2846f520> and <deepray.layers.transformer.Transformer object at 0x7fcc284d3a00>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc2829fa60> and <deepray.layers.transformer.Transformer object at 0x7fcc2846f520>).
W0222 02:54:22.031438 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc2829fa60> and <deepray.layers.transformer.Transformer object at 0x7fcc2846f520>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc283449a0> and <deepray.layers.transformer.Transformer object at 0x7fcc2829fa60>).
W0222 02:54:22.039267 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc283449a0> and <deepray.layers.transformer.Transformer object at 0x7fcc2829fa60>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc281d1970> and <deepray.layers.transformer.Transformer object at 0x7fcc283449a0>).
W0222 02:54:22.047093 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc281d1970> and <deepray.layers.transformer.Transformer object at 0x7fcc283449a0>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc28298670> and <deepray.layers.transformer.Transformer object at 0x7fcc281d1970>).
W0222 02:54:22.054926 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.layers.transformer.Transformer object at 0x7fcc28298670> and <deepray.layers.transformer.Transformer object at 0x7fcc281d1970>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7fcc280e2370> and <keras.layers.core.lambda_layer.Lambda object at 0x7fcc284a1fd0>).
W0222 02:54:22.066577 140521934866240 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7fcc280e2370> and <keras.layers.core.lambda_layer.Lambda object at 0x7fcc284a1fd0>).
I0222 02:54:22.370549 140514811483968 base_trainer.py:233] Loading from checkpoint file completed
I0222 02:54:22.564684 139842431985472 base_trainer.py:233] Loading from checkpoint file completed
I0222 02:54:22.665153 139694807635776 base_trainer.py:233] Loading from checkpoint file completed
I0222 02:54:22.788403 140521934866240 base_trainer.py:233] Loading from checkpoint file completed
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:54:40.545229 140514811483968 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:54:40.637545 139842431985472 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:54:40.904253 140521934866240 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:54:40.955181 139694807635776 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:55:02.530953 139842431985472 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:55:02.588361 140514811483968 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:55:03.270597 140521934866240 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:55:04.099206 139694807635776 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
2023-02-22 02:55:24.547115: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.

If you want XLA:CPU, do one of the following:

 - set the TF_XLA_FLAGS to include "--tf_xla_cpu_global_jit", or
 - set cpu_global_jit to true on this session's OptimizerOptions, or
 - use experimental_jit_scope, or
 - use tf.function(jit_compile=True).

To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a
proper command-line flag, not via TF_XLA_FLAGS).
2023-02-22 02:55:24.640948: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.

If you want XLA:CPU, do one of the following:

 - set the TF_XLA_FLAGS to include "--tf_xla_cpu_global_jit", or
 - set cpu_global_jit to true on this session's OptimizerOptions, or
 - use experimental_jit_scope, or
 - use tf.function(jit_compile=True).

To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a
proper command-line flag, not via TF_XLA_FLAGS).
2023-02-22 02:55:25.387853: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.

If you want XLA:CPU, do one of the following:

 - set the TF_XLA_FLAGS to include "--tf_xla_cpu_global_jit", or
 - set cpu_global_jit to true on this session's OptimizerOptions, or
 - use experimental_jit_scope, or
 - use tf.function(jit_compile=True).

To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a
proper command-line flag, not via TF_XLA_FLAGS).
2023-02-22 02:55:26.018586: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.

If you want XLA:CPU, do one of the following:

 - set the TF_XLA_FLAGS to include "--tf_xla_cpu_global_jit", or
 - set cpu_global_jit to true on this session's OptimizerOptions, or
 - use experimental_jit_scope, or
 - use tf.function(jit_compile=True).

To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a
proper command-line flag, not via TF_XLA_FLAGS).
2023-02-22 02:55:29.107067: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2cd14a3770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-02-22 02:55:29.107123: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0
2023-02-22 02:55:29.256085: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc9514a45c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-02-22 02:55:29.256147: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0
2023-02-22 02:55:29.494129: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-02-22 02:55:29.644150: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-02-22 02:55:29.701060: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fcb0158f940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-02-22 02:55:29.701116: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0
2023-02-22 02:55:30.100463: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-02-22 02:55:30.321975: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f0a594a3a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-02-22 02:55:30.322029: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0
2023-02-22 02:55:30.708583: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-02-22 02:56:04.996348: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-02-22 02:56:05.586823: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-02-22 02:56:05.668538: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-02-22 02:56:06.095378: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Bootstrap : Using bond0.2074:10.0.74.1<0>
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO NET/IB : No device found.
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO NET/Socket : Using [0]bond0.2074:10.0.74.1<0> [1]lxcbr0:10.0.3.1<0> [2]bond0:fe80::c494:eeff:fe63:7b0c%bond0<0>
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Using network Socket
NCCL version 2.9.9+cuda11.3
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Bootstrap : Using bond0.2074:10.0.74.1<0>
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Bootstrap : Using bond0.2074:10.0.74.1<0>
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO NET/IB : No device found.
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO NET/IB : No device found.
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO NET/Socket : Using [0]bond0.2074:10.0.74.1<0> [1]lxcbr0:10.0.3.1<0> [2]bond0:fe80::c494:eeff:fe63:7b0c%bond0<0>
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Using network Socket
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO NET/Socket : Using [0]bond0.2074:10.0.74.1<0> [1]lxcbr0:10.0.3.1<0> [2]bond0:fe80::c494:eeff:fe63:7b0c%bond0<0>
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Using network Socket
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Bootstrap : Using bond0.2074:10.0.74.1<0>
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO NET/IB : No device found.
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO NET/Socket : Using [0]bond0.2074:10.0.74.1<0> [1]lxcbr0:10.0.3.1<0> [2]bond0:fe80::c494:eeff:fe63:7b0c%bond0<0>
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Using network Socket
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Channel 00/02 :    0   1   2   3
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Channel 01/02 :    0   1   2   3
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Setting affinity for GPU 3 to fff0,00fff000
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Setting affinity for GPU 1 to 0f,ff000fff
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Setting affinity for GPU 2 to fff0,00fff000
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Channel 00 : 3[af000] -> 0[18000] via direct shared memory
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Channel 00 : 2[86000] -> 3[af000] via direct shared memory
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Channel 00 : 1[3b000] -> 2[86000] via direct shared memory
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Channel 00 : 0[18000] -> 1[3b000] via direct shared memory
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Channel 01 : 3[af000] -> 0[18000] via direct shared memory
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Channel 01 : 2[86000] -> 3[af000] via direct shared memory
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Channel 01 : 0[18000] -> 1[3b000] via direct shared memory
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Channel 01 : 1[3b000] -> 2[86000] via direct shared memory
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Connected all rings
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Connected all rings
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Connected all rings
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Connected all rings
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Channel 00 : 3[af000] -> 2[86000] via direct shared memory
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Channel 01 : 3[af000] -> 2[86000] via direct shared memory
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Channel 00 : 2[86000] -> 1[3b000] via direct shared memory
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Channel 00 : 1[3b000] -> 0[18000] via direct shared memory
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Channel 01 : 2[86000] -> 1[3b000] via direct shared memory
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Channel 01 : 1[3b000] -> 0[18000] via direct shared memory
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO Connected all trees
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
op-arsenaldevk8s-gpu01:147739:148126 [3] NCCL INFO comm 0x7fcc24347330 rank 3 nranks 4 cudaDev 3 busId af000 - Init COMPLETE
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Connected all trees
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO comm 0x7f2dec38c000 rank 0 nranks 4 cudaDev 0 busId 18000 - Init COMPLETE
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO Connected all trees
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO Connected all trees
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
op-arsenaldevk8s-gpu01:147738:148127 [2] NCCL INFO comm 0x7f0bdc348e40 rank 2 nranks 4 cudaDev 2 busId 86000 - Init COMPLETE
op-arsenaldevk8s-gpu01:147737:148124 [1] NCCL INFO comm 0x7fca7c348dd0 rank 1 nranks 4 cudaDev 1 busId 3b000 - Init COMPLETE
op-arsenaldevk8s-gpu01:147736:148125 [0] NCCL INFO Launch mode Parallel
2023-02-22 02:56:28.864512: I tensorflow/stream_executor/gpu/asm_compiler.cc:323] ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_58'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_180'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_74'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_138'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_118'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_106'
ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_170'

2023-02-22 02:56:28.936890: I tensorflow/stream_executor/gpu/asm_compiler.cc:323] ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_58'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_180'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_74'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_138'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_118'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_106'
ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_170'

2023-02-22 02:56:28.986222: I tensorflow/stream_executor/gpu/asm_compiler.cc:323] ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_58'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_180'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_74'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_138'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_118'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_106'
ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_170'

2023-02-22 02:56:28.996426: I tensorflow/stream_executor/gpu/asm_compiler.cc:323] ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_58'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_180'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_74'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_138'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_118'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_106'
ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down'
ptxas warning : Registers are spilled to local memory in function 'input_fusion_reduce_170'

I0222 02:57:04.378168 139842431985472 base_trainer.py:372] Step: 200 Lr 1.98075e-05 Loss scale 8192
I0222 02:57:04.378374 139842431985472 base_trainer.py:373] Train Step: 200/1846  / loss=4.043647289276123 / time=161.277sec
I0222 02:57:04.378454 139842431985472 base_trainer.py:374] Perf 59.53
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:57:16.590664 139694807635776 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:57:16.646932 139842431985472 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:57:17.089605 140521934866240 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0222 02:57:17.092291 140514811483968 utils.py:76] Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
I0222 02:58:48.120443 139842431985472 base_trainer.py:372] Step: 400 Lr 1.74007e-05 Loss scale 8192
I0222 02:58:48.120648 139842431985472 base_trainer.py:373] Train Step: 400/1846  / loss=1.6114380359649658 / time=103.739sec
I0222 02:58:48.120728 139842431985472 base_trainer.py:374] Perf 92.54
I0222 02:59:21.715652 139842431985472 base_trainer.py:372] Step: 600 Lr 1.4994e-05 Loss scale 8192
I0222 02:59:21.715851 139842431985472 base_trainer.py:373] Train Step: 600/1846  / loss=1.2907629013061523 / time=33.592sec
I0222 02:59:21.715930 139842431985472 base_trainer.py:374] Perf 285.80
I0222 02:59:55.317249 139842431985472 base_trainer.py:372] Step: 800 Lr 1.25872e-05 Loss scale 2048
I0222 02:59:55.317450 139842431985472 base_trainer.py:373] Train Step: 800/1846  / loss=1.3398425579071045 / time=33.598sec
I0222 02:59:55.317529 139842431985472 base_trainer.py:374] Perf 285.75
I0222 03:00:32.682036 139842431985472 base_trainer.py:357] Saved checkpoint to /results/tf_bert_finetuning_squad_base_fp16_gbs48_230222025408/ckpt-1
I0222 03:00:32.686215 139842431985472 base_trainer.py:372] Step: 1000 Lr 1.01805e-05 Loss scale 2048
I0222 03:00:32.686394 139842431985472 base_trainer.py:373] Train Step: 1000/1846  / loss=1.404260277748108 / time=33.516sec
I0222 03:00:32.686472 139842431985472 base_trainer.py:374] Perf 286.44
I0222 03:01:06.210244 139842431985472 base_trainer.py:372] Step: 1200 Lr 7.77377e-06 Loss scale 2048
I0222 03:01:06.210459 139842431985472 base_trainer.py:373] Train Step: 1200/1846  / loss=1.448732852935791 / time=33.521sec
I0222 03:01:06.210533 139842431985472 base_trainer.py:374] Perf 286.41
I0222 03:01:39.693241 139842431985472 base_trainer.py:372] Step: 1400 Lr 5.36703e-06 Loss scale 2048
I0222 03:01:39.693437 139842431985472 base_trainer.py:373] Train Step: 1400/1846  / loss=1.2302013635635376 / time=33.479sec
I0222 03:01:39.693515 139842431985472 base_trainer.py:374] Perf 286.76
I0222 03:02:13.173210 139842431985472 base_trainer.py:372] Step: 1600 Lr 2.96029e-06 Loss scale 2048
I0222 03:02:13.173408 139842431985472 base_trainer.py:373] Train Step: 1600/1846  / loss=1.4454467296600342 / time=33.476sec
I0222 03:02:13.173486 139842431985472 base_trainer.py:374] Perf 286.78
I0222 03:02:46.674173 139842431985472 base_trainer.py:372] Step: 1800 Lr 5.5355e-07 Loss scale 2048
I0222 03:02:46.674366 139842431985472 base_trainer.py:373] Train Step: 1800/1846  / loss=1.2681738138198853 / time=33.497sec
I0222 03:02:46.674444 139842431985472 base_trainer.py:374] Perf 286.60
I0222 03:02:54.398929 139842431985472 base_trainer.py:372] Step: 1846 Lr 0 Loss scale 2048
I0222 03:02:54.399125 139842431985472 base_trainer.py:373] Train Step: 1846/1846  / loss=1.0677543878555298 / time=7.721sec
I0222 03:02:54.399204 139842431985472 base_trainer.py:374] Perf 286.02
I0222 03:02:57.660079 139842431985472 base_trainer.py:80] Saving model as TF checkpoint: /results/tf_bert_finetuning_squad_base_fp16_gbs48_230222025408/ctl_step_1846.ckpt-2
I0222 03:02:57.661284 139842431985472 base_trainer.py:106] Training Summary: 
{'total_training_steps': 1846, 'train_loss': 1.0677543878555298}
I0222 03:02:57.662265 139842431985472 base_trainer.py:422] -----------------------------
I0222 03:02:57.662383 139842431985472 base_trainer.py:423]   Batch size = 12
I0222 03:02:57.662463 139842431985472 base_trainer.py:424]   Num steps = 1846
I0222 03:02:57.662553 139842431985472 base_trainer.py:425]   LR = 5e-06
I0222 03:02:57.662634 139842431985472 base_trainer.py:427] Multi-GPU training with TF Horovod
I0222 03:02:57.662727 139842431985472 base_trainer.py:428] hvd.size() = 4
I0222 03:02:57.662802 139842431985472 base_trainer.py:429] Total Training Time = 511.30 for Examples = 88608
I0222 03:02:57.662878 139842431985472 base_trainer.py:431] Throughput Average (examples/sec) with overhead = 173.30
I0222 03:02:57.663168 139842431985472 base_trainer.py:433] Throughput Average (examples/sec) = 286.32
I0222 03:02:57.663239 139842431985472 base_trainer.py:434] -----------------------------
DLL 2023-02-22 03:02:57.663303 -  throughput_train : 286.319 sequences/s
DLL 2023-02-22 03:02:57.663415 -  total_loss : 1.0678 
I0222 03:03:00.373434 139842431985472 squad_lib.py:355] *** Example ***
I0222 03:03:00.373624 139842431985472 squad_lib.py:356] unique_id: 1000000000
I0222 03:03:00.373709 139842431985472 squad_lib.py:357] example_index: 0
I0222 03:03:00.373780 139842431985472 squad_lib.py:358] doc_span_index: 0
I0222 03:03:00.373990 139842431985472 squad_lib.py:359] tokens: [CLS] which nfl team represented the afc at super bowl 50 ? [SEP] super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season . the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24  10 to earn their third super bowl title . the game was played on february 7 , 2016 , at levi ' s stadium in the san francisco bay area at santa clara , california . as this was the 50th super bowl , the league emphasized the " golden anniversary " with various gold - themed initiatives , as well as temporarily suspend ##ing the tradition of naming each super bowl game with roman nu ##meral ##s ( under which the game would have been known as " super bowl l " ) , so that the logo could prominently feature the arabic nu ##meral ##s 50 . [SEP]
I0222 03:03:00.374190 139842431985472 squad_lib.py:361] token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:17 32:17 33:18 34:19 35:20 36:21 37:21 38:22 39:23 40:24 41:25 42:26 43:26 44:26 45:27 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:35 54:35 55:35 56:36 57:37 58:38 59:39 60:39 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:54 79:54 80:55 81:56 82:56 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:65 93:66 94:66 95:67 96:67 97:68 98:69 99:70 100:71 101:72 102:73 103:74 104:74 105:75 106:76 107:77 108:78 109:79 110:79 111:80 112:80 113:81 114:82 115:83 116:83 117:83 118:84 119:84 120:85 121:86 122:87 123:88 124:89 125:89 126:90 127:91 128:92 129:93 130:94 131:95 132:96 133:97 134:98 135:99 136:100 137:100 138:100 139:101 140:101 141:102 142:103 143:104 144:105 145:106 146:107 147:108 148:109 149:110 150:110 151:111 152:112 153:112 154:112 155:112 156:113 157:114 158:115 159:116 160:117 161:118 162:119 163:120 164:121 165:122 166:122 167:122 168:123 169:123
I0222 03:03:00.374384 139842431985472 squad_lib.py:365] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True
I0222 03:03:00.374678 139842431985472 squad_lib.py:370] input_ids: 101 2029 5088 2136 3421 1996 10511 2012 3565 4605 2753 1029 102 3565 4605 2753 2001 2019 2137 2374 2208 2000 5646 1996 3410 1997 1996 2120 2374 2223 1006 5088 1007 2005 1996 2325 2161 1012 1996 2137 2374 3034 1006 10511 1007 3410 7573 14169 3249 1996 2120 2374 3034 1006 22309 1007 3410 3792 12915 2484 1516 2184 2000 7796 2037 2353 3565 4605 2516 1012 1996 2208 2001 2209 2006 2337 1021 1010 2355 1010 2012 11902 1005 1055 3346 1999 1996 2624 3799 3016 2181 2012 4203 10254 1010 2662 1012 2004 2023 2001 1996 12951 3565 4605 1010 1996 2223 13155 1996 1000 3585 5315 1000 2007 2536 2751 1011 11773 11107 1010 2004 2092 2004 8184 28324 2075 1996 4535 1997 10324 2169 3565 4605 2208 2007 3142 16371 28990 2015 1006 2104 2029 1996 2208 2052 2031 2042 2124 2004 1000 3565 4605 1048 1000 1007 1010 2061 2008 1996 8154 2071 14500 3444 1996 5640 16371 28990 2015 2753 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
I0222 03:03:00.374953 139842431985472 squad_lib.py:371] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
I0222 03:03:00.375225 139842431985472 squad_lib.py:372] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
I0222 03:03:00.384944 139842431985472 squad_lib.py:355] *** Example ***
I0222 03:03:00.385075 139842431985472 squad_lib.py:356] unique_id: 1000000001
I0222 03:03:00.385154 139842431985472 squad_lib.py:357] example_index: 1
I0222 03:03:00.385238 139842431985472 squad_lib.py:358] doc_span_index: 0
I0222 03:03:00.385454 139842431985472 squad_lib.py:359] tokens: [CLS] which nfl team represented the nfc at super bowl 50 ? [SEP] super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season . the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24  10 to earn their third super bowl title . the game was played on february 7 , 2016 , at levi ' s stadium in the san francisco bay area at santa clara , california . as this was the 50th super bowl , the league emphasized the " golden anniversary " with various gold - themed initiatives , as well as temporarily suspend ##ing the tradition of naming each super bowl game with roman nu ##meral ##s ( under which the game would have been known as " super bowl l " ) , so that the logo could prominently feature the arabic nu ##meral ##s 50 . [SEP]
I0222 03:03:00.385650 139842431985472 squad_lib.py:361] token_to_orig_map: 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:17 32:17 33:18 34:19 35:20 36:21 37:21 38:22 39:23 40:24 41:25 42:26 43:26 44:26 45:27 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:35 54:35 55:35 56:36 57:37 58:38 59:39 60:39 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:54 79:54 80:55 81:56 82:56 83:56 84:57 85:58 86:59 87:60 88:61 89:62 90:63 91:64 92:65 93:66 94:66 95:67 96:67 97:68 98:69 99:70 100:71 101:72 102:73 103:74 104:74 105:75 106:76 107:77 108:78 109:79 110:79 111:80 112:80 113:81 114:82 115:83 116:83 117:83 118:84 119:84 120:85 121:86 122:87 123:88 124:89 125:89 126:90 127:91 128:92 129:93 130:94 131:95 132:96 133:97 134:98 135:99 136:100 137:100 138:100 139:101 140:101 141:102 142:103 143:104 144:105 145:106 146:107 147:108 148:109 149:110 150:110 151:111 152:112 153:112 154:112 155:112 156:113 157:114 158:115 159:116 160:117 161:118 162:119 163:120 164:121 165:122 166:122 167:122 168:123 169:123
I0222 03:03:00.385840 139842431985472 squad_lib.py:365] token_is_max_context: 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True
I0222 03:03:00.386119 139842431985472 squad_lib.py:370] input_ids: 101 2029 5088 2136 3421 1996 22309 2012 3565 4605 2753 1029 102 3565 4605 2753 2001 2019 2137 2374 2208 2000 5646 1996 3410 1997 1996 2120 2374 2223 1006 5088 1007 2005 1996 2325 2161 1012 1996 2137 2374 3034 1006 10511 1007 3410 7573 14169 3249 1996 2120 2374 3034 1006 22309 1007 3410 3792 12915 2484 1516 2184 2000 7796 2037 2353 3565 4605 2516 1012 1996 2208 2001 2209 2006 2337 1021 1010 2355 1010 2012 11902 1005 1055 3346 1999 1996 2624 3799 3016 2181 2012 4203 10254 1010 2662 1012 2004 2023 2001 1996 12951 3565 4605 1010 1996 2223 13155 1996 1000 3585 5315 1000 2007 2536 2751 1011 11773 11107 1010 2004 2092 2004 8184 28324 2075 1996 4535 1997 10324 2169 3565 4605 2208 2007 3142 16371 28990 2015 1006 2104 2029 1996 2208 2052 2031 2042 2124 2004 1000 3565 4605 1048 1000 1007 1010 2061 2008 1996 8154 2071 14500 3444 1996 5640 16371 28990 2015 2753 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
I0222 03:03:00.386393 139842431985472 squad_lib.py:371] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
I0222 03:03:00.386664 139842431985472 squad_lib.py:372] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
I0222 03:04:41.536795 139842431985472 squad_lib.py:409] Adding padding examples to make sure no partial batch.
I0222 03:04:41.537015 139842431985472 squad_lib.py:410] Adds 7 padding examples for inference.
I0222 03:04:41.547415 139842431985472 run_squad.py:330] ***** Running predictions *****
I0222 03:04:41.547578 139842431985472 run_squad.py:331]   Num orig examples = 10570
I0222 03:04:41.547662 139842431985472 run_squad.py:332]   Num split examples = 10833
I0222 03:04:41.547745 139842431985472 run_squad.py:333]   Batch size = 8
I0222 03:04:41.547884 139842431985472 distribution_utils.py:134] Run horovod and turn off distribution strategy.
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.networks.transformer_encoder.TransformerEncoder object at 0x7f2c7add2b20> and <keras.engine.input_layer.InputLayer object at 0x7f2c7add2c40>).
W0222 03:04:45.993871 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.networks.transformer_encoder.TransformerEncoder object at 0x7f2c7add2b20> and <keras.engine.input_layer.InputLayer object at 0x7f2c7add2c40>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.networks.span_labeling.SpanLabeling object at 0x7f2c78c36610> and <deepray.networks.transformer_encoder.TransformerEncoder object at 0x7f2c7add2b20>).
W0222 03:04:46.006213 139842431985472 base.py:324] Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<deepray.networks.span_labeling.SpanLabeling object at 0x7f2c78c36610> and <deepray.networks.transformer_encoder.TransformerEncoder object at 0x7f2c7add2b20>).
I0222 03:04:46.153525 139842431985472 run_squad.py:138] Restoring checkpoints from /results/tf_bert_finetuning_squad_base_fp16_gbs48_230222025408/ctl_step_1846.ckpt-2
I0222 03:05:02.647718 139842431985472 run_squad.py:193] Made predictions for 200 records.
I0222 03:05:03.220581 139842431985472 run_squad.py:193] Made predictions for 400 records.
I0222 03:05:03.788269 139842431985472 run_squad.py:193] Made predictions for 600 records.
I0222 03:05:04.356176 139842431985472 run_squad.py:193] Made predictions for 800 records.
I0222 03:05:04.923093 139842431985472 run_squad.py:193] Made predictions for 1000 records.
I0222 03:05:05.490363 139842431985472 run_squad.py:193] Made predictions for 1200 records.
I0222 03:05:06.057389 139842431985472 run_squad.py:193] Made predictions for 1400 records.
I0222 03:05:06.624577 139842431985472 run_squad.py:193] Made predictions for 1600 records.
I0222 03:05:07.192167 139842431985472 run_squad.py:193] Made predictions for 1800 records.
I0222 03:05:07.755165 139842431985472 run_squad.py:193] Made predictions for 2000 records.
I0222 03:05:08.321818 139842431985472 run_squad.py:193] Made predictions for 2200 records.
I0222 03:05:08.889806 139842431985472 run_squad.py:193] Made predictions for 2400 records.
I0222 03:05:09.456604 139842431985472 run_squad.py:193] Made predictions for 2600 records.
I0222 03:05:10.022928 139842431985472 run_squad.py:193] Made predictions for 2800 records.
I0222 03:05:10.640971 139842431985472 run_squad.py:193] Made predictions for 3000 records.
I0222 03:05:11.207592 139842431985472 run_squad.py:193] Made predictions for 3200 records.
I0222 03:05:11.774128 139842431985472 run_squad.py:193] Made predictions for 3400 records.
I0222 03:05:12.340717 139842431985472 run_squad.py:193] Made predictions for 3600 records.
I0222 03:05:12.907655 139842431985472 run_squad.py:193] Made predictions for 3800 records.
I0222 03:05:13.474116 139842431985472 run_squad.py:193] Made predictions for 4000 records.
I0222 03:05:14.040781 139842431985472 run_squad.py:193] Made predictions for 4200 records.
I0222 03:05:14.607630 139842431985472 run_squad.py:193] Made predictions for 4400 records.
I0222 03:05:15.174620 139842431985472 run_squad.py:193] Made predictions for 4600 records.
I0222 03:05:15.742293 139842431985472 run_squad.py:193] Made predictions for 4800 records.
I0222 03:05:16.309273 139842431985472 run_squad.py:193] Made predictions for 5000 records.
I0222 03:05:16.876605 139842431985472 run_squad.py:193] Made predictions for 5200 records.
I0222 03:05:17.494976 139842431985472 run_squad.py:193] Made predictions for 5400 records.
I0222 03:05:18.061524 139842431985472 run_squad.py:193] Made predictions for 5600 records.
I0222 03:05:18.628394 139842431985472 run_squad.py:193] Made predictions for 5800 records.
I0222 03:05:19.195588 139842431985472 run_squad.py:193] Made predictions for 6000 records.
I0222 03:05:19.761762 139842431985472 run_squad.py:193] Made predictions for 6200 records.
I0222 03:05:20.328730 139842431985472 run_squad.py:193] Made predictions for 6400 records.
I0222 03:05:20.895705 139842431985472 run_squad.py:193] Made predictions for 6600 records.
I0222 03:05:21.462655 139842431985472 run_squad.py:193] Made predictions for 6800 records.
I0222 03:05:22.029147 139842431985472 run_squad.py:193] Made predictions for 7000 records.
I0222 03:05:22.590895 139842431985472 run_squad.py:193] Made predictions for 7200 records.
I0222 03:05:23.156916 139842431985472 run_squad.py:193] Made predictions for 7400 records.
I0222 03:05:23.723860 139842431985472 run_squad.py:193] Made predictions for 7600 records.
I0222 03:05:24.290778 139842431985472 run_squad.py:193] Made predictions for 7800 records.
I0222 03:05:24.908982 139842431985472 run_squad.py:193] Made predictions for 8000 records.
I0222 03:05:25.475772 139842431985472 run_squad.py:193] Made predictions for 8200 records.
I0222 03:05:26.041187 139842431985472 run_squad.py:193] Made predictions for 8400 records.
I0222 03:05:26.606945 139842431985472 run_squad.py:193] Made predictions for 8600 records.
I0222 03:05:27.173358 139842431985472 run_squad.py:193] Made predictions for 8800 records.
I0222 03:05:27.739070 139842431985472 run_squad.py:193] Made predictions for 9000 records.
I0222 03:05:28.305346 139842431985472 run_squad.py:193] Made predictions for 9200 records.
I0222 03:05:28.870999 139842431985472 run_squad.py:193] Made predictions for 9400 records.
I0222 03:05:29.437528 139842431985472 run_squad.py:193] Made predictions for 9600 records.
I0222 03:05:30.003364 139842431985472 run_squad.py:193] Made predictions for 9800 records.
I0222 03:05:30.569719 139842431985472 run_squad.py:193] Made predictions for 10000 records.
I0222 03:05:31.135895 139842431985472 run_squad.py:193] Made predictions for 10200 records.
I0222 03:05:31.754679 139842431985472 run_squad.py:193] Made predictions for 10400 records.
I0222 03:05:32.320123 139842431985472 run_squad.py:193] Made predictions for 10600 records.
I0222 03:05:32.886599 139842431985472 run_squad.py:193] Made predictions for 10800 records.
I0222 03:05:32.998801 139842431985472 run_squad.py:196] -----------------------------
I0222 03:05:32.998948 139842431985472 run_squad.py:197] Summary Inference Statistics
I0222 03:05:32.999028 139842431985472 run_squad.py:198] Batch size = 8
I0222 03:05:32.999103 139842431985472 run_squad.py:199] Sequence Length = 384
I0222 03:05:32.999177 139842431985472 run_squad.py:200] Precision = fp16
I0222 03:05:32.999249 139842431985472 run_squad.py:201] Total Inference Time = 46.22 for Sentences = 10840
I0222 03:05:32.999327 139842431985472 run_squad.py:230] -----------------------------
I0222 03:05:33.054645 139842431985472 squad_lib.py:693] Writing predictions to: /results/tf_bert_finetuning_squad_base_fp16_gbs48_230222025408/predictions.json
I0222 03:05:33.054855 139842431985472 squad_lib.py:694] Writing nbest to: /results/tf_bert_finetuning_squad_base_fp16_gbs48_230222025408/nbest_predictions.json
DLL 2023-02-22 03:07:34.981729 -  f1 : 84.4242 None
DLL 2023-02-22 03:07:34.981843 -  exact_match : 75.4494 
b'{"exact_match": 75.44938505203406, "f1": 84.4241704124407}\n'
