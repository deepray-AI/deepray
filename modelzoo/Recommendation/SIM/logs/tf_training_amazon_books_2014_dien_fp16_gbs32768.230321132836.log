I0321 13:28:42.586664 139924683052864 distribution_utils.py:137] Run horovod and turn off distribution strategy.
I0321 13:28:42.588471 139893781284672 distribution_utils.py:137] Run horovod and turn off distribution strategy.
I0321 13:28:42.590100 140134327568192 distribution_utils.py:137] Run horovod and turn off distribution strategy.
I0321 13:28:42.595052 140058691233600 distribution_utils.py:137] Run horovod and turn off distribution strategy.
I0321 13:28:42.602874 139924683052864 feature_map.py:35] File not exists: /workspaces/Deepray2/business/data/feature_map.csv
I0321 13:28:42.604684 139893781284672 feature_map.py:35] File not exists: /workspaces/Deepray2/business/data/feature_map.csv
2023-03-21 13:28:42.606010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0321 13:28:42.606510 140134327568192 feature_map.py:35] File not exists: /workspaces/Deepray2/business/data/feature_map.csv
2023-03-21 13:28:42.607463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-21 13:28:42.609633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0321 13:28:42.611399 140058691233600 feature_map.py:35] File not exists: /workspaces/Deepray2/business/data/feature_map.csv
2023-03-21 13:28:42.614503: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-21 13:28:44.033454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10515 MB memory:  -> device: 1, name: NVIDIA TITAN V, pci bus id: 0000:3b:00.0, compute capability: 7.0
2023-03-21 13:28:44.041523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10515 MB memory:  -> device: 3, name: NVIDIA TITAN V, pci bus id: 0000:af:00.0, compute capability: 7.0
2023-03-21 13:28:44.048415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10515 MB memory:  -> device: 2, name: NVIDIA TITAN V, pci bus id: 0000:86:00.0, compute capability: 7.0
2023-03-21 13:28:44.065202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10515 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:18:00.0, compute capability: 7.0
I0321 13:28:44.106506 139924683052864 distribution_utils.py:137] Run horovod and turn off distribution strategy.
decayed_learning_rate_at_crossover_point = 3.856000e-02, adjusted_init_lr = 4.149378e-02
I0321 13:28:44.116419 139893781284672 distribution_utils.py:137] Run horovod and turn off distribution strategy.
decayed_learning_rate_at_crossover_point = 3.856000e-02, adjusted_init_lr = 4.149378e-02
I0321 13:28:44.117624 140134327568192 distribution_utils.py:137] Run horovod and turn off distribution strategy.
decayed_learning_rate_at_crossover_point = 3.856000e-02, adjusted_init_lr = 4.149378e-02
I0321 13:28:44.134938 140058691233600 distribution_utils.py:137] Run horovod and turn off distribution strategy.
I0321 13:28:44.135191 140058691233600 base_trainer.py:262]  20230321 13:28:44 Initialize training
I0321 13:28:44.135276 140058691233600 base_trainer.py:264] 	tf.app.flags.FLAGS:
I0321 13:28:44.135550 140058691233600 base_trainer.py:266] 	?                        = False
I0321 13:28:44.135623 140058691233600 base_trainer.py:266] 	alsologtostderr          = False
I0321 13:28:44.135694 140058691233600 base_trainer.py:266] 	aux_mlp_dims             = ['100', '50']
I0321 13:28:44.135762 140058691233600 base_trainer.py:266] 	batch_size               = 8192
I0321 13:28:44.135828 140058691233600 base_trainer.py:266] 	bds                      = test_benchmark
I0321 13:28:44.135893 140058691233600 base_trainer.py:266] 	benchmark                = True
I0321 13:28:44.135959 140058691233600 base_trainer.py:266] 	benchmark_log_dir        = None
I0321 13:28:44.136023 140058691233600 base_trainer.py:266] 	benchmark_logger_type    = BaseBenchmarkLogger
I0321 13:28:44.136088 140058691233600 base_trainer.py:266] 	benchmark_test_id        = None
I0321 13:28:44.136153 140058691233600 base_trainer.py:266] 	bert_config_file         = None
I0321 13:28:44.136218 140058691233600 base_trainer.py:266] 	bigquery_data_set        = test_benchmark
I0321 13:28:44.136291 140058691233600 base_trainer.py:266] 	bigquery_metric_table    = benchmark_metric
I0321 13:28:44.136356 140058691233600 base_trainer.py:266] 	bigquery_run_status_table= benchmark_run_status
I0321 13:28:44.136420 140058691233600 base_trainer.py:266] 	bigquery_run_table       = benchmark_run
I0321 13:28:44.136485 140058691233600 base_trainer.py:266] 	black_list               = None
I0321 13:28:44.136550 140058691233600 base_trainer.py:266] 	bld                      = None
I0321 13:28:44.136615 140058691233600 base_trainer.py:266] 	bmt                      = benchmark_metric
I0321 13:28:44.136679 140058691233600 base_trainer.py:266] 	brst                     = benchmark_run_status
I0321 13:28:44.136744 140058691233600 base_trainer.py:266] 	brt                      = benchmark_run
I0321 13:28:44.136808 140058691233600 base_trainer.py:266] 	bs                       = 8192
I0321 13:28:44.136873 140058691233600 base_trainer.py:266] 	bti                      = None
I0321 13:28:44.136939 140058691233600 base_trainer.py:266] 	clean                    = False
I0321 13:28:44.137004 140058691233600 base_trainer.py:266] 	conf_file                = /workspaces/Deepray2/conf/dp.yaml
I0321 13:28:44.137069 140058691233600 base_trainer.py:266] 	d                        = 2023-03-20
I0321 13:28:44.137135 140058691233600 base_trainer.py:266] 	data_dir                 = /tmp/movielens-data/
I0321 13:28:44.137200 140058691233600 base_trainer.py:266] 	dataset                  = None
I0321 13:28:44.137264 140058691233600 base_trainer.py:266] 	date                     = 2023-03-20
I0321 13:28:44.137329 140058691233600 base_trainer.py:266] 	distribution_strategy    = mirrored
I0321 13:28:44.137393 140058691233600 base_trainer.py:266] 	dllog_path               = deepray_dllogger.json
I0321 13:28:44.137458 140058691233600 base_trainer.py:266] 	do_lower_case            = True
I0321 13:28:44.137523 140058691233600 base_trainer.py:266] 	download_if_missing      = True
I0321 13:28:44.137591 140058691233600 base_trainer.py:266] 	dropout_rate             = -1.0
I0321 13:28:44.137656 140058691233600 base_trainer.py:266] 	ds                       = mirrored
I0321 13:28:44.137721 140058691233600 base_trainer.py:266] 	dt                       = fp32
I0321 13:28:44.137785 140058691233600 base_trainer.py:266] 	dtype                    = fp32
I0321 13:28:44.137850 140058691233600 base_trainer.py:266] 	e                        = None
I0321 13:28:44.137915 140058691233600 base_trainer.py:266] 	embedding_dim            = 16
I0321 13:28:44.137980 140058691233600 base_trainer.py:266] 	enable_xla               = True
I0321 13:28:44.138045 140058691233600 base_trainer.py:266] 	end_date                 = None
I0321 13:28:44.138110 140058691233600 base_trainer.py:266] 	epochs                   = 3
I0321 13:28:44.138175 140058691233600 base_trainer.py:266] 	eval_batch_size          = None
I0321 13:28:44.138239 140058691233600 base_trainer.py:266] 	eval_script              = None
I0321 13:28:44.138303 140058691233600 base_trainer.py:266] 	feature_map              = /workspaces/Deepray2/business/data/feature_map.csv
I0321 13:28:44.138369 140058691233600 base_trainer.py:266] 	fine_tune                = None
I0321 13:28:44.138433 140058691233600 base_trainer.py:266] 	fp16_implementation      = keras
I0321 13:28:44.138498 140058691233600 base_trainer.py:266] 	gcp_project              = None
I0321 13:28:44.138563 140058691233600 base_trainer.py:266] 	gp                       = None
I0321 13:28:44.138628 140058691233600 base_trainer.py:266] 	h                        = False
I0321 13:28:44.138692 140058691233600 base_trainer.py:266] 	hbm_oom_exit             = True
I0321 13:28:44.138757 140058691233600 base_trainer.py:266] 	help                     = False
I0321 13:28:44.138822 140058691233600 base_trainer.py:266] 	helpfull                 = False
I0321 13:28:44.138887 140058691233600 base_trainer.py:266] 	helpshort                = False
I0321 13:28:44.138952 140058691233600 base_trainer.py:266] 	helpxml                  = False
I0321 13:28:44.139017 140058691233600 base_trainer.py:266] 	hub_module_url           = None
I0321 13:28:44.139081 140058691233600 base_trainer.py:266] 	init_checkpoint          = 
I0321 13:28:44.139146 140058691233600 base_trainer.py:266] 	init_weights             = 
I0321 13:28:44.139210 140058691233600 base_trainer.py:266] 	input_meta_data_path     = None
I0321 13:28:44.139275 140058691233600 base_trainer.py:266] 	interleave_block         = 2
I0321 13:28:44.139339 140058691233600 base_trainer.py:266] 	interleave_cycle         = 16
I0321 13:28:44.139405 140058691233600 base_trainer.py:266] 	keras_use_ctl            = True
I0321 13:28:44.139471 140058691233600 base_trainer.py:266] 	label                    = ['click', 'play']
I0321 13:28:44.139539 140058691233600 base_trainer.py:266] 	learning_rate            = 0.01
I0321 13:28:44.139604 140058691233600 base_trainer.py:266] 	log_dir                  = 
I0321 13:28:44.139668 140058691233600 base_trainer.py:266] 	log_steps                = 100
I0321 13:28:44.139734 140058691233600 base_trainer.py:266] 	logger_levels            = {}
I0321 13:28:44.139799 140058691233600 base_trainer.py:266] 	logtostderr              = False
I0321 13:28:44.139864 140058691233600 base_trainer.py:266] 	loss_scale               = None
I0321 13:28:44.139929 140058691233600 base_trainer.py:266] 	ls                       = None
I0321 13:28:44.139994 140058691233600 base_trainer.py:266] 	max_answer_length        = 30
I0321 13:28:44.140058 140058691233600 base_trainer.py:266] 	max_seq_length           = 90
I0321 13:28:44.140122 140058691233600 base_trainer.py:266] 	md                       = /results/tf_training_amazon_books_2014_dien_fp16_gbs32768_230321132836
I0321 13:28:44.140187 140058691233600 base_trainer.py:266] 	mode                     = train_and_predict
I0321 13:28:44.140251 140058691233600 base_trainer.py:266] 	model_dir                = /results/tf_training_amazon_books_2014_dien_fp16_gbs32768_230321132836
I0321 13:28:44.140323 140058691233600 base_trainer.py:266] 	model_export_path        = /results/tf_training_amazon_books_2014_dien_fp16_gbs32768_230321132836
I0321 13:28:44.140387 140058691233600 base_trainer.py:266] 	model_type               = bert
I0321 13:28:44.140452 140058691233600 base_trainer.py:266] 	n_best_size              = 20
I0321 13:28:44.140517 140058691233600 base_trainer.py:266] 	neg_sample_rate          = 0.0
I0321 13:28:44.140582 140058691233600 base_trainer.py:266] 	ng                       = 4
I0321 13:28:44.140647 140058691233600 base_trainer.py:266] 	num_accumulation_steps   = 1
I0321 13:28:44.140712 140058691233600 base_trainer.py:266] 	num_gpus                 = 4
I0321 13:28:44.140777 140058691233600 base_trainer.py:266] 	num_train_examples       = 11932672
I0321 13:28:44.140842 140058691233600 base_trainer.py:266] 	only_check_args          = False
I0321 13:28:44.140907 140058691233600 base_trainer.py:266] 	op_conversion_fallback_to_while_loop= True
I0321 13:28:44.140974 140058691233600 base_trainer.py:266] 	optimizer_type           = adam
I0321 13:28:44.141039 140058691233600 base_trainer.py:266] 	parallel_parse           = None
I0321 13:28:44.141103 140058691233600 base_trainer.py:266] 	parallel_reads_per_file  = None
I0321 13:28:44.141168 140058691233600 base_trainer.py:266] 	pdb                      = False
I0321 13:28:44.141233 140058691233600 base_trainer.py:266] 	pdb_post_mortem          = False
I0321 13:28:44.141298 140058691233600 base_trainer.py:266] 	prebatch                 = 5
I0321 13:28:44.141362 140058691233600 base_trainer.py:266] 	predict_batch_size       = 8
I0321 13:28:44.141427 140058691233600 base_trainer.py:266] 	predict_file             = None
I0321 13:28:44.141492 140058691233600 base_trainer.py:266] 	prefetch_buffer          = 16
I0321 13:28:44.141557 140058691233600 base_trainer.py:266] 	profile_file             = None
I0321 13:28:44.141622 140058691233600 base_trainer.py:266] 	r                        = None
I0321 13:28:44.141687 140058691233600 base_trainer.py:266] 	random_seed              = 12345
I0321 13:28:44.141752 140058691233600 base_trainer.py:266] 	restore_date             = None
I0321 13:28:44.141816 140058691233600 base_trainer.py:266] 	run_eagerly              = False
I0321 13:28:44.141881 140058691233600 base_trainer.py:266] 	run_with_pdb             = False
I0321 13:28:44.141946 140058691233600 base_trainer.py:266] 	run_with_profiling       = False
I0321 13:28:44.142010 140058691233600 base_trainer.py:266] 	runtime_oom_exit         = True
I0321 13:28:44.142076 140058691233600 base_trainer.py:266] 	s                        = None
I0321 13:28:44.142140 140058691233600 base_trainer.py:266] 	save_checkpoint_steps    = 1000
I0321 13:28:44.142205 140058691233600 base_trainer.py:266] 	scale_loss               = False
I0321 13:28:44.142270 140058691233600 base_trainer.py:266] 	showprefixforinfo        = True
I0321 13:28:44.142335 140058691233600 base_trainer.py:266] 	shuffle_buffer           = None
I0321 13:28:44.142400 140058691233600 base_trainer.py:266] 	stage_one_mlp_dims       = ['200']
I0321 13:28:44.142466 140058691233600 base_trainer.py:266] 	stage_two_mlp_dims       = ['200', '80']
I0321 13:28:44.142531 140058691233600 base_trainer.py:266] 	start_date               = None
I0321 13:28:44.142596 140058691233600 base_trainer.py:266] 	stderrthreshold          = fatal
I0321 13:28:44.142660 140058691233600 base_trainer.py:266] 	steps_per_summary        = 1
I0321 13:28:44.142725 140058691233600 base_trainer.py:266] 	task_index               = -1
I0321 13:28:44.142790 140058691233600 base_trainer.py:266] 	te                       = 3
I0321 13:28:44.142855 140058691233600 base_trainer.py:266] 	test_random_seed         = 301
I0321 13:28:44.142920 140058691233600 base_trainer.py:266] 	test_randomize_ordering_seed= 
I0321 13:28:44.142984 140058691233600 base_trainer.py:266] 	test_srcdir              = 
I0321 13:28:44.143049 140058691233600 base_trainer.py:266] 	test_tmpdir              = /tmp/absl_testing
I0321 13:28:44.143113 140058691233600 base_trainer.py:266] 	train_data               = /workspaces/dataset/amazon_books_2014/tfrecord_path/
I0321 13:28:44.143178 140058691233600 base_trainer.py:266] 	use_cprofile_for_profiling= True
I0321 13:28:44.143244 140058691233600 base_trainer.py:266] 	use_dynamic_embedding    = False
I0321 13:28:44.143309 140058691233600 base_trainer.py:266] 	use_fp16                 = True
I0321 13:28:44.143373 140058691233600 base_trainer.py:266] 	use_horovod              = True
I0321 13:28:44.143438 140058691233600 base_trainer.py:266] 	v                        = 0
I0321 13:28:44.143503 140058691233600 base_trainer.py:266] 	verbose_logging          = False
I0321 13:28:44.143568 140058691233600 base_trainer.py:266] 	verbosity                = 0
I0321 13:28:44.143632 140058691233600 base_trainer.py:266] 	vocab_file               = None
I0321 13:28:44.143697 140058691233600 base_trainer.py:266] 	warmup_path              = None
I0321 13:28:44.143762 140058691233600 base_trainer.py:266] 	white_list               = None
I0321 13:28:44.143827 140058691233600 base_trainer.py:266] 	worker_hosts             = None
I0321 13:28:44.143892 140058691233600 base_trainer.py:266] 	xml_output_file          = 
decayed_learning_rate_at_crossover_point = 3.856000e-02, adjusted_init_lr = 4.149378e-02
2023-03-21 13:28:44.640951: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.

If you want XLA:CPU, do one of the following:

 - set the TF_XLA_FLAGS to include "--tf_xla_cpu_global_jit", or
 - set cpu_global_jit to true on this session's OptimizerOptions, or
 - use experimental_jit_scope, or
 - use tf.function(jit_compile=True).

To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a
proper command-line flag, not via TF_XLA_FLAGS).
2023-03-21 13:28:44.645405: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.

If you want XLA:CPU, do one of the following:

 - set the TF_XLA_FLAGS to include "--tf_xla_cpu_global_jit", or
 - set cpu_global_jit to true on this session's OptimizerOptions, or
 - use experimental_jit_scope, or
 - use tf.function(jit_compile=True).

To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a
proper command-line flag, not via TF_XLA_FLAGS).
2023-03-21 13:28:44.659404: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.

If you want XLA:CPU, do one of the following:

 - set the TF_XLA_FLAGS to include "--tf_xla_cpu_global_jit", or
 - set cpu_global_jit to true on this session's OptimizerOptions, or
 - use experimental_jit_scope, or
 - use tf.function(jit_compile=True).

To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a
proper command-line flag, not via TF_XLA_FLAGS).
2023-03-21 13:28:44.676332: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1750] (One-time warning): Not using XLA:CPU for cluster.

If you want XLA:CPU, do one of the following:

 - set the TF_XLA_FLAGS to include "--tf_xla_cpu_global_jit", or
 - set cpu_global_jit to true on this session's OptimizerOptions, or
 - use experimental_jit_scope, or
 - use tf.function(jit_compile=True).

To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a
proper command-line flag, not via TF_XLA_FLAGS).
2023-03-21 13:29:06.555065: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f5f2149b0c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-03-21 13:29:06.555115: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0
2023-03-21 13:29:06.702751: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-03-21 13:29:07.256896: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f70b149b0d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-03-21 13:29:07.256956: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0
2023-03-21 13:29:07.370590: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f40054acf20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-03-21 13:29:07.370652: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0
2023-03-21 13:29:07.390098: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f38cd4a5610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-03-21 13:29:07.390151: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0
2023-03-21 13:29:07.401511: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-03-21 13:29:07.514599: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-03-21 13:29:07.534599: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-03-21 13:29:07.784138: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200
2023-03-21 13:29:08.167005: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-03-21 13:29:08.337348: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200
2023-03-21 13:29:08.479329: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200
2023-03-21 13:29:08.537665: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200
2023-03-21 13:29:08.732083: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-03-21 13:29:08.851863: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-03-21 13:29:08.925894: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Bootstrap : Using bond0.2074:10.0.74.1<0>
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO NET/IB : No device found.
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO NET/Socket : Using [0]bond0.2074:10.0.74.1<0> [1]lxcbr0:10.0.3.1<0> [2]bond0:fe80::c494:eeff:fe63:7b0c%bond0<0>
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Using network Socket
NCCL version 2.9.9+cuda11.3
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Bootstrap : Using bond0.2074:10.0.74.1<0>
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Bootstrap : Using bond0.2074:10.0.74.1<0>
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Bootstrap : Using bond0.2074:10.0.74.1<0>
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO NET/IB : No device found.
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO NET/IB : No device found.
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO NET/IB : No device found.
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO NET/Socket : Using [0]bond0.2074:10.0.74.1<0> [1]lxcbr0:10.0.3.1<0> [2]bond0:fe80::c494:eeff:fe63:7b0c%bond0<0>
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Using network Socket
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO NET/Socket : Using [0]bond0.2074:10.0.74.1<0> [1]lxcbr0:10.0.3.1<0> [2]bond0:fe80::c494:eeff:fe63:7b0c%bond0<0>
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Using network Socket
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO NET/Socket : Using [0]bond0.2074:10.0.74.1<0> [1]lxcbr0:10.0.3.1<0> [2]bond0:fe80::c494:eeff:fe63:7b0c%bond0<0>
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Using network Socket
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Channel 00/02 :    0   1   2   3
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Channel 01/02 :    0   1   2   3
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Setting affinity for GPU 3 to fff0,00fff000
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Setting affinity for GPU 1 to 0f,ff000fff
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Setting affinity for GPU 2 to fff0,00fff000
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Channel 00 : 3[af000] -> 0[18000] via direct shared memory
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Channel 01 : 3[af000] -> 0[18000] via direct shared memory
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Channel 00 : 2[86000] -> 3[af000] via direct shared memory
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Channel 00 : 1[3b000] -> 2[86000] via direct shared memory
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Channel 00 : 0[18000] -> 1[3b000] via direct shared memory
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Channel 01 : 2[86000] -> 3[af000] via direct shared memory
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Channel 01 : 1[3b000] -> 2[86000] via direct shared memory
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Channel 01 : 0[18000] -> 1[3b000] via direct shared memory
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Connected all rings
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Connected all rings
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Connected all rings
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Connected all rings
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Channel 00 : 3[af000] -> 2[86000] via direct shared memory
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Channel 01 : 3[af000] -> 2[86000] via direct shared memory
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Channel 00 : 2[86000] -> 1[3b000] via direct shared memory
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Channel 00 : 1[3b000] -> 0[18000] via direct shared memory
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Channel 01 : 2[86000] -> 1[3b000] via direct shared memory
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Channel 01 : 1[3b000] -> 0[18000] via direct shared memory
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Connected all trees
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO comm 0x7f6044345000 rank 0 nranks 4 cudaDev 0 busId 18000 - Init COMPLETE
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO Connected all trees
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
op-arsenaldevk8s-gpu01:194990:195376 [3] NCCL INFO comm 0x7f3a2c342540 rank 3 nranks 4 cudaDev 3 busId af000 - Init COMPLETE
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO Connected all trees
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
op-arsenaldevk8s-gpu01:194989:195377 [2] NCCL INFO comm 0x7f722c341f90 rank 2 nranks 4 cudaDev 2 busId 86000 - Init COMPLETE
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO Connected all trees
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
op-arsenaldevk8s-gpu01:194988:195378 [1] NCCL INFO comm 0x7f415c341e90 rank 1 nranks 4 cudaDev 1 busId 3b000 - Init COMPLETE
op-arsenaldevk8s-gpu01:194987:195375 [0] NCCL INFO Launch mode Parallel
/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_util.py:436: RuntimeWarning: overflow encountered in cast
  nparray = values.astype(dtype.as_numpy_dtype)
I0321 13:29:23.503661 140058691233600 base_trainer.py:769] Step: 1 Lr 0.00115261 Loss scale 32768
I0321 13:29:23.503899 140058691233600 base_trainer.py:770] Train Step: 1/1000 / time=38.775 sec
I0321 13:29:23.503981 140058691233600 base_trainer.py:771] Perf 842.78 samples/s
I0321 13:29:39.214720 140058691233600 base_trainer.py:769] Step: 2 Lr 0.00230521 Loss scale 32768
I0321 13:29:39.214977 140058691233600 base_trainer.py:770] Train Step: 2/1000 / time=15.709 sec
I0321 13:29:39.215063 140058691233600 base_trainer.py:771] Perf 2085.55 samples/s
I0321 13:29:39.296554 140058691233600 base_trainer.py:769] Step: 3 Lr 0.00345781 Loss scale 32768
I0321 13:29:39.296782 140058691233600 base_trainer.py:770] Train Step: 3/1000 / time=0.080 sec
I0321 13:29:39.296869 140058691233600 base_trainer.py:771] Perf 399931.06 samples/s
I0321 13:29:39.349445 140058691233600 base_trainer.py:769] Step: 4 Lr 0.00461042 Loss scale 32768
I0321 13:29:39.349663 140058691233600 base_trainer.py:770] Train Step: 4/1000 / time=0.051 sec
I0321 13:29:39.349741 140058691233600 base_trainer.py:771] Perf 618240.52 samples/s
I0321 13:29:39.403187 140058691233600 base_trainer.py:769] Step: 5 Lr 0.00576302 Loss scale 32768
I0321 13:29:39.403406 140058691233600 base_trainer.py:770] Train Step: 5/1000 / time=0.052 sec
I0321 13:29:39.403493 140058691233600 base_trainer.py:771] Perf 610521.22 samples/s
I0321 13:29:39.458152 140058691233600 base_trainer.py:769] Step: 6 Lr 0.00691563 Loss scale 32768
I0321 13:29:39.458370 140058691233600 base_trainer.py:770] Train Step: 6/1000 / time=0.053 sec
I0321 13:29:39.458449 140058691233600 base_trainer.py:771] Perf 595866.54 samples/s
I0321 13:29:39.514154 140058691233600 base_trainer.py:769] Step: 7 Lr 0.00806823 Loss scale 32768
I0321 13:29:39.514365 140058691233600 base_trainer.py:770] Train Step: 7/1000 / time=0.054 sec
I0321 13:29:39.514443 140058691233600 base_trainer.py:771] Perf 584222.38 samples/s
I0321 13:29:39.568910 140058691233600 base_trainer.py:769] Step: 8 Lr 0.00922084 Loss scale 32768
I0321 13:29:39.569134 140058691233600 base_trainer.py:770] Train Step: 8/1000 / time=0.053 sec
I0321 13:29:39.569222 140058691233600 base_trainer.py:771] Perf 600641.04 samples/s
I0321 13:29:39.622317 140058691233600 base_trainer.py:769] Step: 9 Lr 0.0103734 Loss scale 32768
I0321 13:29:39.622526 140058691233600 base_trainer.py:770] Train Step: 9/1000 / time=0.051 sec
I0321 13:29:39.622602 140058691233600 base_trainer.py:771] Perf 611571.16 samples/s
I0321 13:29:39.675326 140058691233600 base_trainer.py:769] Step: 10 Lr 0.0115261 Loss scale 32768
I0321 13:29:39.675546 140058691233600 base_trainer.py:770] Train Step: 10/1000 / time=0.051 sec
I0321 13:29:39.675635 140058691233600 base_trainer.py:771] Perf 619306.58 samples/s
I0321 13:29:39.729140 140058691233600 base_trainer.py:769] Step: 11 Lr 0.0126787 Loss scale 32768
I0321 13:29:39.729367 140058691233600 base_trainer.py:770] Train Step: 11/1000 / time=0.052 sec
I0321 13:29:39.729454 140058691233600 base_trainer.py:771] Perf 609109.72 samples/s
I0321 13:29:39.783348 140058691233600 base_trainer.py:769] Step: 12 Lr 0.0138313 Loss scale 32768
I0321 13:29:39.783582 140058691233600 base_trainer.py:770] Train Step: 12/1000 / time=0.052 sec
I0321 13:29:39.783672 140058691233600 base_trainer.py:771] Perf 604395.31 samples/s
I0321 13:29:39.836161 140058691233600 base_trainer.py:769] Step: 13 Lr 0.0149839 Loss scale 32768
I0321 13:29:39.836391 140058691233600 base_trainer.py:770] Train Step: 13/1000 / time=0.051 sec
I0321 13:29:39.836476 140058691233600 base_trainer.py:771] Perf 620987.45 samples/s
I0321 13:29:39.889646 140058691233600 base_trainer.py:769] Step: 14 Lr 0.0161365 Loss scale 32768
I0321 13:29:39.889867 140058691233600 base_trainer.py:770] Train Step: 14/1000 / time=0.051 sec
I0321 13:29:39.889955 140058691233600 base_trainer.py:771] Perf 612168.55 samples/s
I0321 13:29:39.943395 140058691233600 base_trainer.py:769] Step: 15 Lr 0.0172891 Loss scale 32768
I0321 13:29:39.943617 140058691233600 base_trainer.py:770] Train Step: 15/1000 / time=0.052 sec
I0321 13:29:39.943713 140058691233600 base_trainer.py:771] Perf 609947.26 samples/s
I0321 13:29:39.997017 140058691233600 base_trainer.py:769] Step: 16 Lr 0.0184417 Loss scale 32768
I0321 13:29:39.997248 140058691233600 base_trainer.py:770] Train Step: 16/1000 / time=0.052 sec
I0321 13:29:39.997341 140058691233600 base_trainer.py:771] Perf 611330.64 samples/s
I0321 13:29:40.048773 140058691233600 base_trainer.py:769] Step: 17 Lr 0.0195943 Loss scale 32768
I0321 13:29:40.048996 140058691233600 base_trainer.py:770] Train Step: 17/1000 / time=0.050 sec
I0321 13:29:40.049082 140058691233600 base_trainer.py:771] Perf 633318.03 samples/s
I0321 13:29:40.101402 140058691233600 base_trainer.py:769] Step: 18 Lr 0.0207469 Loss scale 32768
I0321 13:29:40.101634 140058691233600 base_trainer.py:770] Train Step: 18/1000 / time=0.051 sec
I0321 13:29:40.101720 140058691233600 base_trainer.py:771] Perf 622603.40 samples/s
I0321 13:29:40.154217 140058691233600 base_trainer.py:769] Step: 19 Lr 0.0218995 Loss scale 32768
I0321 13:29:40.154434 140058691233600 base_trainer.py:770] Train Step: 19/1000 / time=0.051 sec
I0321 13:29:40.154517 140058691233600 base_trainer.py:771] Perf 619775.33 samples/s
I0321 13:29:40.206944 140058691233600 base_trainer.py:769] Step: 20 Lr 0.0230521 Loss scale 32768
I0321 13:29:40.207169 140058691233600 base_trainer.py:770] Train Step: 20/1000 / time=0.051 sec
I0321 13:29:40.207252 140058691233600 base_trainer.py:771] Perf 622432.46 samples/s
I0321 13:29:40.262216 140058691233600 base_trainer.py:769] Step: 21 Lr 0.0242047 Loss scale 32768
I0321 13:29:40.262441 140058691233600 base_trainer.py:770] Train Step: 21/1000 / time=0.053 sec
I0321 13:29:40.262526 140058691233600 base_trainer.py:771] Perf 592583.70 samples/s
I0321 13:29:40.317893 140058691233600 base_trainer.py:769] Step: 22 Lr 0.0253573 Loss scale 32768
I0321 13:29:40.318119 140058691233600 base_trainer.py:770] Train Step: 22/1000 / time=0.054 sec
I0321 13:29:40.318201 140058691233600 base_trainer.py:771] Perf 588669.62 samples/s
I0321 13:29:40.375149 140058691233600 base_trainer.py:769] Step: 23 Lr 0.0265099 Loss scale 32768
I0321 13:29:40.375366 140058691233600 base_trainer.py:770] Train Step: 23/1000 / time=0.055 sec
I0321 13:29:40.375443 140058691233600 base_trainer.py:771] Perf 571305.57 samples/s
I0321 13:29:40.428901 140058691233600 base_trainer.py:769] Step: 24 Lr 0.0276625 Loss scale 32768
I0321 13:29:40.429116 140058691233600 base_trainer.py:770] Train Step: 24/1000 / time=0.052 sec
I0321 13:29:40.429195 140058691233600 base_trainer.py:771] Perf 610034.66 samples/s
I0321 13:29:40.481929 140058691233600 base_trainer.py:769] Step: 25 Lr 0.0288151 Loss scale 32768
I0321 13:29:40.482146 140058691233600 base_trainer.py:770] Train Step: 25/1000 / time=0.051 sec
I0321 13:29:40.482232 140058691233600 base_trainer.py:771] Perf 618629.15 samples/s
I0321 13:29:40.535710 140058691233600 base_trainer.py:769] Step: 26 Lr 0.0299677 Loss scale 32768
I0321 13:29:40.535929 140058691233600 base_trainer.py:770] Train Step: 26/1000 / time=0.052 sec
I0321 13:29:40.536008 140058691233600 base_trainer.py:771] Perf 608910.73 samples/s
I0321 13:29:40.592173 140058691233600 base_trainer.py:769] Step: 27 Lr 0.0311203 Loss scale 32768
I0321 13:29:40.592498 140058691233600 base_trainer.py:770] Train Step: 27/1000 / time=0.054 sec
I0321 13:29:40.592584 140058691233600 base_trainer.py:771] Perf 581879.78 samples/s
I0321 13:29:40.648705 140058691233600 base_trainer.py:769] Step: 28 Lr 0.0322729 Loss scale 32768
I0321 13:29:40.648936 140058691233600 base_trainer.py:770] Train Step: 28/1000 / time=0.054 sec
I0321 13:29:40.649024 140058691233600 base_trainer.py:771] Perf 578742.50 samples/s
I0321 13:29:40.701040 140058691233600 base_trainer.py:769] Step: 29 Lr 0.0334255 Loss scale 32768
I0321 13:29:40.701265 140058691233600 base_trainer.py:770] Train Step: 29/1000 / time=0.050 sec
I0321 13:29:40.701351 140058691233600 base_trainer.py:771] Perf 625975.76 samples/s
I0321 13:29:40.754983 140058691233600 base_trainer.py:769] Step: 30 Lr 0.0345781 Loss scale 32768
I0321 13:29:40.755199 140058691233600 base_trainer.py:770] Train Step: 30/1000 / time=0.052 sec
I0321 13:29:40.755279 140058691233600 base_trainer.py:771] Perf 607056.50 samples/s
I0321 13:29:40.811296 140058691233600 base_trainer.py:769] Step: 31 Lr 0.0357308 Loss scale 32768
I0321 13:29:40.811647 140058691233600 base_trainer.py:770] Train Step: 31/1000 / time=0.054 sec
I0321 13:29:40.811755 140058691233600 base_trainer.py:771] Perf 584968.78 samples/s
I0321 13:29:40.870358 140058691233600 base_trainer.py:769] Step: 32 Lr 0.0368834 Loss scale 32768
I0321 13:29:40.870721 140058691233600 base_trainer.py:770] Train Step: 32/1000 / time=0.056 sec
I0321 13:29:40.870872 140058691233600 base_trainer.py:771] Perf 557142.11 samples/s
I0321 13:29:40.928035 140058691233600 base_trainer.py:769] Step: 33 Lr 0.038036 Loss scale 32768
I0321 13:29:40.928334 140058691233600 base_trainer.py:770] Train Step: 33/1000 / time=0.055 sec
I0321 13:29:40.928428 140058691233600 base_trainer.py:771] Perf 565986.34 samples/s
I0321 13:29:40.986312 140058691233600 base_trainer.py:769] Step: 34 Lr 0.0391886 Loss scale 32768
I0321 13:29:40.986544 140058691233600 base_trainer.py:770] Train Step: 34/1000 / time=0.056 sec
I0321 13:29:40.986635 140058691233600 base_trainer.py:771] Perf 560228.37 samples/s
I0321 13:29:41.039054 140058691233600 base_trainer.py:769] Step: 35 Lr 0.0403412 Loss scale 32768
I0321 13:29:41.039278 140058691233600 base_trainer.py:770] Train Step: 35/1000 / time=0.051 sec
I0321 13:29:41.039366 140058691233600 base_trainer.py:771] Perf 621465.85 samples/s
I0321 13:29:41.093186 140058691233600 base_trainer.py:769] Step: 36 Lr 0.0414938 Loss scale 32768
I0321 13:29:41.093505 140058691233600 base_trainer.py:770] Train Step: 36/1000 / time=0.050 sec
I0321 13:29:41.093597 140058691233600 base_trainer.py:771] Perf 629354.19 samples/s
I0321 13:29:41.254972 140058691233600 base_trainer.py:769] Step: 37 Lr 0.0414523 Loss scale 32768
I0321 13:29:41.255199 140058691233600 base_trainer.py:770] Train Step: 37/1000 / time=0.159 sec
I0321 13:29:41.255286 140058691233600 base_trainer.py:771] Perf 201412.84 samples/s
I0321 13:29:41.316589 140058691233600 base_trainer.py:769] Step: 38 Lr 0.0414108 Loss scale 32768
I0321 13:29:41.316828 140058691233600 base_trainer.py:770] Train Step: 38/1000 / time=0.059 sec
I0321 13:29:41.316915 140058691233600 base_trainer.py:771] Perf 530976.61 samples/s
I0321 13:29:41.475920 140058691233600 base_trainer.py:769] Step: 39 Lr 0.0413693 Loss scale 16384
I0321 13:29:41.476153 140058691233600 base_trainer.py:770] Train Step: 39/1000 / time=0.156 sec
I0321 13:29:41.476244 140058691233600 base_trainer.py:771] Perf 205816.24 samples/s
I0321 13:29:41.532233 140058691233600 base_trainer.py:769] Step: 40 Lr 0.0413278 Loss scale 8192
I0321 13:29:41.532480 140058691233600 base_trainer.py:770] Train Step: 40/1000 / time=0.053 sec
I0321 13:29:41.532570 140058691233600 base_trainer.py:771] Perf 581061.57 samples/s
I0321 13:29:41.588666 140058691233600 base_trainer.py:769] Step: 41 Lr 0.0412863 Loss scale 8192
I0321 13:29:41.588896 140058691233600 base_trainer.py:770] Train Step: 41/1000 / time=0.053 sec
I0321 13:29:41.588977 140058691233600 base_trainer.py:771] Perf 581057.92 samples/s
I0321 13:29:41.645317 140058691233600 base_trainer.py:769] Step: 42 Lr 0.0412448 Loss scale 8192
I0321 13:29:41.645585 140058691233600 base_trainer.py:770] Train Step: 42/1000 / time=0.053 sec
I0321 13:29:41.645709 140058691233600 base_trainer.py:771] Perf 580877.71 samples/s
I0321 13:29:41.698369 140058691233600 base_trainer.py:769] Step: 43 Lr 0.0412033 Loss scale 8192
I0321 13:29:41.698599 140058691233600 base_trainer.py:770] Train Step: 43/1000 / time=0.050 sec
I0321 13:29:41.698685 140058691233600 base_trainer.py:771] Perf 614201.57 samples/s
I0321 13:29:41.750901 140058691233600 base_trainer.py:769] Step: 44 Lr 0.0411618 Loss scale 8192
I0321 13:29:41.751136 140058691233600 base_trainer.py:770] Train Step: 44/1000 / time=0.049 sec
I0321 13:29:41.751224 140058691233600 base_trainer.py:771] Perf 624197.63 samples/s
I0321 13:29:41.805743 140058691233600 base_trainer.py:769] Step: 45 Lr 0.0411203 Loss scale 8192
I0321 13:29:41.805976 140058691233600 base_trainer.py:770] Train Step: 45/1000 / time=0.052 sec
I0321 13:29:41.806062 140058691233600 base_trainer.py:771] Perf 598193.53 samples/s
I0321 13:29:41.863852 140058691233600 base_trainer.py:769] Step: 46 Lr 0.0410788 Loss scale 8192
I0321 13:29:41.864064 140058691233600 base_trainer.py:770] Train Step: 46/1000 / time=0.055 sec
I0321 13:29:41.864142 140058691233600 base_trainer.py:771] Perf 561372.63 samples/s
I0321 13:29:41.917125 140058691233600 base_trainer.py:769] Step: 47 Lr 0.0410373 Loss scale 8192
I0321 13:29:41.917349 140058691233600 base_trainer.py:770] Train Step: 47/1000 / time=0.050 sec
I0321 13:29:41.917436 140058691233600 base_trainer.py:771] Perf 616521.28 samples/s
I0321 13:29:41.971672 140058691233600 base_trainer.py:769] Step: 48 Lr 0.0409958 Loss scale 8192
I0321 13:29:41.971884 140058691233600 base_trainer.py:770] Train Step: 48/1000 / time=0.052 sec
I0321 13:29:41.971970 140058691233600 base_trainer.py:771] Perf 601458.17 samples/s
I0321 13:29:42.026687 140058691233600 base_trainer.py:769] Step: 49 Lr 0.0409544 Loss scale 8192
I0321 13:29:42.026911 140058691233600 base_trainer.py:770] Train Step: 49/1000 / time=0.052 sec
I0321 13:29:42.026995 140058691233600 base_trainer.py:771] Perf 595105.92 samples/s
I0321 13:29:42.079334 140058691233600 base_trainer.py:769] Step: 50 Lr 0.0409129 Loss scale 8192
I0321 13:29:42.079565 140058691233600 base_trainer.py:770] Train Step: 50/1000 / time=0.050 sec
I0321 13:29:42.079658 140058691233600 base_trainer.py:771] Perf 623367.19 samples/s
I0321 13:29:42.131124 140058691233600 base_trainer.py:769] Step: 51 Lr 0.0408714 Loss scale 8192
I0321 13:29:42.131346 140058691233600 base_trainer.py:770] Train Step: 51/1000 / time=0.049 sec
I0321 13:29:42.131426 140058691233600 base_trainer.py:771] Perf 630336.02 samples/s
I0321 13:29:42.188155 140058691233600 base_trainer.py:769] Step: 52 Lr 0.0408299 Loss scale 8192
I0321 13:29:42.188391 140058691233600 base_trainer.py:770] Train Step: 52/1000 / time=0.054 sec
I0321 13:29:42.188486 140058691233600 base_trainer.py:771] Perf 576191.92 samples/s
I0321 13:29:42.242270 140058691233600 base_trainer.py:769] Step: 53 Lr 0.0407884 Loss scale 8192
I0321 13:29:42.242487 140058691233600 base_trainer.py:770] Train Step: 53/1000 / time=0.051 sec
I0321 13:29:42.242578 140058691233600 base_trainer.py:771] Perf 604377.99 samples/s
I0321 13:29:42.297171 140058691233600 base_trainer.py:769] Step: 54 Lr 0.0407469 Loss scale 8192
I0321 13:29:42.297385 140058691233600 base_trainer.py:770] Train Step: 54/1000 / time=0.052 sec
I0321 13:29:42.297465 140058691233600 base_trainer.py:771] Perf 598119.75 samples/s
I0321 13:29:42.350371 140058691233600 base_trainer.py:769] Step: 55 Lr 0.0407054 Loss scale 8192
I0321 13:29:42.350587 140058691233600 base_trainer.py:770] Train Step: 55/1000 / time=0.050 sec
I0321 13:29:42.350666 140058691233600 base_trainer.py:771] Perf 615300.87 samples/s
I0321 13:29:42.403323 140058691233600 base_trainer.py:769] Step: 56 Lr 0.0406639 Loss scale 8192
I0321 13:29:42.403533 140058691233600 base_trainer.py:770] Train Step: 56/1000 / time=0.050 sec
I0321 13:29:42.403612 140058691233600 base_trainer.py:771] Perf 617263.42 samples/s
I0321 13:29:42.459694 140058691233600 base_trainer.py:769] Step: 57 Lr 0.0406224 Loss scale 8192
I0321 13:29:42.459906 140058691233600 base_trainer.py:770] Train Step: 57/1000 / time=0.054 sec
I0321 13:29:42.459984 140058691233600 base_trainer.py:771] Perf 582724.02 samples/s
I0321 13:29:42.511860 140058691233600 base_trainer.py:769] Step: 58 Lr 0.0405809 Loss scale 8192
I0321 13:29:42.512086 140058691233600 base_trainer.py:770] Train Step: 58/1000 / time=0.049 sec
I0321 13:29:42.512171 140058691233600 base_trainer.py:771] Perf 629065.60 samples/s
I0321 13:29:42.564249 140058691233600 base_trainer.py:769] Step: 59 Lr 0.0405394 Loss scale 8192
I0321 13:29:42.564478 140058691233600 base_trainer.py:770] Train Step: 59/1000 / time=0.050 sec
I0321 13:29:42.564563 140058691233600 base_trainer.py:771] Perf 624676.63 samples/s
I0321 13:29:42.615632 140058691233600 base_trainer.py:769] Step: 60 Lr 0.0404979 Loss scale 8192
I0321 13:29:42.615858 140058691233600 base_trainer.py:770] Train Step: 60/1000 / time=0.048 sec
I0321 13:29:42.615947 140058691233600 base_trainer.py:771] Perf 638300.70 samples/s
I0321 13:29:42.668636 140058691233600 base_trainer.py:769] Step: 61 Lr 0.0404564 Loss scale 8192
I0321 13:29:42.668860 140058691233600 base_trainer.py:770] Train Step: 61/1000 / time=0.050 sec
I0321 13:29:42.668944 140058691233600 base_trainer.py:771] Perf 617561.31 samples/s
I0321 13:29:42.722922 140058691233600 base_trainer.py:769] Step: 62 Lr 0.0404149 Loss scale 8192
I0321 13:29:42.723132 140058691233600 base_trainer.py:770] Train Step: 62/1000 / time=0.051 sec
I0321 13:29:42.723211 140058691233600 base_trainer.py:771] Perf 605253.50 samples/s
I0321 13:29:42.777132 140058691233600 base_trainer.py:769] Step: 63 Lr 0.0403734 Loss scale 8192
I0321 13:29:42.777364 140058691233600 base_trainer.py:770] Train Step: 63/1000 / time=0.051 sec
I0321 13:29:42.777453 140058691233600 base_trainer.py:771] Perf 604732.53 samples/s
I0321 13:29:42.830531 140058691233600 base_trainer.py:769] Step: 64 Lr 0.0403319 Loss scale 8192
I0321 13:29:42.830746 140058691233600 base_trainer.py:770] Train Step: 64/1000 / time=0.050 sec
I0321 13:29:42.830824 140058691233600 base_trainer.py:771] Perf 613120.53 samples/s
I0321 13:29:42.883751 140058691233600 base_trainer.py:769] Step: 65 Lr 0.0402905 Loss scale 8192
I0321 13:29:42.883979 140058691233600 base_trainer.py:770] Train Step: 65/1000 / time=0.050 sec
I0321 13:29:42.884062 140058691233600 base_trainer.py:771] Perf 616070.31 samples/s
I0321 13:29:42.934400 140058691233600 base_trainer.py:769] Step: 66 Lr 0.040249 Loss scale 8192
I0321 13:29:42.934636 140058691233600 base_trainer.py:770] Train Step: 66/1000 / time=0.048 sec
I0321 13:29:42.934731 140058691233600 base_trainer.py:771] Perf 648831.71 samples/s
I0321 13:29:42.988653 140058691233600 base_trainer.py:769] Step: 67 Lr 0.0402075 Loss scale 8192
I0321 13:29:42.988882 140058691233600 base_trainer.py:770] Train Step: 67/1000 / time=0.051 sec
I0321 13:29:42.988965 140058691233600 base_trainer.py:771] Perf 602349.20 samples/s
I0321 13:29:43.041531 140058691233600 base_trainer.py:769] Step: 68 Lr 0.040166 Loss scale 8192
I0321 13:29:43.041744 140058691233600 base_trainer.py:770] Train Step: 68/1000 / time=0.050 sec
I0321 13:29:43.041824 140058691233600 base_trainer.py:771] Perf 616839.84 samples/s
I0321 13:29:43.095774 140058691233600 base_trainer.py:769] Step: 69 Lr 0.0401245 Loss scale 8192
I0321 13:29:43.096033 140058691233600 base_trainer.py:770] Train Step: 69/1000 / time=0.051 sec
I0321 13:29:43.096138 140058691233600 base_trainer.py:771] Perf 609262.95 samples/s
I0321 13:29:43.149141 140058691233600 base_trainer.py:769] Step: 70 Lr 0.040083 Loss scale 8192
I0321 13:29:43.149363 140058691233600 base_trainer.py:770] Train Step: 70/1000 / time=0.050 sec
I0321 13:29:43.149453 140058691233600 base_trainer.py:771] Perf 611440.11 samples/s
I0321 13:29:43.201976 140058691233600 base_trainer.py:769] Step: 71 Lr 0.0400415 Loss scale 8192
I0321 13:29:43.202198 140058691233600 base_trainer.py:770] Train Step: 71/1000 / time=0.050 sec
I0321 13:29:43.202285 140058691233600 base_trainer.py:771] Perf 619399.17 samples/s
I0321 13:29:43.256175 140058691233600 base_trainer.py:769] Step: 72 Lr 0.04 Loss scale 8192
I0321 13:29:43.256398 140058691233600 base_trainer.py:770] Train Step: 72/1000 / time=0.052 sec
I0321 13:29:43.256476 140058691233600 base_trainer.py:771] Perf 602933.30 samples/s
I0321 13:29:43.307835 140058691233600 base_trainer.py:769] Step: 73 Lr 0.0399585 Loss scale 8192
I0321 13:29:43.308071 140058691233600 base_trainer.py:770] Train Step: 73/1000 / time=0.049 sec
I0321 13:29:43.308158 140058691233600 base_trainer.py:771] Perf 637591.06 samples/s
I0321 13:29:43.358633 140058691233600 base_trainer.py:769] Step: 74 Lr 0.039917 Loss scale 8192
I0321 13:29:43.358847 140058691233600 base_trainer.py:770] Train Step: 74/1000 / time=0.048 sec
I0321 13:29:43.358924 140058691233600 base_trainer.py:771] Perf 642760.04 samples/s
I0321 13:29:43.416620 140058691233600 base_trainer.py:769] Step: 75 Lr 0.0398755 Loss scale 8192
I0321 13:29:43.416841 140058691233600 base_trainer.py:770] Train Step: 75/1000 / time=0.055 sec
I0321 13:29:43.416930 140058691233600 base_trainer.py:771] Perf 565985.34 samples/s
I0321 13:29:43.470182 140058691233600 base_trainer.py:769] Step: 76 Lr 0.039834 Loss scale 8192
I0321 13:29:43.470411 140058691233600 base_trainer.py:770] Train Step: 76/1000 / time=0.051 sec
I0321 13:29:43.470504 140058691233600 base_trainer.py:771] Perf 613004.50 samples/s
I0321 13:29:43.523591 140058691233600 base_trainer.py:769] Step: 77 Lr 0.0397925 Loss scale 8192
I0321 13:29:43.523805 140058691233600 base_trainer.py:770] Train Step: 77/1000 / time=0.051 sec
I0321 13:29:43.523898 140058691233600 base_trainer.py:771] Perf 610690.67 samples/s
I0321 13:29:43.572364 140058691233600 base_trainer.py:769] Step: 78 Lr 0.039751 Loss scale 8192
I0321 13:29:43.572584 140058691233600 base_trainer.py:770] Train Step: 78/1000 / time=0.046 sec
I0321 13:29:43.572679 140058691233600 base_trainer.py:771] Perf 674616.37 samples/s
I0321 13:29:43.625381 140058691233600 base_trainer.py:769] Step: 79 Lr 0.0397095 Loss scale 8192
I0321 13:29:43.625605 140058691233600 base_trainer.py:770] Train Step: 79/1000 / time=0.050 sec
I0321 13:29:43.625690 140058691233600 base_trainer.py:771] Perf 618713.94 samples/s
I0321 13:29:43.678203 140058691233600 base_trainer.py:769] Step: 80 Lr 0.039668 Loss scale 8192
I0321 13:29:43.678428 140058691233600 base_trainer.py:770] Train Step: 80/1000 / time=0.050 sec
I0321 13:29:43.678503 140058691233600 base_trainer.py:771] Perf 615754.60 samples/s
I0321 13:29:43.731654 140058691233600 base_trainer.py:769] Step: 81 Lr 0.0396266 Loss scale 8192
I0321 13:29:43.731879 140058691233600 base_trainer.py:770] Train Step: 81/1000 / time=0.051 sec
I0321 13:29:43.731966 140058691233600 base_trainer.py:771] Perf 617546.98 samples/s
I0321 13:29:43.787400 140058691233600 base_trainer.py:769] Step: 82 Lr 0.0395851 Loss scale 8192
I0321 13:29:43.787632 140058691233600 base_trainer.py:770] Train Step: 82/1000 / time=0.053 sec
I0321 13:29:43.787715 140058691233600 base_trainer.py:771] Perf 588128.56 samples/s
I0321 13:29:43.839923 140058691233600 base_trainer.py:769] Step: 83 Lr 0.0395436 Loss scale 8192
I0321 13:29:43.840150 140058691233600 base_trainer.py:770] Train Step: 83/1000 / time=0.050 sec
I0321 13:29:43.840234 140058691233600 base_trainer.py:771] Perf 623466.20 samples/s
I0321 13:29:43.892012 140058691233600 base_trainer.py:769] Step: 84 Lr 0.0395021 Loss scale 8192
I0321 13:29:43.892237 140058691233600 base_trainer.py:770] Train Step: 84/1000 / time=0.049 sec
I0321 13:29:43.892354 140058691233600 base_trainer.py:771] Perf 629045.92 samples/s
I0321 13:29:43.944454 140058691233600 base_trainer.py:769] Step: 85 Lr 0.0394606 Loss scale 8192
I0321 13:29:43.944666 140058691233600 base_trainer.py:770] Train Step: 85/1000 / time=0.050 sec
I0321 13:29:43.944745 140058691233600 base_trainer.py:771] Perf 623168.10 samples/s
I0321 13:29:43.995318 140058691233600 base_trainer.py:769] Step: 86 Lr 0.0394191 Loss scale 8192
I0321 13:29:43.995549 140058691233600 base_trainer.py:770] Train Step: 86/1000 / time=0.048 sec
I0321 13:29:43.995639 140058691233600 base_trainer.py:771] Perf 646256.44 samples/s
I0321 13:29:44.048301 140058691233600 base_trainer.py:769] Step: 87 Lr 0.0393776 Loss scale 8192
I0321 13:29:44.048519 140058691233600 base_trainer.py:770] Train Step: 87/1000 / time=0.050 sec
I0321 13:29:44.048611 140058691233600 base_trainer.py:771] Perf 616774.19 samples/s
I0321 13:29:44.101079 140058691233600 base_trainer.py:769] Step: 88 Lr 0.0393361 Loss scale 8192
I0321 13:29:44.101291 140058691233600 base_trainer.py:770] Train Step: 88/1000 / time=0.050 sec
I0321 13:29:44.101370 140058691233600 base_trainer.py:771] Perf 622272.41 samples/s
I0321 13:29:44.153486 140058691233600 base_trainer.py:769] Step: 89 Lr 0.0392946 Loss scale 8192
I0321 13:29:44.153713 140058691233600 base_trainer.py:770] Train Step: 89/1000 / time=0.050 sec
I0321 13:29:44.153794 140058691233600 base_trainer.py:771] Perf 625484.17 samples/s
I0321 13:29:44.207191 140058691233600 base_trainer.py:769] Step: 90 Lr 0.0392531 Loss scale 8192
I0321 13:29:44.207402 140058691233600 base_trainer.py:770] Train Step: 90/1000 / time=0.051 sec
I0321 13:29:44.207479 140058691233600 base_trainer.py:771] Perf 609279.84 samples/s
I0321 13:29:44.260792 140058691233600 base_trainer.py:769] Step: 91 Lr 0.0392116 Loss scale 8192
I0321 13:29:44.261017 140058691233600 base_trainer.py:770] Train Step: 91/1000 / time=0.051 sec
I0321 13:29:44.261089 140058691233600 base_trainer.py:771] Perf 609189.92 samples/s
I0321 13:29:44.313225 140058691233600 base_trainer.py:769] Step: 92 Lr 0.0391701 Loss scale 8192
I0321 13:29:44.313465 140058691233600 base_trainer.py:770] Train Step: 92/1000 / time=0.049 sec
I0321 13:29:44.313554 140058691233600 base_trainer.py:771] Perf 631089.33 samples/s
I0321 13:29:44.371294 140058691233600 base_trainer.py:769] Step: 93 Lr 0.0391286 Loss scale 8192
I0321 13:29:44.371512 140058691233600 base_trainer.py:770] Train Step: 93/1000 / time=0.055 sec
I0321 13:29:44.371603 140058691233600 base_trainer.py:771] Perf 560782.53 samples/s
I0321 13:29:44.427563 140058691233600 base_trainer.py:769] Step: 94 Lr 0.0390871 Loss scale 8192
I0321 13:29:44.427787 140058691233600 base_trainer.py:770] Train Step: 94/1000 / time=0.053 sec
I0321 13:29:44.427883 140058691233600 base_trainer.py:771] Perf 583932.20 samples/s
I0321 13:29:44.479815 140058691233600 base_trainer.py:769] Step: 95 Lr 0.0390456 Loss scale 8192
I0321 13:29:44.480042 140058691233600 base_trainer.py:770] Train Step: 95/1000 / time=0.049 sec
I0321 13:29:44.480129 140058691233600 base_trainer.py:771] Perf 627226.94 samples/s
I0321 13:29:44.533049 140058691233600 base_trainer.py:769] Step: 96 Lr 0.0390042 Loss scale 8192
I0321 13:29:44.533296 140058691233600 base_trainer.py:770] Train Step: 96/1000 / time=0.050 sec
I0321 13:29:44.533379 140058691233600 base_trainer.py:771] Perf 615752.72 samples/s
I0321 13:29:44.585800 140058691233600 base_trainer.py:769] Step: 97 Lr 0.0389627 Loss scale 8192
I0321 13:29:44.586030 140058691233600 base_trainer.py:770] Train Step: 97/1000 / time=0.050 sec
I0321 13:29:44.586117 140058691233600 base_trainer.py:771] Perf 622077.71 samples/s
I0321 13:29:44.642118 140058691233600 base_trainer.py:769] Step: 98 Lr 0.0389212 Loss scale 8192
I0321 13:29:44.642367 140058691233600 base_trainer.py:770] Train Step: 98/1000 / time=0.053 sec
I0321 13:29:44.642459 140058691233600 base_trainer.py:771] Perf 584309.00 samples/s
I0321 13:29:44.693735 140058691233600 base_trainer.py:769] Step: 99 Lr 0.0388797 Loss scale 8192
I0321 13:29:44.693952 140058691233600 base_trainer.py:770] Train Step: 99/1000 / time=0.049 sec
I0321 13:29:44.694029 140058691233600 base_trainer.py:771] Perf 629105.84 samples/s
I0321 13:29:44.747328 140058691233600 base_trainer.py:769] Step: 100 Lr 0.0388382 Loss scale 8192
I0321 13:29:44.747547 140058691233600 base_trainer.py:770] Train Step: 100/1000 / time=0.051 sec
I0321 13:29:44.747632 140058691233600 base_trainer.py:771] Perf 613124.17 samples/s
I0321 13:29:44.799989 140058691233600 base_trainer.py:769] Step: 101 Lr 0.0387967 Loss scale 8192
I0321 13:29:44.800214 140058691233600 base_trainer.py:770] Train Step: 101/1000 / time=0.050 sec
I0321 13:29:44.800314 140058691233600 base_trainer.py:771] Perf 622225.69 samples/s
I0321 13:29:44.853204 140058691233600 base_trainer.py:769] Step: 102 Lr 0.0387552 Loss scale 8192
I0321 13:29:44.853429 140058691233600 base_trainer.py:770] Train Step: 102/1000 / time=0.050 sec
I0321 13:29:44.853513 140058691233600 base_trainer.py:771] Perf 616305.74 samples/s
I0321 13:29:44.906529 140058691233600 base_trainer.py:769] Step: 103 Lr 0.0387137 Loss scale 8192
I0321 13:29:44.906750 140058691233600 base_trainer.py:770] Train Step: 103/1000 / time=0.050 sec
I0321 13:29:44.906825 140058691233600 base_trainer.py:771] Perf 613846.28 samples/s
I0321 13:29:44.959774 140058691233600 base_trainer.py:769] Step: 104 Lr 0.0386722 Loss scale 8192
I0321 13:29:44.960000 140058691233600 base_trainer.py:770] Train Step: 104/1000 / time=0.050 sec
I0321 13:29:44.960081 140058691233600 base_trainer.py:771] Perf 617326.70 samples/s
I0321 13:29:45.014297 140058691233600 base_trainer.py:769] Step: 105 Lr 0.0386307 Loss scale 8192
I0321 13:29:45.014663 140058691233600 base_trainer.py:770] Train Step: 105/1000 / time=0.051 sec
I0321 13:29:45.014747 140058691233600 base_trainer.py:771] Perf 602478.97 samples/s
I0321 13:29:45.066996 140058691233600 base_trainer.py:769] Step: 106 Lr 0.0385892 Loss scale 8192
I0321 13:29:45.067219 140058691233600 base_trainer.py:770] Train Step: 106/1000 / time=0.050 sec
I0321 13:29:45.067304 140058691233600 base_trainer.py:771] Perf 618582.60 samples/s
I0321 13:29:45.119740 140058691233600 base_trainer.py:769] Step: 107 Lr 0.0385477 Loss scale 8192
I0321 13:29:45.119959 140058691233600 base_trainer.py:770] Train Step: 107/1000 / time=0.050 sec
I0321 13:29:45.120045 140058691233600 base_trainer.py:771] Perf 621567.03 samples/s
I0321 13:29:45.172157 140058691233600 base_trainer.py:769] Step: 108 Lr 0.0385062 Loss scale 8192
I0321 13:29:45.172380 140058691233600 base_trainer.py:770] Train Step: 108/1000 / time=0.050 sec
I0321 13:29:45.172458 140058691233600 base_trainer.py:771] Perf 623184.12 samples/s
I0321 13:29:45.224555 140058691233600 base_trainer.py:769] Step: 109 Lr 0.0384647 Loss scale 8192
I0321 13:29:45.224777 140058691233600 base_trainer.py:770] Train Step: 109/1000 / time=0.050 sec
I0321 13:29:45.224863 140058691233600 base_trainer.py:771] Perf 627719.86 samples/s
I0321 13:29:45.278732 140058691233600 base_trainer.py:769] Step: 110 Lr 0.0384232 Loss scale 8192
I0321 13:29:45.278943 140058691233600 base_trainer.py:770] Train Step: 110/1000 / time=0.051 sec
I0321 13:29:45.279021 140058691233600 base_trainer.py:771] Perf 604021.55 samples/s
I0321 13:29:45.333913 140058691233600 base_trainer.py:769] Step: 111 Lr 0.0383817 Loss scale 8192
I0321 13:29:45.334121 140058691233600 base_trainer.py:770] Train Step: 111/1000 / time=0.052 sec
I0321 13:29:45.334198 140058691233600 base_trainer.py:771] Perf 594258.84 samples/s
I0321 13:29:45.385615 140058691233600 base_trainer.py:769] Step: 112 Lr 0.0383403 Loss scale 8192
I0321 13:29:45.385827 140058691233600 base_trainer.py:770] Train Step: 112/1000 / time=0.049 sec
I0321 13:29:45.385906 140058691233600 base_trainer.py:771] Perf 632033.06 samples/s
I0321 13:29:45.437803 140058691233600 base_trainer.py:769] Step: 113 Lr 0.0382988 Loss scale 8192
I0321 13:29:45.438025 140058691233600 base_trainer.py:770] Train Step: 113/1000 / time=0.049 sec
I0321 13:29:45.438104 140058691233600 base_trainer.py:771] Perf 629039.51 samples/s
I0321 13:29:45.490837 140058691233600 base_trainer.py:769] Step: 114 Lr 0.0382573 Loss scale 8192
I0321 13:29:45.491060 140058691233600 base_trainer.py:770] Train Step: 114/1000 / time=0.050 sec
I0321 13:29:45.491150 140058691233600 base_trainer.py:771] Perf 618968.43 samples/s
I0321 13:29:45.543980 140058691233600 base_trainer.py:769] Step: 115 Lr 0.0382158 Loss scale 8192
I0321 13:29:45.544203 140058691233600 base_trainer.py:770] Train Step: 115/1000 / time=0.050 sec
I0321 13:29:45.544302 140058691233600 base_trainer.py:771] Perf 616952.85 samples/s
I0321 13:29:45.600934 140058691233600 base_trainer.py:769] Step: 116 Lr 0.0381743 Loss scale 8192
I0321 13:29:45.601154 140058691233600 base_trainer.py:770] Train Step: 116/1000 / time=0.054 sec
I0321 13:29:45.601244 140058691233600 base_trainer.py:771] Perf 575789.69 samples/s
I0321 13:29:45.654311 140058691233600 base_trainer.py:769] Step: 117 Lr 0.0381328 Loss scale 8192
I0321 13:29:45.654525 140058691233600 base_trainer.py:770] Train Step: 117/1000 / time=0.050 sec
I0321 13:29:45.654609 140058691233600 base_trainer.py:771] Perf 613384.99 samples/s
I0321 13:29:45.707337 140058691233600 base_trainer.py:769] Step: 118 Lr 0.0380913 Loss scale 8192
I0321 13:29:45.707549 140058691233600 base_trainer.py:770] Train Step: 118/1000 / time=0.050 sec
I0321 13:29:45.707631 140058691233600 base_trainer.py:771] Perf 617705.75 samples/s
I0321 13:29:45.761708 140058691233600 base_trainer.py:769] Step: 119 Lr 0.0380498 Loss scale 8192
I0321 13:29:45.761943 140058691233600 base_trainer.py:770] Train Step: 119/1000 / time=0.051 sec
I0321 13:29:45.762030 140058691233600 base_trainer.py:771] Perf 605640.04 samples/s
I0321 13:29:45.813725 140058691233600 base_trainer.py:769] Step: 120 Lr 0.0380083 Loss scale 8192
I0321 13:29:45.813939 140058691233600 base_trainer.py:770] Train Step: 120/1000 / time=0.049 sec
I0321 13:29:45.814018 140058691233600 base_trainer.py:771] Perf 625484.45 samples/s
I0321 13:29:45.865294 140058691233600 base_trainer.py:769] Step: 121 Lr 0.0379668 Loss scale 4096
I0321 13:29:45.865522 140058691233600 base_trainer.py:770] Train Step: 121/1000 / time=0.049 sec
I0321 13:29:45.865607 140058691233600 base_trainer.py:771] Perf 637371.39 samples/s
I0321 13:29:45.925566 140058691233600 base_trainer.py:769] Step: 122 Lr 0.0379253 Loss scale 4096
I0321 13:29:45.925797 140058691233600 base_trainer.py:770] Train Step: 122/1000 / time=0.057 sec
I0321 13:29:45.925882 140058691233600 base_trainer.py:771] Perf 543875.41 samples/s
I0321 13:29:45.979266 140058691233600 base_trainer.py:769] Step: 123 Lr 0.0378838 Loss scale 4096
I0321 13:29:45.979491 140058691233600 base_trainer.py:770] Train Step: 123/1000 / time=0.051 sec
I0321 13:29:45.979576 140058691233600 base_trainer.py:771] Perf 609925.25 samples/s
I0321 13:29:46.032022 140058691233600 base_trainer.py:769] Step: 124 Lr 0.0378423 Loss scale 4096
I0321 13:29:46.032266 140058691233600 base_trainer.py:770] Train Step: 124/1000 / time=0.050 sec
I0321 13:29:46.032366 140058691233600 base_trainer.py:771] Perf 621442.90 samples/s
I0321 13:29:46.086850 140058691233600 base_trainer.py:769] Step: 125 Lr 0.0378008 Loss scale 4096
I0321 13:29:46.087072 140058691233600 base_trainer.py:770] Train Step: 125/1000 / time=0.052 sec
I0321 13:29:46.087157 140058691233600 base_trainer.py:771] Perf 597120.27 samples/s
I0321 13:29:46.141392 140058691233600 base_trainer.py:769] Step: 126 Lr 0.0377593 Loss scale 4096
I0321 13:29:46.141602 140058691233600 base_trainer.py:770] Train Step: 126/1000 / time=0.052 sec
I0321 13:29:46.141681 140058691233600 base_trainer.py:771] Perf 599233.78 samples/s
I0321 13:29:46.195786 140058691233600 base_trainer.py:769] Step: 127 Lr 0.0377178 Loss scale 4096
I0321 13:29:46.196011 140058691233600 base_trainer.py:770] Train Step: 127/1000 / time=0.051 sec
I0321 13:29:46.196097 140058691233600 base_trainer.py:771] Perf 605207.18 samples/s
I0321 13:29:46.248504 140058691233600 base_trainer.py:769] Step: 128 Lr 0.0376763 Loss scale 4096
I0321 13:29:46.248888 140058691233600 base_trainer.py:770] Train Step: 128/1000 / time=0.050 sec
I0321 13:29:46.248978 140058691233600 base_trainer.py:771] Perf 622508.06 samples/s
I0321 13:29:46.301751 140058691233600 base_trainer.py:769] Step: 129 Lr 0.0376349 Loss scale 4096
I0321 13:29:46.301975 140058691233600 base_trainer.py:770] Train Step: 129/1000 / time=0.050 sec
I0321 13:29:46.302093 140058691233600 base_trainer.py:771] Perf 613883.02 samples/s
I0321 13:29:46.354840 140058691233600 base_trainer.py:769] Step: 130 Lr 0.0375934 Loss scale 4096
I0321 13:29:46.355059 140058691233600 base_trainer.py:770] Train Step: 130/1000 / time=0.050 sec
I0321 13:29:46.355153 140058691233600 base_trainer.py:771] Perf 615337.99 samples/s
I0321 13:29:46.407275 140058691233600 base_trainer.py:769] Step: 131 Lr 0.0375519 Loss scale 4096
I0321 13:29:46.407484 140058691233600 base_trainer.py:770] Train Step: 131/1000 / time=0.050 sec
I0321 13:29:46.407562 140058691233600 base_trainer.py:771] Perf 624152.81 samples/s
I0321 13:29:46.458394 140058691233600 base_trainer.py:769] Step: 132 Lr 0.0375104 Loss scale 4096
I0321 13:29:46.458607 140058691233600 base_trainer.py:770] Train Step: 132/1000 / time=0.048 sec
I0321 13:29:46.458688 140058691233600 base_trainer.py:771] Perf 641479.50 samples/s
I0321 13:29:46.512980 140058691233600 base_trainer.py:769] Step: 133 Lr 0.0374689 Loss scale 4096
I0321 13:29:46.513209 140058691233600 base_trainer.py:770] Train Step: 133/1000 / time=0.052 sec
I0321 13:29:46.513306 140058691233600 base_trainer.py:771] Perf 603272.49 samples/s
I0321 13:29:46.570143 140058691233600 base_trainer.py:769] Step: 134 Lr 0.0374274 Loss scale 4096
I0321 13:29:46.570373 140058691233600 base_trainer.py:770] Train Step: 134/1000 / time=0.054 sec
I0321 13:29:46.570471 140058691233600 base_trainer.py:771] Perf 573052.31 samples/s
I0321 13:29:46.623711 140058691233600 base_trainer.py:769] Step: 135 Lr 0.0373859 Loss scale 4096
I0321 13:29:46.623964 140058691233600 base_trainer.py:770] Train Step: 135/1000 / time=0.050 sec
I0321 13:29:46.624083 140058691233600 base_trainer.py:771] Perf 613983.56 samples/s
I0321 13:29:46.675609 140058691233600 base_trainer.py:769] Step: 136 Lr 0.0373444 Loss scale 4096
I0321 13:29:46.675835 140058691233600 base_trainer.py:770] Train Step: 136/1000 / time=0.049 sec
I0321 13:29:46.675920 140058691233600 base_trainer.py:771] Perf 629186.50 samples/s
I0321 13:29:46.727093 140058691233600 base_trainer.py:769] Step: 137 Lr 0.0373029 Loss scale 4096
I0321 13:29:46.727308 140058691233600 base_trainer.py:770] Train Step: 137/1000 / time=0.049 sec
I0321 13:29:46.727396 140058691233600 base_trainer.py:771] Perf 635572.51 samples/s
I0321 13:29:46.780362 140058691233600 base_trainer.py:769] Step: 138 Lr 0.0372614 Loss scale 4096
I0321 13:29:46.780576 140058691233600 base_trainer.py:770] Train Step: 138/1000 / time=0.050 sec
I0321 13:29:46.780661 140058691233600 base_trainer.py:771] Perf 615848.45 samples/s
I0321 13:29:46.832878 140058691233600 base_trainer.py:769] Step: 139 Lr 0.0372199 Loss scale 4096
I0321 13:29:46.833100 140058691233600 base_trainer.py:770] Train Step: 139/1000 / time=0.050 sec
I0321 13:29:46.833182 140058691233600 base_trainer.py:771] Perf 624635.09 samples/s
I0321 13:29:46.887807 140058691233600 base_trainer.py:769] Step: 140 Lr 0.0371784 Loss scale 4096
I0321 13:29:46.888025 140058691233600 base_trainer.py:770] Train Step: 140/1000 / time=0.052 sec
I0321 13:29:46.888106 140058691233600 base_trainer.py:771] Perf 594686.31 samples/s
I0321 13:29:46.940819 140058691233600 base_trainer.py:769] Step: 141 Lr 0.0371369 Loss scale 4096
I0321 13:29:46.941031 140058691233600 base_trainer.py:770] Train Step: 141/1000 / time=0.050 sec
I0321 13:29:46.941110 140058691233600 base_trainer.py:771] Perf 619756.15 samples/s
I0321 13:29:46.993924 140058691233600 base_trainer.py:769] Step: 142 Lr 0.0370954 Loss scale 4096
I0321 13:29:46.994140 140058691233600 base_trainer.py:770] Train Step: 142/1000 / time=0.050 sec
I0321 13:29:46.994229 140058691233600 base_trainer.py:771] Perf 614911.18 samples/s
I0321 13:29:47.046585 140058691233600 base_trainer.py:769] Step: 143 Lr 0.0370539 Loss scale 4096
I0321 13:29:47.046807 140058691233600 base_trainer.py:770] Train Step: 143/1000 / time=0.050 sec
I0321 13:29:47.046891 140058691233600 base_trainer.py:771] Perf 624295.54 samples/s
I0321 13:29:47.100473 140058691233600 base_trainer.py:769] Step: 144 Lr 0.0370125 Loss scale 4096
I0321 13:29:47.100828 140058691233600 base_trainer.py:770] Train Step: 144/1000 / time=0.050 sec
I0321 13:29:47.100972 140058691233600 base_trainer.py:771] Perf 623230.17 samples/s
I0321 13:29:47.156337 140058691233600 base_trainer.py:769] Step: 145 Lr 0.036971 Loss scale 4096
I0321 13:29:47.156568 140058691233600 base_trainer.py:770] Train Step: 145/1000 / time=0.052 sec
I0321 13:29:47.156650 140058691233600 base_trainer.py:771] Perf 575838.25 samples/s
I0321 13:29:47.210242 140058691233600 base_trainer.py:769] Step: 146 Lr 0.0369295 Loss scale 4096
I0321 13:29:47.210476 140058691233600 base_trainer.py:770] Train Step: 146/1000 / time=0.051 sec
I0321 13:29:47.210566 140058691233600 base_trainer.py:771] Perf 605714.94 samples/s
I0321 13:29:47.263780 140058691233600 base_trainer.py:769] Step: 147 Lr 0.036888 Loss scale 4096
I0321 13:29:47.264004 140058691233600 base_trainer.py:770] Train Step: 147/1000 / time=0.051 sec
I0321 13:29:47.264088 140058691233600 base_trainer.py:771] Perf 612355.98 samples/s
I0321 13:29:47.316772 140058691233600 base_trainer.py:769] Step: 148 Lr 0.0368465 Loss scale 4096
I0321 13:29:47.316997 140058691233600 base_trainer.py:770] Train Step: 148/1000 / time=0.050 sec
I0321 13:29:47.317080 140058691233600 base_trainer.py:771] Perf 618017.91 samples/s
I0321 13:29:47.368396 140058691233600 base_trainer.py:769] Step: 149 Lr 0.036805 Loss scale 4096
I0321 13:29:47.368623 140058691233600 base_trainer.py:770] Train Step: 149/1000 / time=0.049 sec
I0321 13:29:47.368703 140058691233600 base_trainer.py:771] Perf 634517.04 samples/s
I0321 13:29:47.422566 140058691233600 base_trainer.py:769] Step: 150 Lr 0.0367635 Loss scale 4096
I0321 13:29:47.422797 140058691233600 base_trainer.py:770] Train Step: 150/1000 / time=0.051 sec
I0321 13:29:47.422868 140058691233600 base_trainer.py:771] Perf 603090.05 samples/s
I0321 13:29:47.477966 140058691233600 base_trainer.py:769] Step: 151 Lr 0.036722 Loss scale 4096
I0321 13:29:47.478199 140058691233600 base_trainer.py:770] Train Step: 151/1000 / time=0.052 sec
I0321 13:29:47.478291 140058691233600 base_trainer.py:771] Perf 594041.47 samples/s
I0321 13:29:47.531569 140058691233600 base_trainer.py:769] Step: 152 Lr 0.0366805 Loss scale 4096
I0321 13:29:47.531783 140058691233600 base_trainer.py:770] Train Step: 152/1000 / time=0.051 sec
I0321 13:29:47.531863 140058691233600 base_trainer.py:771] Perf 608495.52 samples/s
I0321 13:29:47.583703 140058691233600 base_trainer.py:769] Step: 153 Lr 0.036639 Loss scale 4096
I0321 13:29:47.583913 140058691233600 base_trainer.py:770] Train Step: 153/1000 / time=0.049 sec
I0321 13:29:47.583996 140058691233600 base_trainer.py:771] Perf 630790.92 samples/s
I0321 13:29:47.635467 140058691233600 base_trainer.py:769] Step: 154 Lr 0.0365975 Loss scale 4096
I0321 13:29:47.635680 140058691233600 base_trainer.py:770] Train Step: 154/1000 / time=0.049 sec
I0321 13:29:47.635767 140058691233600 base_trainer.py:771] Perf 633066.02 samples/s
I0321 13:29:47.686081 140058691233600 base_trainer.py:769] Step: 155 Lr 0.036556 Loss scale 4096
I0321 13:29:47.686306 140058691233600 base_trainer.py:770] Train Step: 155/1000 / time=0.048 sec
I0321 13:29:47.686385 140058691233600 base_trainer.py:771] Perf 647554.66 samples/s
I0321 13:29:47.740249 140058691233600 base_trainer.py:769] Step: 156 Lr 0.0365145 Loss scale 4096
I0321 13:29:47.740476 140058691233600 base_trainer.py:770] Train Step: 156/1000 / time=0.051 sec
I0321 13:29:47.740563 140058691233600 base_trainer.py:771] Perf 603309.38 samples/s
I0321 13:29:47.794440 140058691233600 base_trainer.py:769] Step: 157 Lr 0.036473 Loss scale 4096
I0321 13:29:47.794664 140058691233600 base_trainer.py:770] Train Step: 157/1000 / time=0.051 sec
I0321 13:29:47.794750 140058691233600 base_trainer.py:771] Perf 607806.39 samples/s
I0321 13:29:47.846770 140058691233600 base_trainer.py:769] Step: 158 Lr 0.0364315 Loss scale 4096
I0321 13:29:47.847000 140058691233600 base_trainer.py:770] Train Step: 158/1000 / time=0.049 sec
I0321 13:29:47.847086 140058691233600 base_trainer.py:771] Perf 624866.73 samples/s
I0321 13:29:47.899835 140058691233600 base_trainer.py:769] Step: 159 Lr 0.03639 Loss scale 4096
I0321 13:29:47.900046 140058691233600 base_trainer.py:770] Train Step: 159/1000 / time=0.050 sec
I0321 13:29:47.900121 140058691233600 base_trainer.py:771] Perf 616182.09 samples/s
I0321 13:29:47.951680 140058691233600 base_trainer.py:769] Step: 160 Lr 0.0363485 Loss scale 4096
I0321 13:29:47.951893 140058691233600 base_trainer.py:770] Train Step: 160/1000 / time=0.049 sec
I0321 13:29:47.951973 140058691233600 base_trainer.py:771] Perf 632659.90 samples/s
I0321 13:29:48.004128 140058691233600 base_trainer.py:769] Step: 161 Lr 0.0363071 Loss scale 4096
I0321 13:29:48.004363 140058691233600 base_trainer.py:770] Train Step: 161/1000 / time=0.050 sec
I0321 13:29:48.004450 140058691233600 base_trainer.py:771] Perf 625046.87 samples/s
I0321 13:29:48.058125 140058691233600 base_trainer.py:769] Step: 162 Lr 0.0362656 Loss scale 4096
I0321 13:29:48.058351 140058691233600 base_trainer.py:770] Train Step: 162/1000 / time=0.051 sec
I0321 13:29:48.058436 140058691233600 base_trainer.py:771] Perf 607463.56 samples/s
I0321 13:29:48.112699 140058691233600 base_trainer.py:769] Step: 163 Lr 0.0362241 Loss scale 4096
I0321 13:29:48.112923 140058691233600 base_trainer.py:770] Train Step: 163/1000 / time=0.052 sec
I0321 13:29:48.113003 140058691233600 base_trainer.py:771] Perf 601284.04 samples/s
I0321 13:29:48.165417 140058691233600 base_trainer.py:769] Step: 164 Lr 0.0361826 Loss scale 4096
I0321 13:29:48.165635 140058691233600 base_trainer.py:770] Train Step: 164/1000 / time=0.050 sec
I0321 13:29:48.165714 140058691233600 base_trainer.py:771] Perf 620598.41 samples/s
I0321 13:29:48.218075 140058691233600 base_trainer.py:769] Step: 165 Lr 0.0361411 Loss scale 4096
I0321 13:29:48.218295 140058691233600 base_trainer.py:770] Train Step: 165/1000 / time=0.050 sec
I0321 13:29:48.218371 140058691233600 base_trainer.py:771] Perf 621114.34 samples/s
I0321 13:29:48.267917 140058691233600 base_trainer.py:769] Step: 166 Lr 0.0360996 Loss scale 4096
I0321 13:29:48.268156 140058691233600 base_trainer.py:770] Train Step: 166/1000 / time=0.047 sec
I0321 13:29:48.268241 140058691233600 base_trainer.py:771] Perf 659844.50 samples/s
I0321 13:29:48.318600 140058691233600 base_trainer.py:769] Step: 167 Lr 0.0360581 Loss scale 4096
I0321 13:29:48.318829 140058691233600 base_trainer.py:770] Train Step: 167/1000 / time=0.048 sec
I0321 13:29:48.318912 140058691233600 base_trainer.py:771] Perf 645954.39 samples/s
I0321 13:29:48.373528 140058691233600 base_trainer.py:769] Step: 168 Lr 0.0360166 Loss scale 4096
I0321 13:29:48.373744 140058691233600 base_trainer.py:770] Train Step: 168/1000 / time=0.052 sec
I0321 13:29:48.373823 140058691233600 base_trainer.py:771] Perf 597731.86 samples/s
I0321 13:29:48.429590 140058691233600 base_trainer.py:769] Step: 169 Lr 0.0359751 Loss scale 4096
I0321 13:29:48.429823 140058691233600 base_trainer.py:770] Train Step: 169/1000 / time=0.053 sec
I0321 13:29:48.429909 140058691233600 base_trainer.py:771] Perf 584561.79 samples/s
I0321 13:29:48.481572 140058691233600 base_trainer.py:769] Step: 170 Lr 0.0359336 Loss scale 4096
I0321 13:29:48.481795 140058691233600 base_trainer.py:770] Train Step: 170/1000 / time=0.049 sec
I0321 13:29:48.481884 140058691233600 base_trainer.py:771] Perf 629721.83 samples/s
I0321 13:29:48.534877 140058691233600 base_trainer.py:769] Step: 171 Lr 0.0358921 Loss scale 4096
I0321 13:29:48.535097 140058691233600 base_trainer.py:770] Train Step: 171/1000 / time=0.050 sec
I0321 13:29:48.535180 140058691233600 base_trainer.py:771] Perf 614827.45 samples/s
I0321 13:29:48.588652 140058691233600 base_trainer.py:769] Step: 172 Lr 0.0358506 Loss scale 4096
I0321 13:29:48.588892 140058691233600 base_trainer.py:770] Train Step: 172/1000 / time=0.051 sec
I0321 13:29:48.588988 140058691233600 base_trainer.py:771] Perf 612294.00 samples/s
I0321 13:29:48.640493 140058691233600 base_trainer.py:769] Step: 173 Lr 0.0358091 Loss scale 4096
I0321 13:29:48.640708 140058691233600 base_trainer.py:770] Train Step: 173/1000 / time=0.049 sec
I0321 13:29:48.640785 140058691233600 base_trainer.py:771] Perf 628228.78 samples/s
I0321 13:29:48.692738 140058691233600 base_trainer.py:769] Step: 174 Lr 0.0357676 Loss scale 4096
I0321 13:29:48.692974 140058691233600 base_trainer.py:770] Train Step: 174/1000 / time=0.049 sec
I0321 13:29:48.693055 140058691233600 base_trainer.py:771] Perf 628749.88 samples/s
I0321 13:29:48.745404 140058691233600 base_trainer.py:769] Step: 175 Lr 0.0357261 Loss scale 4096
I0321 13:29:48.745619 140058691233600 base_trainer.py:770] Train Step: 175/1000 / time=0.050 sec
I0321 13:29:48.745697 140058691233600 base_trainer.py:771] Perf 619891.19 samples/s
I0321 13:29:48.797863 140058691233600 base_trainer.py:769] Step: 176 Lr 0.0356846 Loss scale 4096
I0321 13:29:48.798090 140058691233600 base_trainer.py:770] Train Step: 176/1000 / time=0.050 sec
I0321 13:29:48.798179 140058691233600 base_trainer.py:771] Perf 626728.21 samples/s
I0321 13:29:48.851221 140058691233600 base_trainer.py:769] Step: 177 Lr 0.0356432 Loss scale 4096
I0321 13:29:48.851445 140058691233600 base_trainer.py:770] Train Step: 177/1000 / time=0.050 sec
I0321 13:29:48.851529 140058691233600 base_trainer.py:771] Perf 613176.29 samples/s
I0321 13:29:48.903278 140058691233600 base_trainer.py:769] Step: 178 Lr 0.0356017 Loss scale 4096
I0321 13:29:48.903491 140058691233600 base_trainer.py:770] Train Step: 178/1000 / time=0.049 sec
I0321 13:29:48.903568 140058691233600 base_trainer.py:771] Perf 627525.31 samples/s
I0321 13:29:48.953999 140058691233600 base_trainer.py:769] Step: 179 Lr 0.0355602 Loss scale 4096
I0321 13:29:48.954228 140058691233600 base_trainer.py:770] Train Step: 179/1000 / time=0.048 sec
I0321 13:29:48.954310 140058691233600 base_trainer.py:771] Perf 648021.22 samples/s
I0321 13:29:49.005588 140058691233600 base_trainer.py:769] Step: 180 Lr 0.0355187 Loss scale 4096
I0321 13:29:49.005820 140058691233600 base_trainer.py:770] Train Step: 180/1000 / time=0.049 sec
I0321 13:29:49.005909 140058691233600 base_trainer.py:771] Perf 635523.05 samples/s
I0321 13:29:49.058278 140058691233600 base_trainer.py:769] Step: 181 Lr 0.0354772 Loss scale 4096
I0321 13:29:49.058497 140058691233600 base_trainer.py:770] Train Step: 181/1000 / time=0.050 sec
I0321 13:29:49.058578 140058691233600 base_trainer.py:771] Perf 622582.70 samples/s
I0321 13:29:49.111270 140058691233600 base_trainer.py:769] Step: 182 Lr 0.0354357 Loss scale 4096
I0321 13:29:49.111649 140058691233600 base_trainer.py:770] Train Step: 182/1000 / time=0.050 sec
I0321 13:29:49.111776 140058691233600 base_trainer.py:771] Perf 624702.27 samples/s
I0321 13:29:49.171198 140058691233600 base_trainer.py:769] Step: 183 Lr 0.0353942 Loss scale 4096
I0321 13:29:49.171416 140058691233600 base_trainer.py:770] Train Step: 183/1000 / time=0.057 sec
I0321 13:29:49.171501 140058691233600 base_trainer.py:771] Perf 541480.18 samples/s
I0321 13:29:49.224276 140058691233600 base_trainer.py:769] Step: 184 Lr 0.0353527 Loss scale 4096
I0321 13:29:49.224492 140058691233600 base_trainer.py:770] Train Step: 184/1000 / time=0.050 sec
I0321 13:29:49.224579 140058691233600 base_trainer.py:771] Perf 615664.93 samples/s
I0321 13:29:49.280818 140058691233600 base_trainer.py:769] Step: 185 Lr 0.0353112 Loss scale 4096
I0321 13:29:49.281034 140058691233600 base_trainer.py:770] Train Step: 185/1000 / time=0.054 sec
I0321 13:29:49.281119 140058691233600 base_trainer.py:771] Perf 581603.75 samples/s
I0321 13:29:49.336055 140058691233600 base_trainer.py:769] Step: 186 Lr 0.0352697 Loss scale 4096
I0321 13:29:49.336326 140058691233600 base_trainer.py:770] Train Step: 186/1000 / time=0.052 sec
I0321 13:29:49.336427 140058691233600 base_trainer.py:771] Perf 593337.26 samples/s
I0321 13:29:49.389353 140058691233600 base_trainer.py:769] Step: 187 Lr 0.0352282 Loss scale 4096
I0321 13:29:49.389579 140058691233600 base_trainer.py:770] Train Step: 187/1000 / time=0.050 sec
I0321 13:29:49.389663 140058691233600 base_trainer.py:771] Perf 615622.23 samples/s
I0321 13:29:49.442469 140058691233600 base_trainer.py:769] Step: 188 Lr 0.0351867 Loss scale 4096
I0321 13:29:49.442678 140058691233600 base_trainer.py:770] Train Step: 188/1000 / time=0.050 sec
I0321 13:29:49.442755 140058691233600 base_trainer.py:771] Perf 613565.34 samples/s
I0321 13:29:49.493720 140058691233600 base_trainer.py:769] Step: 189 Lr 0.0351452 Loss scale 4096
I0321 13:29:49.493942 140058691233600 base_trainer.py:770] Train Step: 189/1000 / time=0.048 sec
I0321 13:29:49.494025 140058691233600 base_trainer.py:771] Perf 641346.73 samples/s
I0321 13:29:49.546802 140058691233600 base_trainer.py:769] Step: 190 Lr 0.0351037 Loss scale 4096
I0321 13:29:49.547014 140058691233600 base_trainer.py:770] Train Step: 190/1000 / time=0.050 sec
I0321 13:29:49.547095 140058691233600 base_trainer.py:771] Perf 615653.19 samples/s
I0321 13:29:49.599254 140058691233600 base_trainer.py:769] Step: 191 Lr 0.0350622 Loss scale 4096
I0321 13:29:49.599474 140058691233600 base_trainer.py:770] Train Step: 191/1000 / time=0.050 sec
I0321 13:29:49.599557 140058691233600 base_trainer.py:771] Perf 627564.00 samples/s
I0321 13:29:49.651905 140058691233600 base_trainer.py:769] Step: 192 Lr 0.0350207 Loss scale 4096
I0321 13:29:49.652127 140058691233600 base_trainer.py:770] Train Step: 192/1000 / time=0.050 sec
I0321 13:29:49.652215 140058691233600 base_trainer.py:771] Perf 622156.42 samples/s
I0321 13:29:49.705239 140058691233600 base_trainer.py:769] Step: 193 Lr 0.0349793 Loss scale 4096
I0321 13:29:49.705469 140058691233600 base_trainer.py:770] Train Step: 193/1000 / time=0.050 sec
I0321 13:29:49.705551 140058691233600 base_trainer.py:771] Perf 615785.21 samples/s
I0321 13:29:49.757747 140058691233600 base_trainer.py:769] Step: 194 Lr 0.0349378 Loss scale 4096
I0321 13:29:49.757972 140058691233600 base_trainer.py:770] Train Step: 194/1000 / time=0.050 sec
I0321 13:29:49.758058 140058691233600 base_trainer.py:771] Perf 622919.64 samples/s
I0321 13:29:49.810106 140058691233600 base_trainer.py:769] Step: 195 Lr 0.0348963 Loss scale 4096
I0321 13:29:49.810320 140058691233600 base_trainer.py:770] Train Step: 195/1000 / time=0.049 sec
I0321 13:29:49.810399 140058691233600 base_trainer.py:771] Perf 626425.79 samples/s
I0321 13:29:49.862614 140058691233600 base_trainer.py:769] Step: 196 Lr 0.0348548 Loss scale 4096
I0321 13:29:49.862835 140058691233600 base_trainer.py:770] Train Step: 196/1000 / time=0.050 sec
I0321 13:29:49.862917 140058691233600 base_trainer.py:771] Perf 623276.16 samples/s
I0321 13:29:49.915208 140058691233600 base_trainer.py:769] Step: 197 Lr 0.0348133 Loss scale 4096
I0321 13:29:49.915422 140058691233600 base_trainer.py:770] Train Step: 197/1000 / time=0.050 sec
I0321 13:29:49.915507 140058691233600 base_trainer.py:771] Perf 623112.58 samples/s
I0321 13:29:49.967873 140058691233600 base_trainer.py:769] Step: 198 Lr 0.0347718 Loss scale 4096
I0321 13:29:49.968091 140058691233600 base_trainer.py:770] Train Step: 198/1000 / time=0.050 sec
I0321 13:29:49.968176 140058691233600 base_trainer.py:771] Perf 622819.90 samples/s
I0321 13:29:50.023213 140058691233600 base_trainer.py:769] Step: 199 Lr 0.0347303 Loss scale 4096
I0321 13:29:50.023457 140058691233600 base_trainer.py:770] Train Step: 199/1000 / time=0.052 sec
I0321 13:29:50.023553 140058691233600 base_trainer.py:771] Perf 593983.74 samples/s
I0321 13:29:50.077767 140058691233600 base_trainer.py:769] Step: 200 Lr 0.0346888 Loss scale 4096
I0321 13:29:50.078064 140058691233600 base_trainer.py:770] Train Step: 200/1000 / time=0.052 sec
I0321 13:29:50.078154 140058691233600 base_trainer.py:771] Perf 599733.04 samples/s
I0321 13:29:50.130525 140058691233600 base_trainer.py:769] Step: 201 Lr 0.0346473 Loss scale 4096
I0321 13:29:50.130748 140058691233600 base_trainer.py:770] Train Step: 201/1000 / time=0.050 sec
I0321 13:29:50.130828 140058691233600 base_trainer.py:771] Perf 619687.06 samples/s
I0321 13:29:50.183063 140058691233600 base_trainer.py:769] Step: 202 Lr 0.0346058 Loss scale 4096
I0321 13:29:50.183285 140058691233600 base_trainer.py:770] Train Step: 202/1000 / time=0.050 sec
I0321 13:29:50.183371 140058691233600 base_trainer.py:771] Perf 624015.18 samples/s
I0321 13:29:50.235784 140058691233600 base_trainer.py:769] Step: 203 Lr 0.0345643 Loss scale 4096
I0321 13:29:50.235994 140058691233600 base_trainer.py:770] Train Step: 203/1000 / time=0.050 sec
I0321 13:29:50.236074 140058691233600 base_trainer.py:771] Perf 619132.55 samples/s
I0321 13:29:50.291578 140058691233600 base_trainer.py:769] Step: 204 Lr 0.0345228 Loss scale 4096
I0321 13:29:50.291927 140058691233600 base_trainer.py:770] Train Step: 204/1000 / time=0.052 sec
I0321 13:29:50.292031 140058691233600 base_trainer.py:771] Perf 594606.57 samples/s
I0321 13:29:50.345463 140058691233600 base_trainer.py:769] Step: 205 Lr 0.0344813 Loss scale 4096
I0321 13:29:50.345694 140058691233600 base_trainer.py:770] Train Step: 205/1000 / time=0.051 sec
I0321 13:29:50.345779 140058691233600 base_trainer.py:771] Perf 603511.44 samples/s
I0321 13:29:50.398632 140058691233600 base_trainer.py:769] Step: 206 Lr 0.0344398 Loss scale 4096
I0321 13:29:50.398848 140058691233600 base_trainer.py:770] Train Step: 206/1000 / time=0.050 sec
I0321 13:29:50.398929 140058691233600 base_trainer.py:771] Perf 614232.42 samples/s
I0321 13:29:50.450625 140058691233600 base_trainer.py:769] Step: 207 Lr 0.0343983 Loss scale 4096
I0321 13:29:50.450845 140058691233600 base_trainer.py:770] Train Step: 207/1000 / time=0.049 sec
I0321 13:29:50.450934 140058691233600 base_trainer.py:771] Perf 631322.55 samples/s
I0321 13:29:50.504587 140058691233600 base_trainer.py:769] Step: 208 Lr 0.0343568 Loss scale 4096
I0321 13:29:50.504811 140058691233600 base_trainer.py:770] Train Step: 208/1000 / time=0.051 sec
I0321 13:29:50.504903 140058691233600 base_trainer.py:771] Perf 610347.81 samples/s
I0321 13:29:50.558219 140058691233600 base_trainer.py:769] Step: 209 Lr 0.0343154 Loss scale 4096
I0321 13:29:50.558457 140058691233600 base_trainer.py:770] Train Step: 209/1000 / time=0.050 sec
I0321 13:29:50.558556 140058691233600 base_trainer.py:771] Perf 611399.48 samples/s
I0321 13:29:50.613328 140058691233600 base_trainer.py:769] Step: 210 Lr 0.0342739 Loss scale 4096
I0321 13:29:50.613586 140058691233600 base_trainer.py:770] Train Step: 210/1000 / time=0.052 sec
I0321 13:29:50.613678 140058691233600 base_trainer.py:771] Perf 593235.33 samples/s
I0321 13:29:50.666671 140058691233600 base_trainer.py:769] Step: 211 Lr 0.0342324 Loss scale 4096
I0321 13:29:50.666896 140058691233600 base_trainer.py:770] Train Step: 211/1000 / time=0.050 sec
I0321 13:29:50.666982 140058691233600 base_trainer.py:771] Perf 614129.50 samples/s
I0321 13:29:50.718398 140058691233600 base_trainer.py:769] Step: 212 Lr 0.0341909 Loss scale 4096
I0321 13:29:50.718621 140058691233600 base_trainer.py:770] Train Step: 212/1000 / time=0.049 sec
I0321 13:29:50.718706 140058691233600 base_trainer.py:771] Perf 633662.46 samples/s
I0321 13:29:50.772571 140058691233600 base_trainer.py:769] Step: 213 Lr 0.0341494 Loss scale 4096
I0321 13:29:50.772795 140058691233600 base_trainer.py:770] Train Step: 213/1000 / time=0.051 sec
I0321 13:29:50.772877 140058691233600 base_trainer.py:771] Perf 604025.59 samples/s
I0321 13:29:50.825057 140058691233600 base_trainer.py:769] Step: 214 Lr 0.0341079 Loss scale 4096
I0321 13:29:50.825288 140058691233600 base_trainer.py:770] Train Step: 214/1000 / time=0.050 sec
I0321 13:29:50.825382 140058691233600 base_trainer.py:771] Perf 624326.11 samples/s
I0321 13:29:50.876770 140058691233600 base_trainer.py:769] Step: 215 Lr 0.0340664 Loss scale 4096
I0321 13:29:50.877004 140058691233600 base_trainer.py:770] Train Step: 215/1000 / time=0.049 sec
I0321 13:29:50.877108 140058691233600 base_trainer.py:771] Perf 632938.37 samples/s
I0321 13:29:50.935696 140058691233600 base_trainer.py:769] Step: 216 Lr 0.0340249 Loss scale 4096
I0321 13:29:50.935919 140058691233600 base_trainer.py:770] Train Step: 216/1000 / time=0.056 sec
I0321 13:29:50.936004 140058691233600 base_trainer.py:771] Perf 556875.69 samples/s
I0321 13:29:50.989476 140058691233600 base_trainer.py:769] Step: 217 Lr 0.0339834 Loss scale 4096
I0321 13:29:50.989695 140058691233600 base_trainer.py:770] Train Step: 217/1000 / time=0.051 sec
I0321 13:29:50.989778 140058691233600 base_trainer.py:771] Perf 609300.52 samples/s
I0321 13:29:51.042671 140058691233600 base_trainer.py:769] Step: 218 Lr 0.0339419 Loss scale 4096
I0321 13:29:51.042888 140058691233600 base_trainer.py:770] Train Step: 218/1000 / time=0.050 sec
I0321 13:29:51.042983 140058691233600 base_trainer.py:771] Perf 615675.77 samples/s
I0321 13:29:51.094324 140058691233600 base_trainer.py:769] Step: 219 Lr 0.0339004 Loss scale 4096
I0321 13:29:51.094544 140058691233600 base_trainer.py:770] Train Step: 219/1000 / time=0.049 sec
I0321 13:29:51.094630 140058691233600 base_trainer.py:771] Perf 634485.22 samples/s
I0321 13:29:51.146617 140058691233600 base_trainer.py:769] Step: 220 Lr 0.0338589 Loss scale 4096
I0321 13:29:51.146845 140058691233600 base_trainer.py:770] Train Step: 220/1000 / time=0.049 sec
I0321 13:29:51.146930 140058691233600 base_trainer.py:771] Perf 626925.09 samples/s
I0321 13:29:51.199336 140058691233600 base_trainer.py:769] Step: 221 Lr 0.0338174 Loss scale 4096
I0321 13:29:51.199561 140058691233600 base_trainer.py:770] Train Step: 221/1000 / time=0.050 sec
I0321 13:29:51.199646 140058691233600 base_trainer.py:771] Perf 623511.53 samples/s
I0321 13:29:51.252226 140058691233600 base_trainer.py:769] Step: 222 Lr 0.0337759 Loss scale 4096
I0321 13:29:51.252495 140058691233600 base_trainer.py:770] Train Step: 222/1000 / time=0.050 sec
I0321 13:29:51.252585 140058691233600 base_trainer.py:771] Perf 619324.25 samples/s
I0321 13:29:51.303450 140058691233600 base_trainer.py:769] Step: 223 Lr 0.0337344 Loss scale 4096
I0321 13:29:51.303669 140058691233600 base_trainer.py:770] Train Step: 223/1000 / time=0.048 sec
I0321 13:29:51.303757 140058691233600 base_trainer.py:771] Perf 638133.26 samples/s
I0321 13:29:51.568463 140058691233600 base_trainer.py:769] Step: 224 Lr 0.0336929 Loss scale 4096
I0321 13:29:51.568691 140058691233600 base_trainer.py:770] Train Step: 224/1000 / time=0.262 sec
I0321 13:29:51.568774 140058691233600 base_trainer.py:771] Perf 123673.63 samples/s
I0321 13:29:51.857872 140058691233600 base_trainer.py:769] Step: 225 Lr 0.0336515 Loss scale 4096
I0321 13:29:51.858148 140058691233600 base_trainer.py:770] Train Step: 225/1000 / time=0.286 sec
I0321 13:29:51.858276 140058691233600 base_trainer.py:771] Perf 113334.49 samples/s
I0321 13:29:52.144988 140058691233600 base_trainer.py:769] Step: 226 Lr 0.03361 Loss scale 4096
I0321 13:29:52.145257 140058691233600 base_trainer.py:770] Train Step: 226/1000 / time=0.284 sec
I0321 13:29:52.145368 140058691233600 base_trainer.py:771] Perf 114147.03 samples/s
I0321 13:29:52.436601 140058691233600 base_trainer.py:769] Step: 227 Lr 0.0335685 Loss scale 4096
I0321 13:29:52.436823 140058691233600 base_trainer.py:770] Train Step: 227/1000 / time=0.289 sec
I0321 13:29:52.436907 140058691233600 base_trainer.py:771] Perf 112205.49 samples/s
I0321 13:29:52.724215 140058691233600 base_trainer.py:769] Step: 228 Lr 0.033527 Loss scale 4096
I0321 13:29:52.724456 140058691233600 base_trainer.py:770] Train Step: 228/1000 / time=0.285 sec
I0321 13:29:52.724543 140058691233600 base_trainer.py:771] Perf 113944.15 samples/s
I0321 13:29:53.012629 140058691233600 base_trainer.py:769] Step: 229 Lr 0.0334855 Loss scale 4096
I0321 13:29:53.012855 140058691233600 base_trainer.py:770] Train Step: 229/1000 / time=0.285 sec
I0321 13:29:53.012938 140058691233600 base_trainer.py:771] Perf 113640.73 samples/s
I0321 13:29:53.299470 140058691233600 base_trainer.py:769] Step: 230 Lr 0.033444 Loss scale 4096
I0321 13:29:53.299690 140058691233600 base_trainer.py:770] Train Step: 230/1000 / time=0.284 sec
I0321 13:29:53.299775 140058691233600 base_trainer.py:771] Perf 114231.67 samples/s
I0321 13:29:53.597773 140058691233600 base_trainer.py:769] Step: 231 Lr 0.0334025 Loss scale 4096
I0321 13:29:53.597998 140058691233600 base_trainer.py:770] Train Step: 231/1000 / time=0.295 sec
I0321 13:29:53.598079 140058691233600 base_trainer.py:771] Perf 109854.29 samples/s
I0321 13:29:53.884618 140058691233600 base_trainer.py:769] Step: 232 Lr 0.033361 Loss scale 4096
I0321 13:29:53.884844 140058691233600 base_trainer.py:770] Train Step: 232/1000 / time=0.284 sec
I0321 13:29:53.884924 140058691233600 base_trainer.py:771] Perf 114177.40 samples/s
I0321 13:29:54.175389 140058691233600 base_trainer.py:769] Step: 233 Lr 0.0333195 Loss scale 4096
I0321 13:29:54.175610 140058691233600 base_trainer.py:770] Train Step: 233/1000 / time=0.288 sec
I0321 13:29:54.175700 140058691233600 base_trainer.py:771] Perf 112763.95 samples/s
I0321 13:29:54.463999 140058691233600 base_trainer.py:769] Step: 234 Lr 0.033278 Loss scale 4096
I0321 13:29:54.464226 140058691233600 base_trainer.py:770] Train Step: 234/1000 / time=0.286 sec
I0321 13:29:54.464321 140058691233600 base_trainer.py:771] Perf 113524.01 samples/s
I0321 13:29:54.759028 140058691233600 base_trainer.py:769] Step: 235 Lr 0.0332365 Loss scale 4096
I0321 13:29:54.759256 140058691233600 base_trainer.py:770] Train Step: 235/1000 / time=0.292 sec
I0321 13:29:54.759339 140058691233600 base_trainer.py:771] Perf 111066.55 samples/s
I0321 13:29:55.041919 140058691233600 base_trainer.py:769] Step: 236 Lr 0.033195 Loss scale 4096
I0321 13:29:55.042140 140058691233600 base_trainer.py:770] Train Step: 236/1000 / time=0.280 sec
I0321 13:29:55.042221 140058691233600 base_trainer.py:771] Perf 115852.80 samples/s
I0321 13:29:55.335180 140058691233600 base_trainer.py:769] Step: 237 Lr 0.0331535 Loss scale 4096
I0321 13:29:55.335407 140058691233600 base_trainer.py:770] Train Step: 237/1000 / time=0.290 sec
I0321 13:29:55.335488 140058691233600 base_trainer.py:771] Perf 111741.04 samples/s
I0321 13:29:55.615847 140058691233600 base_trainer.py:769] Step: 238 Lr 0.033112 Loss scale 4096
I0321 13:29:55.616075 140058691233600 base_trainer.py:770] Train Step: 238/1000 / time=0.278 sec
I0321 13:29:55.616160 140058691233600 base_trainer.py:771] Perf 116745.68 samples/s
I0321 13:29:55.913528 140058691233600 base_trainer.py:769] Step: 239 Lr 0.0330705 Loss scale 4096
I0321 13:29:55.913750 140058691233600 base_trainer.py:770] Train Step: 239/1000 / time=0.295 sec
I0321 13:29:55.913830 140058691233600 base_trainer.py:771] Perf 110054.01 samples/s
I0321 13:29:56.204752 140058691233600 base_trainer.py:769] Step: 240 Lr 0.033029 Loss scale 4096
I0321 13:29:56.204982 140058691233600 base_trainer.py:770] Train Step: 240/1000 / time=0.288 sec
I0321 13:29:56.205065 140058691233600 base_trainer.py:771] Perf 112543.58 samples/s
I0321 13:29:56.496881 140058691233600 base_trainer.py:769] Step: 241 Lr 0.0329876 Loss scale 4096
I0321 13:29:56.497102 140058691233600 base_trainer.py:770] Train Step: 241/1000 / time=0.289 sec
I0321 13:29:56.497186 140058691233600 base_trainer.py:771] Perf 112196.58 samples/s
I0321 13:29:56.790518 140058691233600 base_trainer.py:769] Step: 242 Lr 0.0329461 Loss scale 4096
I0321 13:29:56.790755 140058691233600 base_trainer.py:770] Train Step: 242/1000 / time=0.291 sec
I0321 13:29:56.790842 140058691233600 base_trainer.py:771] Perf 111586.04 samples/s
I0321 13:29:57.078299 140058691233600 base_trainer.py:769] Step: 243 Lr 0.0329046 Loss scale 4096
I0321 13:29:57.078526 140058691233600 base_trainer.py:770] Train Step: 243/1000 / time=0.285 sec
I0321 13:29:57.078603 140058691233600 base_trainer.py:771] Perf 113791.05 samples/s
I0321 13:29:57.368959 140058691233600 base_trainer.py:769] Step: 244 Lr 0.0328631 Loss scale 4096
I0321 13:29:57.369172 140058691233600 base_trainer.py:770] Train Step: 244/1000 / time=0.288 sec
I0321 13:29:57.369252 140058691233600 base_trainer.py:771] Perf 112730.59 samples/s
I0321 13:29:57.690099 140058691233600 base_trainer.py:769] Step: 245 Lr 0.0328216 Loss scale 4096
I0321 13:29:57.690331 140058691233600 base_trainer.py:770] Train Step: 245/1000 / time=0.318 sec
I0321 13:29:57.690417 140058691233600 base_trainer.py:771] Perf 102134.22 samples/s
I0321 13:29:57.981841 140058691233600 base_trainer.py:769] Step: 246 Lr 0.0327801 Loss scale 4096
I0321 13:29:57.982066 140058691233600 base_trainer.py:770] Train Step: 246/1000 / time=0.289 sec
I0321 13:29:57.982150 140058691233600 base_trainer.py:771] Perf 112277.37 samples/s
I0321 13:29:58.273596 140058691233600 base_trainer.py:769] Step: 247 Lr 0.0327386 Loss scale 4096
I0321 13:29:58.273822 140058691233600 base_trainer.py:770] Train Step: 247/1000 / time=0.289 sec
I0321 13:29:58.273904 140058691233600 base_trainer.py:771] Perf 112323.68 samples/s
I0321 13:29:58.576072 140058691233600 base_trainer.py:769] Step: 248 Lr 0.0326971 Loss scale 4096
I0321 13:29:58.576318 140058691233600 base_trainer.py:770] Train Step: 248/1000 / time=0.300 sec
I0321 13:29:58.576403 140058691233600 base_trainer.py:771] Perf 108332.60 samples/s
I0321 13:29:58.870741 140058691233600 base_trainer.py:769] Step: 249 Lr 0.0326556 Loss scale 4096
I0321 13:29:58.870978 140058691233600 base_trainer.py:770] Train Step: 249/1000 / time=0.292 sec
I0321 13:29:58.871063 140058691233600 base_trainer.py:771] Perf 111208.54 samples/s
I0321 13:29:59.167041 140058691233600 base_trainer.py:769] Step: 250 Lr 0.0326141 Loss scale 4096
I0321 13:29:59.167256 140058691233600 base_trainer.py:770] Train Step: 250/1000 / time=0.294 sec
I0321 13:29:59.167346 140058691233600 base_trainer.py:771] Perf 110509.48 samples/s
I0321 13:29:59.467252 140058691233600 base_trainer.py:769] Step: 251 Lr 0.0325726 Loss scale 4096
I0321 13:29:59.467481 140058691233600 base_trainer.py:770] Train Step: 251/1000 / time=0.297 sec
I0321 13:29:59.467567 140058691233600 base_trainer.py:771] Perf 109234.47 samples/s
I0321 13:29:59.748719 140058691233600 base_trainer.py:769] Step: 252 Lr 0.0325311 Loss scale 4096
I0321 13:29:59.748974 140058691233600 base_trainer.py:770] Train Step: 252/1000 / time=0.278 sec
I0321 13:29:59.749061 140058691233600 base_trainer.py:771] Perf 116465.58 samples/s
I0321 13:30:00.037686 140058691233600 base_trainer.py:769] Step: 253 Lr 0.0324896 Loss scale 4096
I0321 13:30:00.037918 140058691233600 base_trainer.py:770] Train Step: 253/1000 / time=0.286 sec
I0321 13:30:00.038006 140058691233600 base_trainer.py:771] Perf 113372.36 samples/s
I0321 13:30:00.325215 140058691233600 base_trainer.py:769] Step: 254 Lr 0.0324481 Loss scale 4096
I0321 13:30:00.325444 140058691233600 base_trainer.py:770] Train Step: 254/1000 / time=0.285 sec
I0321 13:30:00.325530 140058691233600 base_trainer.py:771] Perf 113949.67 samples/s
I0321 13:30:00.610329 140058691233600 base_trainer.py:769] Step: 255 Lr 0.0324066 Loss scale 4096
I0321 13:30:00.610559 140058691233600 base_trainer.py:770] Train Step: 255/1000 / time=0.282 sec
I0321 13:30:00.610632 140058691233600 base_trainer.py:771] Perf 114811.73 samples/s
I0321 13:30:00.907731 140058691233600 base_trainer.py:769] Step: 256 Lr 0.0323651 Loss scale 4096
I0321 13:30:00.907942 140058691233600 base_trainer.py:770] Train Step: 256/1000 / time=0.295 sec
I0321 13:30:00.908020 140058691233600 base_trainer.py:771] Perf 110258.53 samples/s
I0321 13:30:01.196379 140058691233600 base_trainer.py:769] Step: 257 Lr 0.0323237 Loss scale 4096
I0321 13:30:01.196609 140058691233600 base_trainer.py:770] Train Step: 257/1000 / time=0.286 sec
I0321 13:30:01.196696 140058691233600 base_trainer.py:771] Perf 113561.71 samples/s
I0321 13:30:01.483139 140058691233600 base_trainer.py:769] Step: 258 Lr 0.0322822 Loss scale 4096
I0321 13:30:01.483366 140058691233600 base_trainer.py:770] Train Step: 258/1000 / time=0.284 sec
I0321 13:30:01.483452 140058691233600 base_trainer.py:771] Perf 114249.89 samples/s
I0321 13:30:01.784803 140058691233600 base_trainer.py:769] Step: 259 Lr 0.0322407 Loss scale 4096
I0321 13:30:01.785016 140058691233600 base_trainer.py:770] Train Step: 259/1000 / time=0.299 sec
I0321 13:30:01.785095 140058691233600 base_trainer.py:771] Perf 108593.11 samples/s
I0321 13:30:02.074107 140058691233600 base_trainer.py:769] Step: 260 Lr 0.0321992 Loss scale 4096
I0321 13:30:02.074337 140058691233600 base_trainer.py:770] Train Step: 260/1000 / time=0.286 sec
I0321 13:30:02.074427 140058691233600 base_trainer.py:771] Perf 113335.69 samples/s
I0321 13:30:02.364689 140058691233600 base_trainer.py:769] Step: 261 Lr 0.0321577 Loss scale 4096
I0321 13:30:02.364902 140058691233600 base_trainer.py:770] Train Step: 261/1000 / time=0.288 sec
I0321 13:30:02.364984 140058691233600 base_trainer.py:771] Perf 112715.09 samples/s
I0321 13:30:02.658035 140058691233600 base_trainer.py:769] Step: 262 Lr 0.0321162 Loss scale 4096
I0321 13:30:02.658250 140058691233600 base_trainer.py:770] Train Step: 262/1000 / time=0.291 sec
I0321 13:30:02.658334 140058691233600 base_trainer.py:771] Perf 111677.71 samples/s
I0321 13:30:02.955044 140058691233600 base_trainer.py:769] Step: 263 Lr 0.0320747 Loss scale 4096
I0321 13:30:02.955258 140058691233600 base_trainer.py:770] Train Step: 263/1000 / time=0.294 sec
I0321 13:30:02.955336 140058691233600 base_trainer.py:771] Perf 110315.43 samples/s
I0321 13:30:03.247227 140058691233600 base_trainer.py:769] Step: 264 Lr 0.0320332 Loss scale 4096
I0321 13:30:03.247449 140058691233600 base_trainer.py:770] Train Step: 264/1000 / time=0.289 sec
I0321 13:30:03.247535 140058691233600 base_trainer.py:771] Perf 112223.82 samples/s
I0321 13:30:03.532537 140058691233600 base_trainer.py:769] Step: 265 Lr 0.0319917 Loss scale 4096
I0321 13:30:03.532751 140058691233600 base_trainer.py:770] Train Step: 265/1000 / time=0.283 sec
I0321 13:30:03.532829 140058691233600 base_trainer.py:771] Perf 114801.51 samples/s
I0321 13:30:03.827004 140058691233600 base_trainer.py:769] Step: 266 Lr 0.0319502 Loss scale 4096
I0321 13:30:03.827225 140058691233600 base_trainer.py:770] Train Step: 266/1000 / time=0.292 sec
I0321 13:30:03.827309 140058691233600 base_trainer.py:771] Perf 111311.08 samples/s
I0321 13:30:04.116568 140058691233600 base_trainer.py:769] Step: 267 Lr 0.0319087 Loss scale 4096
I0321 13:30:04.116787 140058691233600 base_trainer.py:770] Train Step: 267/1000 / time=0.287 sec
I0321 13:30:04.116876 140058691233600 base_trainer.py:771] Perf 113185.19 samples/s
I0321 13:30:04.409851 140058691233600 base_trainer.py:769] Step: 268 Lr 0.0318672 Loss scale 4096
I0321 13:30:04.410076 140058691233600 base_trainer.py:770] Train Step: 268/1000 / time=0.290 sec
I0321 13:30:04.410165 140058691233600 base_trainer.py:771] Perf 111741.86 samples/s
I0321 13:30:04.695480 140058691233600 base_trainer.py:769] Step: 269 Lr 0.0318257 Loss scale 4096
I0321 13:30:04.695695 140058691233600 base_trainer.py:770] Train Step: 269/1000 / time=0.283 sec
I0321 13:30:04.695773 140058691233600 base_trainer.py:771] Perf 114648.41 samples/s
I0321 13:30:04.990135 140058691233600 base_trainer.py:769] Step: 270 Lr 0.0317842 Loss scale 4096
I0321 13:30:04.990379 140058691233600 base_trainer.py:770] Train Step: 270/1000 / time=0.292 sec
I0321 13:30:04.990476 140058691233600 base_trainer.py:771] Perf 111351.28 samples/s
I0321 13:30:05.269829 140058691233600 base_trainer.py:769] Step: 271 Lr 0.0317427 Loss scale 4096
I0321 13:30:05.270066 140058691233600 base_trainer.py:770] Train Step: 271/1000 / time=0.276 sec
I0321 13:30:05.270159 140058691233600 base_trainer.py:771] Perf 117175.85 samples/s
I0321 13:30:05.564030 140058691233600 base_trainer.py:769] Step: 272 Lr 0.0317012 Loss scale 4096
I0321 13:30:05.564244 140058691233600 base_trainer.py:770] Train Step: 272/1000 / time=0.291 sec
I0321 13:30:05.564335 140058691233600 base_trainer.py:771] Perf 111217.18 samples/s
I0321 13:30:05.879180 140058691233600 base_trainer.py:769] Step: 273 Lr 0.0316598 Loss scale 4096
I0321 13:30:05.879418 140058691233600 base_trainer.py:770] Train Step: 273/1000 / time=0.312 sec
I0321 13:30:05.879514 140058691233600 base_trainer.py:771] Perf 104114.48 samples/s
I0321 13:30:06.168244 140058691233600 base_trainer.py:769] Step: 274 Lr 0.0316183 Loss scale 4096
I0321 13:30:06.168492 140058691233600 base_trainer.py:770] Train Step: 274/1000 / time=0.286 sec
I0321 13:30:06.168581 140058691233600 base_trainer.py:771] Perf 113276.08 samples/s
I0321 13:30:06.455729 140058691233600 base_trainer.py:769] Step: 275 Lr 0.0315768 Loss scale 4096
I0321 13:30:06.455944 140058691233600 base_trainer.py:770] Train Step: 275/1000 / time=0.285 sec
I0321 13:30:06.456022 140058691233600 base_trainer.py:771] Perf 113914.11 samples/s
I0321 13:30:06.741054 140058691233600 base_trainer.py:769] Step: 276 Lr 0.0315353 Loss scale 4096
I0321 13:30:06.741268 140058691233600 base_trainer.py:770] Train Step: 276/1000 / time=0.283 sec
I0321 13:30:06.741346 140058691233600 base_trainer.py:771] Perf 114841.59 samples/s
I0321 13:30:07.027553 140058691233600 base_trainer.py:769] Step: 277 Lr 0.0314938 Loss scale 4096
I0321 13:30:07.027783 140058691233600 base_trainer.py:770] Train Step: 277/1000 / time=0.283 sec
I0321 13:30:07.027878 140058691233600 base_trainer.py:771] Perf 114518.98 samples/s
I0321 13:30:07.315221 140058691233600 base_trainer.py:769] Step: 278 Lr 0.0314523 Loss scale 4096
I0321 13:30:07.315454 140058691233600 base_trainer.py:770] Train Step: 278/1000 / time=0.285 sec
I0321 13:30:07.315537 140058691233600 base_trainer.py:771] Perf 113856.02 samples/s
I0321 13:30:07.610600 140058691233600 base_trainer.py:769] Step: 279 Lr 0.0314108 Loss scale 4096
I0321 13:30:07.610826 140058691233600 base_trainer.py:770] Train Step: 279/1000 / time=0.292 sec
I0321 13:30:07.610912 140058691233600 base_trainer.py:771] Perf 110931.18 samples/s
I0321 13:30:07.906279 140058691233600 base_trainer.py:769] Step: 280 Lr 0.0313693 Loss scale 4096
I0321 13:30:07.906504 140058691233600 base_trainer.py:770] Train Step: 280/1000 / time=0.293 sec
I0321 13:30:07.906586 140058691233600 base_trainer.py:771] Perf 110829.66 samples/s
I0321 13:30:08.206116 140058691233600 base_trainer.py:769] Step: 281 Lr 0.0313278 Loss scale 4096
I0321 13:30:08.206346 140058691233600 base_trainer.py:770] Train Step: 281/1000 / time=0.297 sec
I0321 13:30:08.206435 140058691233600 base_trainer.py:771] Perf 109295.76 samples/s
I0321 13:30:08.491252 140058691233600 base_trainer.py:769] Step: 282 Lr 0.0312863 Loss scale 4096
I0321 13:30:08.491480 140058691233600 base_trainer.py:770] Train Step: 282/1000 / time=0.282 sec
I0321 13:30:08.491567 140058691233600 base_trainer.py:771] Perf 114911.71 samples/s
I0321 13:30:08.779616 140058691233600 base_trainer.py:769] Step: 283 Lr 0.0312448 Loss scale 4096
I0321 13:30:08.779839 140058691233600 base_trainer.py:770] Train Step: 283/1000 / time=0.285 sec
I0321 13:30:08.779922 140058691233600 base_trainer.py:771] Perf 113650.93 samples/s
I0321 13:30:09.067136 140058691233600 base_trainer.py:769] Step: 284 Lr 0.0312033 Loss scale 4096
I0321 13:30:09.067350 140058691233600 base_trainer.py:770] Train Step: 284/1000 / time=0.285 sec
I0321 13:30:09.067427 140058691233600 base_trainer.py:771] Perf 113868.96 samples/s
I0321 13:30:09.353946 140058691233600 base_trainer.py:769] Step: 285 Lr 0.0311618 Loss scale 4096
I0321 13:30:09.354160 140058691233600 base_trainer.py:770] Train Step: 285/1000 / time=0.284 sec
I0321 13:30:09.354238 140058691233600 base_trainer.py:771] Perf 114259.44 samples/s
I0321 13:30:09.654402 140058691233600 base_trainer.py:769] Step: 286 Lr 0.0311203 Loss scale 4096
I0321 13:30:09.654624 140058691233600 base_trainer.py:770] Train Step: 286/1000 / time=0.297 sec
I0321 13:30:09.654714 140058691233600 base_trainer.py:771] Perf 109160.37 samples/s
I0321 13:30:09.949253 140058691233600 base_trainer.py:769] Step: 287 Lr 0.0310788 Loss scale 4096
I0321 13:30:09.949476 140058691233600 base_trainer.py:770] Train Step: 287/1000 / time=0.292 sec
I0321 13:30:09.949555 140058691233600 base_trainer.py:771] Perf 111088.57 samples/s
I0321 13:30:10.236271 140058691233600 base_trainer.py:769] Step: 288 Lr 0.0310373 Loss scale 4096
I0321 13:30:10.236497 140058691233600 base_trainer.py:770] Train Step: 288/1000 / time=0.284 sec
I0321 13:30:10.236581 140058691233600 base_trainer.py:771] Perf 114182.29 samples/s
I0321 13:30:10.533470 140058691233600 base_trainer.py:769] Step: 289 Lr 0.0309958 Loss scale 4096
I0321 13:30:10.533679 140058691233600 base_trainer.py:770] Train Step: 289/1000 / time=0.294 sec
I0321 13:30:10.533755 140058691233600 base_trainer.py:771] Perf 110194.20 samples/s
I0321 13:30:10.841063 140058691233600 base_trainer.py:769] Step: 290 Lr 0.0309544 Loss scale 4096
I0321 13:30:10.841278 140058691233600 base_trainer.py:770] Train Step: 290/1000 / time=0.305 sec
I0321 13:30:10.841355 140058691233600 base_trainer.py:771] Perf 106559.85 samples/s
I0321 13:30:11.135491 140058691233600 base_trainer.py:769] Step: 291 Lr 0.0309129 Loss scale 4096
I0321 13:30:11.135716 140058691233600 base_trainer.py:770] Train Step: 291/1000 / time=0.292 sec
I0321 13:30:11.135802 140058691233600 base_trainer.py:771] Perf 111313.47 samples/s
I0321 13:30:11.441516 140058691233600 base_trainer.py:769] Step: 292 Lr 0.0308714 Loss scale 4096
I0321 13:30:11.441745 140058691233600 base_trainer.py:770] Train Step: 292/1000 / time=0.303 sec
I0321 13:30:11.441840 140058691233600 base_trainer.py:771] Perf 107114.43 samples/s
I0321 13:30:11.730358 140058691233600 base_trainer.py:769] Step: 293 Lr 0.0308299 Loss scale 4096
I0321 13:30:11.730568 140058691233600 base_trainer.py:770] Train Step: 293/1000 / time=0.286 sec
I0321 13:30:11.730647 140058691233600 base_trainer.py:771] Perf 113345.19 samples/s
I0321 13:30:12.013678 140058691233600 base_trainer.py:769] Step: 294 Lr 0.0307884 Loss scale 4096
I0321 13:30:12.013908 140058691233600 base_trainer.py:770] Train Step: 294/1000 / time=0.280 sec
I0321 13:30:12.013993 140058691233600 base_trainer.py:771] Perf 115755.65 samples/s
I0321 13:30:12.303626 140058691233600 base_trainer.py:769] Step: 295 Lr 0.0307469 Loss scale 4096
I0321 13:30:12.303862 140058691233600 base_trainer.py:770] Train Step: 295/1000 / time=0.287 sec
I0321 13:30:12.303946 140058691233600 base_trainer.py:771] Perf 113004.97 samples/s
I0321 13:30:12.588047 140058691233600 base_trainer.py:769] Step: 296 Lr 0.0307054 Loss scale 4096
I0321 13:30:12.588274 140058691233600 base_trainer.py:770] Train Step: 296/1000 / time=0.281 sec
I0321 13:30:12.588358 140058691233600 base_trainer.py:771] Perf 115205.68 samples/s
I0321 13:30:12.879361 140058691233600 base_trainer.py:769] Step: 297 Lr 0.0306639 Loss scale 4096
I0321 13:30:12.879592 140058691233600 base_trainer.py:770] Train Step: 297/1000 / time=0.288 sec
I0321 13:30:12.879695 140058691233600 base_trainer.py:771] Perf 112508.34 samples/s
I0321 13:30:13.168805 140058691233600 base_trainer.py:769] Step: 298 Lr 0.0306224 Loss scale 4096
I0321 13:30:13.169033 140058691233600 base_trainer.py:770] Train Step: 298/1000 / time=0.286 sec
I0321 13:30:13.169117 140058691233600 base_trainer.py:771] Perf 113212.20 samples/s
I0321 13:30:13.456771 140058691233600 base_trainer.py:769] Step: 299 Lr 0.0305809 Loss scale 4096
I0321 13:30:13.456990 140058691233600 base_trainer.py:770] Train Step: 299/1000 / time=0.285 sec
I0321 13:30:13.457071 140058691233600 base_trainer.py:771] Perf 113783.23 samples/s
I0321 13:30:13.736229 140058691233600 base_trainer.py:769] Step: 300 Lr 0.0305394 Loss scale 4096
I0321 13:30:13.736462 140058691233600 base_trainer.py:770] Train Step: 300/1000 / time=0.276 sec
I0321 13:30:13.736545 140058691233600 base_trainer.py:771] Perf 117266.36 samples/s
I0321 13:30:14.014756 140058691233600 base_trainer.py:769] Step: 301 Lr 0.0304979 Loss scale 4096
I0321 13:30:14.014975 140058691233600 base_trainer.py:770] Train Step: 301/1000 / time=0.276 sec
I0321 13:30:14.015052 140058691233600 base_trainer.py:771] Perf 117647.35 samples/s
I0321 13:30:14.336082 140058691233600 base_trainer.py:769] Step: 302 Lr 0.0304564 Loss scale 4096
I0321 13:30:14.336319 140058691233600 base_trainer.py:770] Train Step: 302/1000 / time=0.319 sec
I0321 13:30:14.336390 140058691233600 base_trainer.py:771] Perf 101906.40 samples/s
I0321 13:30:14.622881 140058691233600 base_trainer.py:769] Step: 303 Lr 0.0304149 Loss scale 4096
I0321 13:30:14.623098 140058691233600 base_trainer.py:770] Train Step: 303/1000 / time=0.284 sec
I0321 13:30:14.623176 140058691233600 base_trainer.py:771] Perf 114273.63 samples/s
I0321 13:30:14.913218 140058691233600 base_trainer.py:769] Step: 304 Lr 0.0303734 Loss scale 4096
I0321 13:30:14.913443 140058691233600 base_trainer.py:770] Train Step: 304/1000 / time=0.287 sec
I0321 13:30:14.913526 140058691233600 base_trainer.py:771] Perf 112955.27 samples/s
I0321 13:30:15.199038 140058691233600 base_trainer.py:769] Step: 305 Lr 0.0303319 Loss scale 4096
I0321 13:30:15.199254 140058691233600 base_trainer.py:770] Train Step: 305/1000 / time=0.283 sec
I0321 13:30:15.199329 140058691233600 base_trainer.py:771] Perf 114559.56 samples/s
I0321 13:30:15.486699 140058691233600 base_trainer.py:769] Step: 306 Lr 0.0302905 Loss scale 4096
I0321 13:30:15.486923 140058691233600 base_trainer.py:770] Train Step: 306/1000 / time=0.285 sec
I0321 13:30:15.487005 140058691233600 base_trainer.py:771] Perf 113978.57 samples/s
I0321 13:30:15.779092 140058691233600 base_trainer.py:769] Step: 307 Lr 0.030249 Loss scale 4096
I0321 13:30:15.779323 140058691233600 base_trainer.py:770] Train Step: 307/1000 / time=0.289 sec
I0321 13:30:15.779417 140058691233600 base_trainer.py:771] Perf 112144.25 samples/s
I0321 13:30:16.064135 140058691233600 base_trainer.py:769] Step: 308 Lr 0.0302075 Loss scale 4096
I0321 13:30:16.064349 140058691233600 base_trainer.py:770] Train Step: 308/1000 / time=0.282 sec
I0321 13:30:16.064425 140058691233600 base_trainer.py:771] Perf 114796.25 samples/s
I0321 13:30:16.363095 140058691233600 base_trainer.py:769] Step: 309 Lr 0.030166 Loss scale 4096
I0321 13:30:16.363311 140058691233600 base_trainer.py:770] Train Step: 309/1000 / time=0.296 sec
I0321 13:30:16.363392 140058691233600 base_trainer.py:771] Perf 109679.01 samples/s
I0321 13:30:16.637758 140058691233600 base_trainer.py:769] Step: 310 Lr 0.0301245 Loss scale 4096
I0321 13:30:16.637977 140058691233600 base_trainer.py:770] Train Step: 310/1000 / time=0.272 sec
I0321 13:30:16.638058 140058691233600 base_trainer.py:771] Perf 119323.87 samples/s
I0321 13:30:16.923603 140058691233600 base_trainer.py:769] Step: 311 Lr 0.030083 Loss scale 4096
I0321 13:30:16.923821 140058691233600 base_trainer.py:770] Train Step: 311/1000 / time=0.283 sec
I0321 13:30:16.923907 140058691233600 base_trainer.py:771] Perf 114639.18 samples/s
I0321 13:30:17.212902 140058691233600 base_trainer.py:769] Step: 312 Lr 0.0300415 Loss scale 4096
I0321 13:30:17.213134 140058691233600 base_trainer.py:770] Train Step: 312/1000 / time=0.286 sec
I0321 13:30:17.213217 140058691233600 base_trainer.py:771] Perf 113290.34 samples/s
I0321 13:30:17.517032 140058691233600 base_trainer.py:769] Step: 313 Lr 0.03 Loss scale 4096
I0321 13:30:17.517255 140058691233600 base_trainer.py:770] Train Step: 313/1000 / time=0.301 sec
I0321 13:30:17.517337 140058691233600 base_trainer.py:771] Perf 107721.98 samples/s
I0321 13:30:17.814991 140058691233600 base_trainer.py:769] Step: 314 Lr 0.0299585 Loss scale 4096
I0321 13:30:17.815213 140058691233600 base_trainer.py:770] Train Step: 314/1000 / time=0.295 sec
I0321 13:30:17.815291 140058691233600 base_trainer.py:771] Perf 109971.01 samples/s
I0321 13:30:18.099828 140058691233600 base_trainer.py:769] Step: 315 Lr 0.029917 Loss scale 4096
I0321 13:30:18.100059 140058691233600 base_trainer.py:770] Train Step: 315/1000 / time=0.282 sec
I0321 13:30:18.100151 140058691233600 base_trainer.py:771] Perf 115036.71 samples/s
I0321 13:30:18.387200 140058691233600 base_trainer.py:769] Step: 316 Lr 0.0298755 Loss scale 4096
I0321 13:30:18.387422 140058691233600 base_trainer.py:770] Train Step: 316/1000 / time=0.284 sec
I0321 13:30:18.387503 140058691233600 base_trainer.py:771] Perf 114042.06 samples/s
I0321 13:30:18.680419 140058691233600 base_trainer.py:769] Step: 317 Lr 0.029834 Loss scale 4096
I0321 13:30:18.680646 140058691233600 base_trainer.py:770] Train Step: 317/1000 / time=0.290 sec
I0321 13:30:18.680733 140058691233600 base_trainer.py:771] Perf 111787.79 samples/s
I0321 13:30:18.966014 140058691233600 base_trainer.py:769] Step: 318 Lr 0.0297925 Loss scale 4096
I0321 13:30:18.966229 140058691233600 base_trainer.py:770] Train Step: 318/1000 / time=0.283 sec
I0321 13:30:18.966316 140058691233600 base_trainer.py:771] Perf 114703.81 samples/s
I0321 13:30:19.257201 140058691233600 base_trainer.py:769] Step: 319 Lr 0.029751 Loss scale 4096
I0321 13:30:19.257428 140058691233600 base_trainer.py:770] Train Step: 319/1000 / time=0.288 sec
I0321 13:30:19.257510 140058691233600 base_trainer.py:771] Perf 112537.75 samples/s
I0321 13:30:19.549539 140058691233600 base_trainer.py:769] Step: 320 Lr 0.0297095 Loss scale 4096
I0321 13:30:19.549763 140058691233600 base_trainer.py:770] Train Step: 320/1000 / time=0.289 sec
I0321 13:30:19.549843 140058691233600 base_trainer.py:771] Perf 112093.72 samples/s
I0321 13:30:19.838086 140058691233600 base_trainer.py:769] Step: 321 Lr 0.0296681 Loss scale 4096
I0321 13:30:19.838307 140058691233600 base_trainer.py:770] Train Step: 321/1000 / time=0.286 sec
I0321 13:30:19.838388 140058691233600 base_trainer.py:771] Perf 113544.71 samples/s
I0321 13:30:20.127527 140058691233600 base_trainer.py:769] Step: 322 Lr 0.0296266 Loss scale 4096
I0321 13:30:20.127750 140058691233600 base_trainer.py:770] Train Step: 322/1000 / time=0.287 sec
I0321 13:30:20.127827 140058691233600 base_trainer.py:771] Perf 113200.83 samples/s
I0321 13:30:20.413439 140058691233600 base_trainer.py:769] Step: 323 Lr 0.0295851 Loss scale 4096
I0321 13:30:20.413672 140058691233600 base_trainer.py:770] Train Step: 323/1000 / time=0.283 sec
I0321 13:30:20.413752 140058691233600 base_trainer.py:771] Perf 114720.54 samples/s
I0321 13:30:20.694830 140058691233600 base_trainer.py:769] Step: 324 Lr 0.0295436 Loss scale 4096
I0321 13:30:20.695053 140058691233600 base_trainer.py:770] Train Step: 324/1000 / time=0.279 sec
I0321 13:30:20.695153 140058691233600 base_trainer.py:771] Perf 116256.40 samples/s
I0321 13:30:20.983883 140058691233600 base_trainer.py:769] Step: 325 Lr 0.0295021 Loss scale 4096
I0321 13:30:20.984106 140058691233600 base_trainer.py:770] Train Step: 325/1000 / time=0.286 sec
I0321 13:30:20.984189 140058691233600 base_trainer.py:771] Perf 113472.19 samples/s
I0321 13:30:21.275906 140058691233600 base_trainer.py:769] Step: 326 Lr 0.0294606 Loss scale 4096
I0321 13:30:21.276113 140058691233600 base_trainer.py:770] Train Step: 326/1000 / time=0.289 sec
I0321 13:30:21.276194 140058691233600 base_trainer.py:771] Perf 112193.18 samples/s
I0321 13:30:21.556960 140058691233600 base_trainer.py:769] Step: 327 Lr 0.0294191 Loss scale 4096
I0321 13:30:21.557182 140058691233600 base_trainer.py:770] Train Step: 327/1000 / time=0.278 sec
I0321 13:30:21.557261 140058691233600 base_trainer.py:771] Perf 116608.11 samples/s
I0321 13:30:21.847164 140058691233600 base_trainer.py:769] Step: 328 Lr 0.0293776 Loss scale 4096
I0321 13:30:21.847386 140058691233600 base_trainer.py:770] Train Step: 328/1000 / time=0.287 sec
I0321 13:30:21.847469 140058691233600 base_trainer.py:771] Perf 112914.97 samples/s
I0321 13:30:22.138421 140058691233600 base_trainer.py:769] Step: 329 Lr 0.0293361 Loss scale 4096
I0321 13:30:22.138643 140058691233600 base_trainer.py:770] Train Step: 329/1000 / time=0.288 sec
I0321 13:30:22.138723 140058691233600 base_trainer.py:771] Perf 112517.18 samples/s
I0321 13:30:22.450851 140058691233600 base_trainer.py:769] Step: 330 Lr 0.0292946 Loss scale 4096
I0321 13:30:22.451066 140058691233600 base_trainer.py:770] Train Step: 330/1000 / time=0.310 sec
I0321 13:30:22.451140 140058691233600 base_trainer.py:771] Perf 104801.16 samples/s
I0321 13:30:22.747032 140058691233600 base_trainer.py:769] Step: 331 Lr 0.0292531 Loss scale 4096
I0321 13:30:22.747251 140058691233600 base_trainer.py:770] Train Step: 331/1000 / time=0.293 sec
I0321 13:30:22.747332 140058691233600 base_trainer.py:771] Perf 110711.97 samples/s
I0321 13:30:23.034167 140058691233600 base_trainer.py:769] Step: 332 Lr 0.0292116 Loss scale 4096
I0321 13:30:23.034388 140058691233600 base_trainer.py:770] Train Step: 332/1000 / time=0.284 sec
I0321 13:30:23.034472 140058691233600 base_trainer.py:771] Perf 114124.64 samples/s
I0321 13:30:23.326747 140058691233600 base_trainer.py:769] Step: 333 Lr 0.0291701 Loss scale 4096
I0321 13:30:23.326953 140058691233600 base_trainer.py:770] Train Step: 333/1000 / time=0.290 sec
I0321 13:30:23.327029 140058691233600 base_trainer.py:771] Perf 111928.48 samples/s
I0321 13:30:23.616461 140058691233600 base_trainer.py:769] Step: 334 Lr 0.0291286 Loss scale 4096
I0321 13:30:23.616682 140058691233600 base_trainer.py:770] Train Step: 334/1000 / time=0.287 sec
I0321 13:30:23.616763 140058691233600 base_trainer.py:771] Perf 113178.81 samples/s
I0321 13:30:23.905324 140058691233600 base_trainer.py:769] Step: 335 Lr 0.0290871 Loss scale 4096
I0321 13:30:23.905534 140058691233600 base_trainer.py:770] Train Step: 335/1000 / time=0.286 sec
I0321 13:30:23.905609 140058691233600 base_trainer.py:771] Perf 113372.14 samples/s
I0321 13:30:24.190706 140058691233600 base_trainer.py:769] Step: 336 Lr 0.0290456 Loss scale 4096
I0321 13:30:24.190930 140058691233600 base_trainer.py:770] Train Step: 336/1000 / time=0.282 sec
I0321 13:30:24.191015 140058691233600 base_trainer.py:771] Perf 114904.62 samples/s
I0321 13:30:24.479255 140058691233600 base_trainer.py:769] Step: 337 Lr 0.0290042 Loss scale 4096
I0321 13:30:24.479466 140058691233600 base_trainer.py:770] Train Step: 337/1000 / time=0.286 sec
I0321 13:30:24.479545 140058691233600 base_trainer.py:771] Perf 113449.47 samples/s
I0321 13:30:24.772575 140058691233600 base_trainer.py:769] Step: 338 Lr 0.0289627 Loss scale 4096
I0321 13:30:24.772797 140058691233600 base_trainer.py:770] Train Step: 338/1000 / time=0.290 sec
I0321 13:30:24.772878 140058691233600 base_trainer.py:771] Perf 111815.40 samples/s
I0321 13:30:25.057939 140058691233600 base_trainer.py:769] Step: 339 Lr 0.0289212 Loss scale 4096
I0321 13:30:25.058161 140058691233600 base_trainer.py:770] Train Step: 339/1000 / time=0.282 sec
I0321 13:30:25.058252 140058691233600 base_trainer.py:771] Perf 114833.61 samples/s
I0321 13:30:25.347033 140058691233600 base_trainer.py:769] Step: 340 Lr 0.0288797 Loss scale 4096
I0321 13:30:25.347259 140058691233600 base_trainer.py:770] Train Step: 340/1000 / time=0.286 sec
I0321 13:30:25.347347 140058691233600 base_trainer.py:771] Perf 113381.18 samples/s
I0321 13:30:25.640106 140058691233600 base_trainer.py:769] Step: 341 Lr 0.0288382 Loss scale 4096
I0321 13:30:25.640344 140058691233600 base_trainer.py:770] Train Step: 341/1000 / time=0.290 sec
I0321 13:30:25.640428 140058691233600 base_trainer.py:771] Perf 111787.97 samples/s
I0321 13:30:25.927609 140058691233600 base_trainer.py:769] Step: 342 Lr 0.0287967 Loss scale 4096
I0321 13:30:25.927826 140058691233600 base_trainer.py:770] Train Step: 342/1000 / time=0.285 sec
I0321 13:30:25.927912 140058691233600 base_trainer.py:771] Perf 113977.06 samples/s
I0321 13:30:26.216393 140058691233600 base_trainer.py:769] Step: 343 Lr 0.0287552 Loss scale 4096
I0321 13:30:26.216609 140058691233600 base_trainer.py:770] Train Step: 343/1000 / time=0.286 sec
I0321 13:30:26.216694 140058691233600 base_trainer.py:771] Perf 113484.71 samples/s
I0321 13:30:26.509673 140058691233600 base_trainer.py:769] Step: 344 Lr 0.0287137 Loss scale 4096
I0321 13:30:26.509896 140058691233600 base_trainer.py:770] Train Step: 344/1000 / time=0.290 sec
I0321 13:30:26.509980 140058691233600 base_trainer.py:771] Perf 111714.33 samples/s
I0321 13:30:26.803048 140058691233600 base_trainer.py:769] Step: 345 Lr 0.0286722 Loss scale 4096
I0321 13:30:26.803275 140058691233600 base_trainer.py:770] Train Step: 345/1000 / time=0.290 sec
I0321 13:30:26.803357 140058691233600 base_trainer.py:771] Perf 111685.81 samples/s
I0321 13:30:27.087726 140058691233600 base_trainer.py:769] Step: 346 Lr 0.0286307 Loss scale 4096
I0321 13:30:27.087939 140058691233600 base_trainer.py:770] Train Step: 346/1000 / time=0.282 sec
I0321 13:30:27.088024 140058691233600 base_trainer.py:771] Perf 115109.23 samples/s
I0321 13:30:27.375537 140058691233600 base_trainer.py:769] Step: 347 Lr 0.0285892 Loss scale 4096
I0321 13:30:27.375756 140058691233600 base_trainer.py:770] Train Step: 347/1000 / time=0.285 sec
I0321 13:30:27.375841 140058691233600 base_trainer.py:771] Perf 113862.61 samples/s
I0321 13:30:27.667721 140058691233600 base_trainer.py:769] Step: 348 Lr 0.0285477 Loss scale 4096
I0321 13:30:27.667943 140058691233600 base_trainer.py:770] Train Step: 348/1000 / time=0.289 sec
I0321 13:30:27.668025 140058691233600 base_trainer.py:771] Perf 112150.18 samples/s
I0321 13:30:27.954012 140058691233600 base_trainer.py:769] Step: 349 Lr 0.0285062 Loss scale 4096
I0321 13:30:27.954219 140058691233600 base_trainer.py:770] Train Step: 349/1000 / time=0.284 sec
I0321 13:30:27.954293 140058691233600 base_trainer.py:771] Perf 114404.60 samples/s
I0321 13:30:28.249077 140058691233600 base_trainer.py:769] Step: 350 Lr 0.0284647 Loss scale 4096
I0321 13:30:28.249299 140058691233600 base_trainer.py:770] Train Step: 350/1000 / time=0.292 sec
I0321 13:30:28.249370 140058691233600 base_trainer.py:771] Perf 111028.93 samples/s
I0321 13:30:28.536400 140058691233600 base_trainer.py:769] Step: 351 Lr 0.0284232 Loss scale 4096
I0321 13:30:28.536616 140058691233600 base_trainer.py:770] Train Step: 351/1000 / time=0.284 sec
I0321 13:30:28.536695 140058691233600 base_trainer.py:771] Perf 114140.15 samples/s
I0321 13:30:28.826706 140058691233600 base_trainer.py:769] Step: 352 Lr 0.0283817 Loss scale 4096
I0321 13:30:28.826920 140058691233600 base_trainer.py:770] Train Step: 352/1000 / time=0.287 sec
I0321 13:30:28.827004 140058691233600 base_trainer.py:771] Perf 112880.94 samples/s
I0321 13:30:29.117774 140058691233600 base_trainer.py:769] Step: 353 Lr 0.0283402 Loss scale 4096
I0321 13:30:29.117982 140058691233600 base_trainer.py:770] Train Step: 353/1000 / time=0.288 sec
I0321 13:30:29.118066 140058691233600 base_trainer.py:771] Perf 112529.89 samples/s
I0321 13:30:29.408912 140058691233600 base_trainer.py:769] Step: 354 Lr 0.0282988 Loss scale 4096
I0321 13:30:29.409138 140058691233600 base_trainer.py:770] Train Step: 354/1000 / time=0.288 sec
I0321 13:30:29.409215 140058691233600 base_trainer.py:771] Perf 112615.50 samples/s
I0321 13:30:29.704824 140058691233600 base_trainer.py:769] Step: 355 Lr 0.0282573 Loss scale 4096
I0321 13:30:29.705038 140058691233600 base_trainer.py:770] Train Step: 355/1000 / time=0.293 sec
I0321 13:30:29.705115 140058691233600 base_trainer.py:771] Perf 110696.64 samples/s
I0321 13:30:29.992292 140058691233600 base_trainer.py:769] Step: 356 Lr 0.0282158 Loss scale 4096
I0321 13:30:29.992520 140058691233600 base_trainer.py:770] Train Step: 356/1000 / time=0.285 sec
I0321 13:30:29.992597 140058691233600 base_trainer.py:771] Perf 114014.62 samples/s
I0321 13:30:30.273214 140058691233600 base_trainer.py:769] Step: 357 Lr 0.0281743 Loss scale 4096
I0321 13:30:30.273429 140058691233600 base_trainer.py:770] Train Step: 357/1000 / time=0.278 sec
I0321 13:30:30.273505 140058691233600 base_trainer.py:771] Perf 116628.91 samples/s
I0321 13:30:30.564884 140058691233600 base_trainer.py:769] Step: 358 Lr 0.0281328 Loss scale 4096
I0321 13:30:30.565112 140058691233600 base_trainer.py:770] Train Step: 358/1000 / time=0.289 sec
I0321 13:30:30.565198 140058691233600 base_trainer.py:771] Perf 112375.56 samples/s
I0321 13:30:30.869727 140058691233600 base_trainer.py:769] Step: 359 Lr 0.0280913 Loss scale 4096
I0321 13:30:30.869936 140058691233600 base_trainer.py:770] Train Step: 359/1000 / time=0.302 sec
I0321 13:30:30.870011 140058691233600 base_trainer.py:771] Perf 107432.54 samples/s
I0321 13:30:31.147222 140058691233600 base_trainer.py:769] Step: 360 Lr 0.0280498 Loss scale 4096
I0321 13:30:31.147459 140058691233600 base_trainer.py:770] Train Step: 360/1000 / time=0.275 sec
I0321 13:30:31.147548 140058691233600 base_trainer.py:771] Perf 118170.45 samples/s
I0321 13:30:31.432790 140058691233600 base_trainer.py:769] Step: 361 Lr 0.0280083 Loss scale 4096
I0321 13:30:31.433020 140058691233600 base_trainer.py:770] Train Step: 361/1000 / time=0.282 sec
I0321 13:30:31.433112 140058691233600 base_trainer.py:771] Perf 114825.86 samples/s
I0321 13:30:31.720488 140058691233600 base_trainer.py:769] Step: 362 Lr 0.0279668 Loss scale 4096
I0321 13:30:31.720705 140058691233600 base_trainer.py:770] Train Step: 362/1000 / time=0.285 sec
I0321 13:30:31.720785 140058691233600 base_trainer.py:771] Perf 113821.33 samples/s
I0321 13:30:32.001171 140058691233600 base_trainer.py:769] Step: 363 Lr 0.0279253 Loss scale 4096
I0321 13:30:32.001379 140058691233600 base_trainer.py:770] Train Step: 363/1000 / time=0.278 sec
I0321 13:30:32.001455 140058691233600 base_trainer.py:771] Perf 116648.59 samples/s
I0321 13:30:32.295340 140058691233600 base_trainer.py:769] Step: 364 Lr 0.0278838 Loss scale 4096
I0321 13:30:32.295560 140058691233600 base_trainer.py:770] Train Step: 364/1000 / time=0.291 sec
I0321 13:30:32.295644 140058691233600 base_trainer.py:771] Perf 111474.73 samples/s
I0321 13:30:51.003397 140058691233600 base_trainer.py:769] Step: 365 Lr 0.0278423 Loss scale 4096
I0321 13:30:51.003642 140058691233600 base_trainer.py:770] Train Step: 365/1000 / time=18.705 sec
I0321 13:30:51.003738 140058691233600 base_trainer.py:771] Perf 1751.56 samples/s
I0321 13:30:51.134927 140058691233600 base_trainer.py:769] Step: 366 Lr 0.0278008 Loss scale 4096
I0321 13:30:51.135140 140058691233600 base_trainer.py:770] Train Step: 366/1000 / time=0.129 sec
I0321 13:30:51.135230 140058691233600 base_trainer.py:771] Perf 248430.73 samples/s
I0321 13:30:51.188942 140058691233600 base_trainer.py:769] Step: 367 Lr 0.0277593 Loss scale 4096
I0321 13:30:51.189160 140058691233600 base_trainer.py:770] Train Step: 367/1000 / time=0.051 sec
I0321 13:30:51.189252 140058691233600 base_trainer.py:771] Perf 609002.07 samples/s
I0321 13:30:51.242704 140058691233600 base_trainer.py:769] Step: 368 Lr 0.0277178 Loss scale 4096
I0321 13:30:51.242924 140058691233600 base_trainer.py:770] Train Step: 368/1000 / time=0.051 sec
I0321 13:30:51.243012 140058691233600 base_trainer.py:771] Perf 608436.27 samples/s
I0321 13:30:51.296457 140058691233600 base_trainer.py:769] Step: 369 Lr 0.0276763 Loss scale 4096
I0321 13:30:51.296679 140058691233600 base_trainer.py:770] Train Step: 369/1000 / time=0.051 sec
I0321 13:30:51.296763 140058691233600 base_trainer.py:771] Perf 610602.39 samples/s
I0321 13:30:51.351258 140058691233600 base_trainer.py:769] Step: 370 Lr 0.0276349 Loss scale 4096
I0321 13:30:51.351472 140058691233600 base_trainer.py:770] Train Step: 370/1000 / time=0.052 sec
I0321 13:30:51.351554 140058691233600 base_trainer.py:771] Perf 597213.44 samples/s
I0321 13:30:51.404315 140058691233600 base_trainer.py:769] Step: 371 Lr 0.0275934 Loss scale 4096
I0321 13:30:51.404528 140058691233600 base_trainer.py:770] Train Step: 371/1000 / time=0.050 sec
I0321 13:30:51.404610 140058691233600 base_trainer.py:771] Perf 617415.97 samples/s
I0321 13:30:51.460174 140058691233600 base_trainer.py:769] Step: 372 Lr 0.0275519 Loss scale 4096
I0321 13:30:51.460413 140058691233600 base_trainer.py:770] Train Step: 372/1000 / time=0.053 sec
I0321 13:30:51.460500 140058691233600 base_trainer.py:771] Perf 587757.89 samples/s
I0321 13:30:51.514104 140058691233600 base_trainer.py:769] Step: 373 Lr 0.0275104 Loss scale 4096
I0321 13:30:51.514324 140058691233600 base_trainer.py:770] Train Step: 373/1000 / time=0.051 sec
I0321 13:30:51.514405 140058691233600 base_trainer.py:771] Perf 607914.54 samples/s
I0321 13:30:51.568953 140058691233600 base_trainer.py:769] Step: 374 Lr 0.0274689 Loss scale 4096
I0321 13:30:51.569308 140058691233600 base_trainer.py:770] Train Step: 374/1000 / time=0.051 sec
I0321 13:30:51.569454 140058691233600 base_trainer.py:771] Perf 602743.51 samples/s
I0321 13:30:51.624105 140058691233600 base_trainer.py:769] Step: 375 Lr 0.0274274 Loss scale 4096
I0321 13:30:51.624350 140058691233600 base_trainer.py:770] Train Step: 375/1000 / time=0.052 sec
I0321 13:30:51.624447 140058691233600 base_trainer.py:771] Perf 590928.55 samples/s
I0321 13:30:51.676917 140058691233600 base_trainer.py:769] Step: 376 Lr 0.0273859 Loss scale 4096
I0321 13:30:51.677138 140058691233600 base_trainer.py:770] Train Step: 376/1000 / time=0.050 sec
I0321 13:30:51.677223 140058691233600 base_trainer.py:771] Perf 618881.91 samples/s
I0321 13:30:51.729897 140058691233600 base_trainer.py:769] Step: 377 Lr 0.0273444 Loss scale 4096
I0321 13:30:51.730122 140058691233600 base_trainer.py:770] Train Step: 377/1000 / time=0.050 sec
I0321 13:30:51.730195 140058691233600 base_trainer.py:771] Perf 617217.99 samples/s
I0321 13:30:51.783494 140058691233600 base_trainer.py:769] Step: 378 Lr 0.0273029 Loss scale 4096
I0321 13:30:51.783718 140058691233600 base_trainer.py:770] Train Step: 378/1000 / time=0.051 sec
I0321 13:30:51.783801 140058691233600 base_trainer.py:771] Perf 611524.14 samples/s
I0321 13:30:51.838418 140058691233600 base_trainer.py:769] Step: 379 Lr 0.0272614 Loss scale 4096
I0321 13:30:51.838639 140058691233600 base_trainer.py:770] Train Step: 379/1000 / time=0.052 sec
I0321 13:30:51.838715 140058691233600 base_trainer.py:771] Perf 595324.72 samples/s
I0321 13:30:51.891492 140058691233600 base_trainer.py:769] Step: 380 Lr 0.0272199 Loss scale 4096
I0321 13:30:51.891721 140058691233600 base_trainer.py:770] Train Step: 380/1000 / time=0.050 sec
I0321 13:30:51.891818 140058691233600 base_trainer.py:771] Perf 619288.70 samples/s
I0321 13:30:51.945992 140058691233600 base_trainer.py:769] Step: 381 Lr 0.0271784 Loss scale 4096
I0321 13:30:51.946208 140058691233600 base_trainer.py:770] Train Step: 381/1000 / time=0.052 sec
I0321 13:30:51.946290 140058691233600 base_trainer.py:771] Perf 601269.27 samples/s
I0321 13:30:51.999358 140058691233600 base_trainer.py:769] Step: 382 Lr 0.0271369 Loss scale 4096
I0321 13:30:51.999570 140058691233600 base_trainer.py:770] Train Step: 382/1000 / time=0.051 sec
I0321 13:30:51.999649 140058691233600 base_trainer.py:771] Perf 613029.05 samples/s
I0321 13:30:52.051352 140058691233600 base_trainer.py:769] Step: 383 Lr 0.0270954 Loss scale 4096
I0321 13:30:52.051580 140058691233600 base_trainer.py:770] Train Step: 383/1000 / time=0.049 sec
I0321 13:30:52.051662 140058691233600 base_trainer.py:771] Perf 632242.59 samples/s
I0321 13:30:52.106264 140058691233600 base_trainer.py:769] Step: 384 Lr 0.0270539 Loss scale 4096
I0321 13:30:52.106490 140058691233600 base_trainer.py:770] Train Step: 384/1000 / time=0.052 sec
I0321 13:30:52.106580 140058691233600 base_trainer.py:771] Perf 596412.88 samples/s
I0321 13:30:52.162348 140058691233600 base_trainer.py:769] Step: 385 Lr 0.0270125 Loss scale 4096
I0321 13:30:52.162559 140058691233600 base_trainer.py:770] Train Step: 385/1000 / time=0.053 sec
I0321 13:30:52.162636 140058691233600 base_trainer.py:771] Perf 583163.03 samples/s
I0321 13:30:52.216831 140058691233600 base_trainer.py:769] Step: 386 Lr 0.026971 Loss scale 4096
I0321 13:30:52.217066 140058691233600 base_trainer.py:770] Train Step: 386/1000 / time=0.051 sec
I0321 13:30:52.217154 140058691233600 base_trainer.py:771] Perf 605501.63 samples/s
I0321 13:30:52.270298 140058691233600 base_trainer.py:769] Step: 387 Lr 0.0269295 Loss scale 4096
I0321 13:30:52.270528 140058691233600 base_trainer.py:770] Train Step: 387/1000 / time=0.051 sec
I0321 13:30:52.270611 140058691233600 base_trainer.py:771] Perf 609735.97 samples/s
I0321 13:30:52.322572 140058691233600 base_trainer.py:769] Step: 388 Lr 0.026888 Loss scale 4096
I0321 13:30:52.322789 140058691233600 base_trainer.py:770] Train Step: 388/1000 / time=0.050 sec
I0321 13:30:52.322861 140058691233600 base_trainer.py:771] Perf 623222.04 samples/s
I0321 13:30:52.376307 140058691233600 base_trainer.py:769] Step: 389 Lr 0.0268465 Loss scale 4096
I0321 13:30:52.376525 140058691233600 base_trainer.py:770] Train Step: 389/1000 / time=0.051 sec
I0321 13:30:52.376607 140058691233600 base_trainer.py:771] Perf 613034.40 samples/s
I0321 13:30:52.432948 140058691233600 base_trainer.py:769] Step: 390 Lr 0.026805 Loss scale 4096
I0321 13:30:52.433336 140058691233600 base_trainer.py:770] Train Step: 390/1000 / time=0.054 sec
I0321 13:30:52.433494 140058691233600 base_trainer.py:771] Perf 580801.29 samples/s
I0321 13:30:52.487252 140058691233600 base_trainer.py:769] Step: 391 Lr 0.0267635 Loss scale 4096
I0321 13:30:52.487475 140058691233600 base_trainer.py:770] Train Step: 391/1000 / time=0.051 sec
I0321 13:30:52.487555 140058691233600 base_trainer.py:771] Perf 602143.56 samples/s
I0321 13:30:52.540654 140058691233600 base_trainer.py:769] Step: 392 Lr 0.026722 Loss scale 4096
I0321 13:30:52.540898 140058691233600 base_trainer.py:770] Train Step: 392/1000 / time=0.050 sec
I0321 13:30:52.540987 140058691233600 base_trainer.py:771] Perf 614466.43 samples/s
I0321 13:30:52.594721 140058691233600 base_trainer.py:769] Step: 393 Lr 0.0266805 Loss scale 4096
I0321 13:30:52.594934 140058691233600 base_trainer.py:770] Train Step: 393/1000 / time=0.051 sec
I0321 13:30:52.595010 140058691233600 base_trainer.py:771] Perf 603942.85 samples/s
I0321 13:30:52.651612 140058691233600 base_trainer.py:769] Step: 394 Lr 0.026639 Loss scale 4096
I0321 13:30:52.651838 140058691233600 base_trainer.py:770] Train Step: 394/1000 / time=0.054 sec
I0321 13:30:52.651922 140058691233600 base_trainer.py:771] Perf 577391.46 samples/s
I0321 13:30:52.703837 140058691233600 base_trainer.py:769] Step: 395 Lr 0.0265975 Loss scale 4096
I0321 13:30:52.704051 140058691233600 base_trainer.py:770] Train Step: 395/1000 / time=0.049 sec
I0321 13:30:52.704133 140058691233600 base_trainer.py:771] Perf 626852.62 samples/s
I0321 13:30:52.757825 140058691233600 base_trainer.py:769] Step: 396 Lr 0.026556 Loss scale 4096
I0321 13:30:52.758098 140058691233600 base_trainer.py:770] Train Step: 396/1000 / time=0.050 sec
I0321 13:30:52.758199 140058691233600 base_trainer.py:771] Perf 614199.66 samples/s
I0321 13:30:52.808852 140058691233600 base_trainer.py:769] Step: 397 Lr 0.0265145 Loss scale 4096
I0321 13:30:52.809072 140058691233600 base_trainer.py:770] Train Step: 397/1000 / time=0.048 sec
I0321 13:30:52.809153 140058691233600 base_trainer.py:771] Perf 635059.30 samples/s
I0321 13:30:52.859120 140058691233600 base_trainer.py:769] Step: 398 Lr 0.026473 Loss scale 4096
I0321 13:30:52.859346 140058691233600 base_trainer.py:770] Train Step: 398/1000 / time=0.047 sec
I0321 13:30:52.859428 140058691233600 base_trainer.py:771] Perf 650970.93 samples/s
I0321 13:30:52.913921 140058691233600 base_trainer.py:769] Step: 399 Lr 0.0264315 Loss scale 4096
I0321 13:30:52.914133 140058691233600 base_trainer.py:770] Train Step: 399/1000 / time=0.052 sec
I0321 13:30:52.914213 140058691233600 base_trainer.py:771] Perf 598081.62 samples/s
I0321 13:30:52.968072 140058691233600 base_trainer.py:769] Step: 400 Lr 0.02639 Loss scale 4096
I0321 13:30:52.968353 140058691233600 base_trainer.py:770] Train Step: 400/1000 / time=0.051 sec
I0321 13:30:52.968483 140058691233600 base_trainer.py:771] Perf 606861.33 samples/s
I0321 13:30:53.019447 140058691233600 base_trainer.py:769] Step: 401 Lr 0.0263485 Loss scale 4096
I0321 13:30:53.019675 140058691233600 base_trainer.py:770] Train Step: 401/1000 / time=0.048 sec
I0321 13:30:53.019760 140058691233600 base_trainer.py:771] Perf 635794.21 samples/s
I0321 13:30:53.075932 140058691233600 base_trainer.py:769] Step: 402 Lr 0.0263071 Loss scale 4096
I0321 13:30:53.076151 140058691233600 base_trainer.py:770] Train Step: 402/1000 / time=0.054 sec
I0321 13:30:53.076244 140058691233600 base_trainer.py:771] Perf 580623.89 samples/s
I0321 13:30:53.128916 140058691233600 base_trainer.py:769] Step: 403 Lr 0.0262656 Loss scale 4096
I0321 13:30:53.129139 140058691233600 base_trainer.py:770] Train Step: 403/1000 / time=0.050 sec
I0321 13:30:53.129217 140058691233600 base_trainer.py:771] Perf 618204.29 samples/s
I0321 13:30:53.181636 140058691233600 base_trainer.py:769] Step: 404 Lr 0.0262241 Loss scale 4096
I0321 13:30:53.181851 140058691233600 base_trainer.py:770] Train Step: 404/1000 / time=0.050 sec
I0321 13:30:53.181930 140058691233600 base_trainer.py:771] Perf 622623.90 samples/s
I0321 13:30:53.235324 140058691233600 base_trainer.py:769] Step: 405 Lr 0.0261826 Loss scale 4096
I0321 13:30:53.235553 140058691233600 base_trainer.py:770] Train Step: 405/1000 / time=0.051 sec
I0321 13:30:53.235657 140058691233600 base_trainer.py:771] Perf 610536.85 samples/s
I0321 13:30:53.289727 140058691233600 base_trainer.py:769] Step: 406 Lr 0.0261411 Loss scale 4096
I0321 13:30:53.289956 140058691233600 base_trainer.py:770] Train Step: 406/1000 / time=0.051 sec
I0321 13:30:53.290041 140058691233600 base_trainer.py:771] Perf 601725.55 samples/s
I0321 13:30:53.341156 140058691233600 base_trainer.py:769] Step: 407 Lr 0.0260996 Loss scale 4096
I0321 13:30:53.341370 140058691233600 base_trainer.py:770] Train Step: 407/1000 / time=0.049 sec
I0321 13:30:53.341446 140058691233600 base_trainer.py:771] Perf 636301.94 samples/s
I0321 13:30:53.395369 140058691233600 base_trainer.py:769] Step: 408 Lr 0.0260581 Loss scale 4096
I0321 13:30:53.395595 140058691233600 base_trainer.py:770] Train Step: 408/1000 / time=0.051 sec
I0321 13:30:53.395671 140058691233600 base_trainer.py:771] Perf 603658.39 samples/s
I0321 13:30:53.445892 140058691233600 base_trainer.py:769] Step: 409 Lr 0.0260166 Loss scale 4096
I0321 13:30:53.446098 140058691233600 base_trainer.py:770] Train Step: 409/1000 / time=0.048 sec
I0321 13:30:53.446173 140058691233600 base_trainer.py:771] Perf 648012.79 samples/s
I0321 13:30:53.498911 140058691233600 base_trainer.py:769] Step: 410 Lr 0.0259751 Loss scale 4096
I0321 13:30:53.499179 140058691233600 base_trainer.py:770] Train Step: 410/1000 / time=0.050 sec
I0321 13:30:53.499273 140058691233600 base_trainer.py:771] Perf 623138.11 samples/s
I0321 13:30:53.551476 140058691233600 base_trainer.py:769] Step: 411 Lr 0.0259336 Loss scale 4096
I0321 13:30:53.551697 140058691233600 base_trainer.py:770] Train Step: 411/1000 / time=0.050 sec
I0321 13:30:53.551791 140058691233600 base_trainer.py:771] Perf 621272.02 samples/s
I0321 13:30:53.603507 140058691233600 base_trainer.py:769] Step: 412 Lr 0.0258921 Loss scale 4096
I0321 13:30:53.603721 140058691233600 base_trainer.py:770] Train Step: 412/1000 / time=0.049 sec
I0321 13:30:53.603799 140058691233600 base_trainer.py:771] Perf 627074.55 samples/s
I0321 13:30:53.657227 140058691233600 base_trainer.py:769] Step: 413 Lr 0.0258506 Loss scale 4096
I0321 13:30:53.657436 140058691233600 base_trainer.py:770] Train Step: 413/1000 / time=0.051 sec
I0321 13:30:53.657517 140058691233600 base_trainer.py:771] Perf 610004.45 samples/s
I0321 13:30:53.714231 140058691233600 base_trainer.py:769] Step: 414 Lr 0.0258091 Loss scale 4096
I0321 13:30:53.714476 140058691233600 base_trainer.py:770] Train Step: 414/1000 / time=0.054 sec
I0321 13:30:53.714584 140058691233600 base_trainer.py:771] Perf 582080.83 samples/s
I0321 13:30:53.767631 140058691233600 base_trainer.py:769] Step: 415 Lr 0.0257676 Loss scale 4096
I0321 13:30:53.767857 140058691233600 base_trainer.py:770] Train Step: 415/1000 / time=0.050 sec
I0321 13:30:53.767938 140058691233600 base_trainer.py:771] Perf 607456.70 samples/s
I0321 13:30:53.820847 140058691233600 base_trainer.py:769] Step: 416 Lr 0.0257261 Loss scale 4096
I0321 13:30:53.821066 140058691233600 base_trainer.py:770] Train Step: 416/1000 / time=0.050 sec
I0321 13:30:53.821144 140058691233600 base_trainer.py:771] Perf 617156.50 samples/s
I0321 13:30:53.874657 140058691233600 base_trainer.py:769] Step: 417 Lr 0.0256846 Loss scale 4096
I0321 13:30:53.874862 140058691233600 base_trainer.py:770] Train Step: 417/1000 / time=0.051 sec
I0321 13:30:53.874939 140058691233600 base_trainer.py:771] Perf 605703.80 samples/s
I0321 13:30:53.926369 140058691233600 base_trainer.py:769] Step: 418 Lr 0.0256432 Loss scale 4096
I0321 13:30:53.926575 140058691233600 base_trainer.py:770] Train Step: 418/1000 / time=0.049 sec
I0321 13:30:53.926650 140058691233600 base_trainer.py:771] Perf 633452.39 samples/s
I0321 13:30:53.979197 140058691233600 base_trainer.py:769] Step: 419 Lr 0.0256017 Loss scale 4096
I0321 13:30:53.979406 140058691233600 base_trainer.py:770] Train Step: 419/1000 / time=0.050 sec
I0321 13:30:53.979484 140058691233600 base_trainer.py:771] Perf 620765.48 samples/s
I0321 13:30:54.034675 140058691233600 base_trainer.py:769] Step: 420 Lr 0.0255602 Loss scale 4096
I0321 13:30:54.034908 140058691233600 base_trainer.py:770] Train Step: 420/1000 / time=0.052 sec
I0321 13:30:54.035016 140058691233600 base_trainer.py:771] Perf 601008.59 samples/s
I0321 13:30:54.089221 140058691233600 base_trainer.py:769] Step: 421 Lr 0.0255187 Loss scale 4096
I0321 13:30:54.089443 140058691233600 base_trainer.py:770] Train Step: 421/1000 / time=0.052 sec
I0321 13:30:54.089514 140058691233600 base_trainer.py:771] Perf 589964.87 samples/s
I0321 13:30:54.140365 140058691233600 base_trainer.py:769] Step: 422 Lr 0.0254772 Loss scale 4096
I0321 13:30:54.140569 140058691233600 base_trainer.py:770] Train Step: 422/1000 / time=0.048 sec
I0321 13:30:54.140645 140058691233600 base_trainer.py:771] Perf 641354.76 samples/s
I0321 13:30:54.192860 140058691233600 base_trainer.py:769] Step: 423 Lr 0.0254357 Loss scale 4096
I0321 13:30:54.193070 140058691233600 base_trainer.py:770] Train Step: 423/1000 / time=0.050 sec
I0321 13:30:54.193145 140058691233600 base_trainer.py:771] Perf 625428.83 samples/s
I0321 13:30:54.246703 140058691233600 base_trainer.py:769] Step: 424 Lr 0.0253942 Loss scale 4096
I0321 13:30:54.246931 140058691233600 base_trainer.py:770] Train Step: 424/1000 / time=0.051 sec
I0321 13:30:54.247023 140058691233600 base_trainer.py:771] Perf 611644.10 samples/s
I0321 13:30:54.300980 140058691233600 base_trainer.py:769] Step: 425 Lr 0.0253527 Loss scale 4096
I0321 13:30:54.301190 140058691233600 base_trainer.py:770] Train Step: 425/1000 / time=0.051 sec
I0321 13:30:54.301268 140058691233600 base_trainer.py:771] Perf 602212.33 samples/s
I0321 13:30:54.353426 140058691233600 base_trainer.py:769] Step: 426 Lr 0.0253112 Loss scale 4096
I0321 13:30:54.353659 140058691233600 base_trainer.py:770] Train Step: 426/1000 / time=0.049 sec
I0321 13:30:54.353746 140058691233600 base_trainer.py:771] Perf 636106.05 samples/s
I0321 13:30:54.407178 140058691233600 base_trainer.py:769] Step: 427 Lr 0.0252697 Loss scale 4096
I0321 13:30:54.407399 140058691233600 base_trainer.py:770] Train Step: 427/1000 / time=0.051 sec
I0321 13:30:54.407485 140058691233600 base_trainer.py:771] Perf 598769.42 samples/s
I0321 13:30:54.459831 140058691233600 base_trainer.py:769] Step: 428 Lr 0.0252282 Loss scale 4096
I0321 13:30:54.460046 140058691233600 base_trainer.py:770] Train Step: 428/1000 / time=0.050 sec
I0321 13:30:54.460124 140058691233600 base_trainer.py:771] Perf 622909.27 samples/s
I0321 13:30:54.514317 140058691233600 base_trainer.py:769] Step: 429 Lr 0.0251867 Loss scale 4096
I0321 13:30:54.514535 140058691233600 base_trainer.py:770] Train Step: 429/1000 / time=0.052 sec
I0321 13:30:54.514625 140058691233600 base_trainer.py:771] Perf 601362.92 samples/s
I0321 13:30:54.566240 140058691233600 base_trainer.py:769] Step: 430 Lr 0.0251452 Loss scale 4096
I0321 13:30:54.566441 140058691233600 base_trainer.py:770] Train Step: 430/1000 / time=0.049 sec
I0321 13:30:54.566517 140058691233600 base_trainer.py:771] Perf 628412.07 samples/s
I0321 13:30:54.621115 140058691233600 base_trainer.py:769] Step: 431 Lr 0.0251037 Loss scale 4096
I0321 13:30:54.621323 140058691233600 base_trainer.py:770] Train Step: 431/1000 / time=0.052 sec
I0321 13:30:54.621398 140058691233600 base_trainer.py:771] Perf 598517.15 samples/s
I0321 13:30:54.675015 140058691233600 base_trainer.py:769] Step: 432 Lr 0.0250622 Loss scale 4096
I0321 13:30:54.675273 140058691233600 base_trainer.py:770] Train Step: 432/1000 / time=0.051 sec
I0321 13:30:54.675359 140058691233600 base_trainer.py:771] Perf 611689.95 samples/s
I0321 13:30:54.725710 140058691233600 base_trainer.py:769] Step: 433 Lr 0.0250207 Loss scale 4096
I0321 13:30:54.725916 140058691233600 base_trainer.py:770] Train Step: 433/1000 / time=0.048 sec
I0321 13:30:54.725991 140058691233600 base_trainer.py:771] Perf 641131.75 samples/s
I0321 13:30:54.778362 140058691233600 base_trainer.py:769] Step: 434 Lr 0.0249793 Loss scale 4096
I0321 13:30:54.778578 140058691233600 base_trainer.py:770] Train Step: 434/1000 / time=0.050 sec
I0321 13:30:54.778664 140058691233600 base_trainer.py:771] Perf 624371.09 samples/s
I0321 13:30:54.831225 140058691233600 base_trainer.py:769] Step: 435 Lr 0.0249378 Loss scale 4096
I0321 13:30:54.831449 140058691233600 base_trainer.py:770] Train Step: 435/1000 / time=0.050 sec
I0321 13:30:54.831533 140058691233600 base_trainer.py:771] Perf 620373.20 samples/s
I0321 13:30:55.000082 140058691233600 base_trainer.py:769] Step: 436 Lr 0.0248963 Loss scale 4096
I0321 13:30:55.000318 140058691233600 base_trainer.py:770] Train Step: 436/1000 / time=0.166 sec
I0321 13:30:55.000392 140058691233600 base_trainer.py:771] Perf 193828.32 samples/s
I0321 13:30:55.305665 140058691233600 base_trainer.py:769] Step: 437 Lr 0.0248548 Loss scale 4096
I0321 13:30:55.305872 140058691233600 base_trainer.py:770] Train Step: 437/1000 / time=0.303 sec
I0321 13:30:55.305948 140058691233600 base_trainer.py:771] Perf 107252.20 samples/s
I0321 13:30:55.619396 140058691233600 base_trainer.py:769] Step: 438 Lr 0.0248133 Loss scale 4096
I0321 13:30:55.619758 140058691233600 base_trainer.py:770] Train Step: 438/1000 / time=0.311 sec
I0321 13:30:55.619892 140058691233600 base_trainer.py:771] Perf 104596.48 samples/s
I0321 13:30:55.953821 140058691233600 base_trainer.py:769] Step: 439 Lr 0.0247718 Loss scale 4096
I0321 13:30:55.954049 140058691233600 base_trainer.py:770] Train Step: 439/1000 / time=0.331 sec
I0321 13:30:55.954125 140058691233600 base_trainer.py:771] Perf 97835.57 samples/s
I0321 13:30:56.261795 140058691233600 base_trainer.py:769] Step: 440 Lr 0.0247303 Loss scale 4096
I0321 13:30:56.262006 140058691233600 base_trainer.py:770] Train Step: 440/1000 / time=0.305 sec
I0321 13:30:56.262083 140058691233600 base_trainer.py:771] Perf 106460.81 samples/s
I0321 13:30:56.571866 140058691233600 base_trainer.py:769] Step: 441 Lr 0.0246888 Loss scale 4096
I0321 13:30:56.572088 140058691233600 base_trainer.py:770] Train Step: 441/1000 / time=0.307 sec
I0321 13:30:56.572167 140058691233600 base_trainer.py:771] Perf 105710.57 samples/s
I0321 13:30:56.875368 140058691233600 base_trainer.py:769] Step: 442 Lr 0.0246473 Loss scale 4096
I0321 13:30:56.875583 140058691233600 base_trainer.py:770] Train Step: 442/1000 / time=0.301 sec
I0321 13:30:56.875658 140058691233600 base_trainer.py:771] Perf 107899.90 samples/s
I0321 13:30:57.188643 140058691233600 base_trainer.py:769] Step: 443 Lr 0.0246058 Loss scale 4096
I0321 13:30:57.188867 140058691233600 base_trainer.py:770] Train Step: 443/1000 / time=0.310 sec
I0321 13:30:57.188948 140058691233600 base_trainer.py:771] Perf 104678.90 samples/s
I0321 13:30:57.507081 140058691233600 base_trainer.py:769] Step: 444 Lr 0.0245643 Loss scale 4096
I0321 13:30:57.507300 140058691233600 base_trainer.py:770] Train Step: 444/1000 / time=0.315 sec
I0321 13:30:57.507383 140058691233600 base_trainer.py:771] Perf 102909.94 samples/s
I0321 13:30:57.817035 140058691233600 base_trainer.py:769] Step: 445 Lr 0.0245228 Loss scale 4096
I0321 13:30:57.817251 140058691233600 base_trainer.py:770] Train Step: 445/1000 / time=0.307 sec
I0321 13:30:57.817337 140058691233600 base_trainer.py:771] Perf 105699.80 samples/s
I0321 13:30:58.119452 140058691233600 base_trainer.py:769] Step: 446 Lr 0.0244813 Loss scale 4096
I0321 13:30:58.119678 140058691233600 base_trainer.py:770] Train Step: 446/1000 / time=0.300 sec
I0321 13:30:58.119768 140058691233600 base_trainer.py:771] Perf 108326.15 samples/s
I0321 13:30:58.436377 140058691233600 base_trainer.py:769] Step: 447 Lr 0.0244398 Loss scale 4096
I0321 13:30:58.436597 140058691233600 base_trainer.py:770] Train Step: 447/1000 / time=0.314 sec
I0321 13:30:58.436680 140058691233600 base_trainer.py:771] Perf 103417.50 samples/s
I0321 13:30:58.750103 140058691233600 base_trainer.py:769] Step: 448 Lr 0.0243983 Loss scale 4096
I0321 13:30:58.750325 140058691233600 base_trainer.py:770] Train Step: 448/1000 / time=0.311 sec
I0321 13:30:58.750406 140058691233600 base_trainer.py:771] Perf 104448.23 samples/s
I0321 13:30:59.067973 140058691233600 base_trainer.py:769] Step: 449 Lr 0.0243568 Loss scale 4096
I0321 13:30:59.068184 140058691233600 base_trainer.py:770] Train Step: 449/1000 / time=0.315 sec
I0321 13:30:59.068271 140058691233600 base_trainer.py:771] Perf 103023.89 samples/s
I0321 13:30:59.381081 140058691233600 base_trainer.py:769] Step: 450 Lr 0.0243153 Loss scale 4096
I0321 13:30:59.381314 140058691233600 base_trainer.py:770] Train Step: 450/1000 / time=0.310 sec
I0321 13:30:59.381402 140058691233600 base_trainer.py:771] Perf 104756.90 samples/s
I0321 13:30:59.704822 140058691233600 base_trainer.py:769] Step: 451 Lr 0.0242739 Loss scale 4096
I0321 13:30:59.705051 140058691233600 base_trainer.py:770] Train Step: 451/1000 / time=0.321 sec
I0321 13:30:59.705200 140058691233600 base_trainer.py:771] Perf 101227.02 samples/s
I0321 13:31:00.028759 140058691233600 base_trainer.py:769] Step: 452 Lr 0.0242324 Loss scale 4096
I0321 13:31:00.028971 140058691233600 base_trainer.py:770] Train Step: 452/1000 / time=0.321 sec
I0321 13:31:00.029047 140058691233600 base_trainer.py:771] Perf 101111.21 samples/s
I0321 13:31:00.349364 140058691233600 base_trainer.py:769] Step: 453 Lr 0.0241909 Loss scale 4096
I0321 13:31:00.349577 140058691233600 base_trainer.py:770] Train Step: 453/1000 / time=0.318 sec
I0321 13:31:00.349653 140058691233600 base_trainer.py:771] Perf 102155.85 samples/s
I0321 13:31:00.678704 140058691233600 base_trainer.py:769] Step: 454 Lr 0.0241494 Loss scale 4096
I0321 13:31:00.678916 140058691233600 base_trainer.py:770] Train Step: 454/1000 / time=0.326 sec
I0321 13:31:00.678992 140058691233600 base_trainer.py:771] Perf 99524.92 samples/s
I0321 13:31:00.998427 140058691233600 base_trainer.py:769] Step: 455 Lr 0.0241079 Loss scale 4096
I0321 13:31:00.998660 140058691233600 base_trainer.py:770] Train Step: 455/1000 / time=0.317 sec
I0321 13:31:00.998790 140058691233600 base_trainer.py:771] Perf 102585.00 samples/s
I0321 13:31:01.305479 140058691233600 base_trainer.py:769] Step: 456 Lr 0.0240664 Loss scale 4096
I0321 13:31:01.305700 140058691233600 base_trainer.py:770] Train Step: 456/1000 / time=0.304 sec
I0321 13:31:01.305781 140058691233600 base_trainer.py:771] Perf 106670.14 samples/s
I0321 13:31:01.617187 140058691233600 base_trainer.py:769] Step: 457 Lr 0.0240249 Loss scale 4096
I0321 13:31:01.617410 140058691233600 base_trainer.py:770] Train Step: 457/1000 / time=0.309 sec
I0321 13:31:01.617492 140058691233600 base_trainer.py:771] Perf 105108.85 samples/s
I0321 13:31:01.925930 140058691233600 base_trainer.py:769] Step: 458 Lr 0.0239834 Loss scale 4096
I0321 13:31:01.926142 140058691233600 base_trainer.py:770] Train Step: 458/1000 / time=0.306 sec
I0321 13:31:01.926218 140058691233600 base_trainer.py:771] Perf 106083.00 samples/s
I0321 13:31:02.236239 140058691233600 base_trainer.py:769] Step: 459 Lr 0.0239419 Loss scale 4096
I0321 13:31:02.236484 140058691233600 base_trainer.py:770] Train Step: 459/1000 / time=0.308 sec
I0321 13:31:02.236562 140058691233600 base_trainer.py:771] Perf 105591.38 samples/s
I0321 13:31:02.538723 140058691233600 base_trainer.py:769] Step: 460 Lr 0.0239004 Loss scale 4096
I0321 13:31:02.538946 140058691233600 base_trainer.py:770] Train Step: 460/1000 / time=0.300 sec
I0321 13:31:02.539028 140058691233600 base_trainer.py:771] Perf 108390.89 samples/s
I0321 13:31:02.851352 140058691233600 base_trainer.py:769] Step: 461 Lr 0.0238589 Loss scale 4096
I0321 13:31:02.851569 140058691233600 base_trainer.py:770] Train Step: 461/1000 / time=0.310 sec
I0321 13:31:02.851659 140058691233600 base_trainer.py:771] Perf 104819.29 samples/s
I0321 13:31:03.170957 140058691233600 base_trainer.py:769] Step: 462 Lr 0.0238174 Loss scale 4096
I0321 13:31:03.171179 140058691233600 base_trainer.py:770] Train Step: 462/1000 / time=0.317 sec
I0321 13:31:03.171258 140058691233600 base_trainer.py:771] Perf 102524.45 samples/s
I0321 13:31:03.482943 140058691233600 base_trainer.py:769] Step: 463 Lr 0.0237759 Loss scale 4096
I0321 13:31:03.483179 140058691233600 base_trainer.py:770] Train Step: 463/1000 / time=0.309 sec
I0321 13:31:03.483263 140058691233600 base_trainer.py:771] Perf 105070.29 samples/s
I0321 13:31:03.791136 140058691233600 base_trainer.py:769] Step: 464 Lr 0.0237344 Loss scale 4096
I0321 13:31:03.791367 140058691233600 base_trainer.py:770] Train Step: 464/1000 / time=0.305 sec
I0321 13:31:03.791456 140058691233600 base_trainer.py:771] Perf 106302.10 samples/s
I0321 13:31:04.138384 140058691233600 base_trainer.py:769] Step: 465 Lr 0.0236929 Loss scale 4096
I0321 13:31:04.138603 140058691233600 base_trainer.py:770] Train Step: 465/1000 / time=0.344 sec
I0321 13:31:04.138681 140058691233600 base_trainer.py:771] Perf 94377.49 samples/s
I0321 13:31:04.450216 140058691233600 base_trainer.py:769] Step: 466 Lr 0.0236515 Loss scale 4096
I0321 13:31:04.450443 140058691233600 base_trainer.py:770] Train Step: 466/1000 / time=0.309 sec
I0321 13:31:04.450528 140058691233600 base_trainer.py:771] Perf 105072.12 samples/s
I0321 13:31:04.770145 140058691233600 base_trainer.py:769] Step: 467 Lr 0.02361 Loss scale 4096
I0321 13:31:04.770422 140058691233600 base_trainer.py:770] Train Step: 467/1000 / time=0.316 sec
I0321 13:31:04.770514 140058691233600 base_trainer.py:771] Perf 102611.84 samples/s
I0321 13:31:05.091056 140058691233600 base_trainer.py:769] Step: 468 Lr 0.0235685 Loss scale 4096
I0321 13:31:05.091265 140058691233600 base_trainer.py:770] Train Step: 468/1000 / time=0.318 sec
I0321 13:31:05.091343 140058691233600 base_trainer.py:771] Perf 101863.12 samples/s
I0321 13:31:05.405760 140058691233600 base_trainer.py:769] Step: 469 Lr 0.023527 Loss scale 4096
I0321 13:31:05.405972 140058691233600 base_trainer.py:770] Train Step: 469/1000 / time=0.312 sec
I0321 13:31:05.406051 140058691233600 base_trainer.py:771] Perf 104147.99 samples/s
I0321 13:31:05.717146 140058691233600 base_trainer.py:769] Step: 470 Lr 0.0234855 Loss scale 4096
I0321 13:31:05.717373 140058691233600 base_trainer.py:770] Train Step: 470/1000 / time=0.308 sec
I0321 13:31:05.717459 140058691233600 base_trainer.py:771] Perf 105322.08 samples/s
I0321 13:31:06.030047 140058691233600 base_trainer.py:769] Step: 471 Lr 0.023444 Loss scale 4096
I0321 13:31:06.030255 140058691233600 base_trainer.py:770] Train Step: 471/1000 / time=0.310 sec
I0321 13:31:06.030330 140058691233600 base_trainer.py:771] Perf 104619.62 samples/s
I0321 13:31:06.356919 140058691233600 base_trainer.py:769] Step: 472 Lr 0.0234025 Loss scale 4096
I0321 13:31:06.357144 140058691233600 base_trainer.py:770] Train Step: 472/1000 / time=0.324 sec
I0321 13:31:06.357230 140058691233600 base_trainer.py:771] Perf 100303.95 samples/s
I0321 13:31:06.665609 140058691233600 base_trainer.py:769] Step: 473 Lr 0.023361 Loss scale 4096
I0321 13:31:06.665822 140058691233600 base_trainer.py:770] Train Step: 473/1000 / time=0.306 sec
I0321 13:31:06.665898 140058691233600 base_trainer.py:771] Perf 106080.26 samples/s
I0321 13:31:06.972151 140058691233600 base_trainer.py:769] Step: 474 Lr 0.0233195 Loss scale 4096
I0321 13:31:06.972400 140058691233600 base_trainer.py:770] Train Step: 474/1000 / time=0.303 sec
I0321 13:31:06.972498 140058691233600 base_trainer.py:771] Perf 107062.21 samples/s
I0321 13:31:07.286213 140058691233600 base_trainer.py:769] Step: 475 Lr 0.023278 Loss scale 4096
I0321 13:31:07.286429 140058691233600 base_trainer.py:770] Train Step: 475/1000 / time=0.311 sec
I0321 13:31:07.286504 140058691233600 base_trainer.py:771] Perf 104194.63 samples/s
I0321 13:31:07.591215 140058691233600 base_trainer.py:769] Step: 476 Lr 0.0232365 Loss scale 4096
I0321 13:31:07.591562 140058691233600 base_trainer.py:770] Train Step: 476/1000 / time=0.302 sec
I0321 13:31:07.591647 140058691233600 base_trainer.py:771] Perf 107538.76 samples/s
I0321 13:31:07.904457 140058691233600 base_trainer.py:769] Step: 477 Lr 0.023195 Loss scale 4096
I0321 13:31:07.904677 140058691233600 base_trainer.py:770] Train Step: 477/1000 / time=0.310 sec
I0321 13:31:07.904755 140058691233600 base_trainer.py:771] Perf 104570.64 samples/s
I0321 13:31:08.227746 140058691233600 base_trainer.py:769] Step: 478 Lr 0.0231535 Loss scale 4096
I0321 13:31:08.227972 140058691233600 base_trainer.py:770] Train Step: 478/1000 / time=0.320 sec
I0321 13:31:08.228059 140058691233600 base_trainer.py:771] Perf 101360.83 samples/s
I0321 13:31:08.527526 140058691233600 base_trainer.py:769] Step: 479 Lr 0.023112 Loss scale 4096
I0321 13:31:08.527783 140058691233600 base_trainer.py:770] Train Step: 479/1000 / time=0.296 sec
I0321 13:31:08.527896 140058691233600 base_trainer.py:771] Perf 109445.22 samples/s
I0321 13:31:08.842200 140058691233600 base_trainer.py:769] Step: 480 Lr 0.0230705 Loss scale 4096
I0321 13:31:08.842421 140058691233600 base_trainer.py:770] Train Step: 480/1000 / time=0.312 sec
I0321 13:31:08.842509 140058691233600 base_trainer.py:771] Perf 104052.39 samples/s
I0321 13:31:09.144893 140058691233600 base_trainer.py:769] Step: 481 Lr 0.023029 Loss scale 4096
I0321 13:31:09.145113 140058691233600 base_trainer.py:770] Train Step: 481/1000 / time=0.300 sec
I0321 13:31:09.145199 140058691233600 base_trainer.py:771] Perf 108203.89 samples/s
I0321 13:31:09.456741 140058691233600 base_trainer.py:769] Step: 482 Lr 0.0229876 Loss scale 4096
I0321 13:31:09.456961 140058691233600 base_trainer.py:770] Train Step: 482/1000 / time=0.309 sec
I0321 13:31:09.457040 140058691233600 base_trainer.py:771] Perf 105058.85 samples/s
I0321 13:31:09.775051 140058691233600 base_trainer.py:769] Step: 483 Lr 0.0229461 Loss scale 4096
I0321 13:31:09.775263 140058691233600 base_trainer.py:770] Train Step: 483/1000 / time=0.316 sec
I0321 13:31:09.775346 140058691233600 base_trainer.py:771] Perf 102927.26 samples/s
I0321 13:31:10.084440 140058691233600 base_trainer.py:769] Step: 484 Lr 0.0229046 Loss scale 4096
I0321 13:31:10.084651 140058691233600 base_trainer.py:770] Train Step: 484/1000 / time=0.307 sec
I0321 13:31:10.084727 140058691233600 base_trainer.py:771] Perf 105898.09 samples/s
I0321 13:31:10.386359 140058691233600 base_trainer.py:769] Step: 485 Lr 0.0228631 Loss scale 4096
I0321 13:31:10.386567 140058691233600 base_trainer.py:770] Train Step: 485/1000 / time=0.299 sec
I0321 13:31:10.386645 140058691233600 base_trainer.py:771] Perf 108584.38 samples/s
I0321 13:31:10.693924 140058691233600 base_trainer.py:769] Step: 486 Lr 0.0228216 Loss scale 4096
I0321 13:31:10.694134 140058691233600 base_trainer.py:770] Train Step: 486/1000 / time=0.305 sec
I0321 13:31:10.694212 140058691233600 base_trainer.py:771] Perf 106526.04 samples/s
I0321 13:31:11.006195 140058691233600 base_trainer.py:769] Step: 487 Lr 0.0227801 Loss scale 4096
I0321 13:31:11.006414 140058691233600 base_trainer.py:770] Train Step: 487/1000 / time=0.309 sec
I0321 13:31:11.006491 140058691233600 base_trainer.py:771] Perf 104973.02 samples/s
I0321 13:31:11.324093 140058691233600 base_trainer.py:769] Step: 488 Lr 0.0227386 Loss scale 4096
I0321 13:31:11.324324 140058691233600 base_trainer.py:770] Train Step: 488/1000 / time=0.315 sec
I0321 13:31:11.324404 140058691233600 base_trainer.py:771] Perf 103070.12 samples/s
I0321 13:31:11.635245 140058691233600 base_trainer.py:769] Step: 489 Lr 0.0226971 Loss scale 4096
I0321 13:31:11.635469 140058691233600 base_trainer.py:770] Train Step: 489/1000 / time=0.308 sec
I0321 13:31:11.635548 140058691233600 base_trainer.py:771] Perf 105333.34 samples/s
I0321 13:31:11.940517 140058691233600 base_trainer.py:769] Step: 490 Lr 0.0226556 Loss scale 4096
I0321 13:31:11.940744 140058691233600 base_trainer.py:770] Train Step: 490/1000 / time=0.303 sec
I0321 13:31:11.940817 140058691233600 base_trainer.py:771] Perf 107239.23 samples/s
I0321 13:31:12.283274 140058691233600 base_trainer.py:769] Step: 491 Lr 0.0226141 Loss scale 4096
I0321 13:31:12.283495 140058691233600 base_trainer.py:770] Train Step: 491/1000 / time=0.340 sec
I0321 13:31:12.283579 140058691233600 base_trainer.py:771] Perf 95671.33 samples/s
I0321 13:31:12.599035 140058691233600 base_trainer.py:769] Step: 492 Lr 0.0225726 Loss scale 4096
I0321 13:31:12.599258 140058691233600 base_trainer.py:770] Train Step: 492/1000 / time=0.313 sec
I0321 13:31:12.599344 140058691233600 base_trainer.py:771] Perf 103794.98 samples/s
I0321 13:31:12.912362 140058691233600 base_trainer.py:769] Step: 493 Lr 0.0225311 Loss scale 4096
I0321 13:31:12.912582 140058691233600 base_trainer.py:770] Train Step: 493/1000 / time=0.310 sec
I0321 13:31:12.912664 140058691233600 base_trainer.py:771] Perf 104561.13 samples/s
I0321 13:31:13.228753 140058691233600 base_trainer.py:769] Step: 494 Lr 0.0224896 Loss scale 4096
I0321 13:31:13.228963 140058691233600 base_trainer.py:770] Train Step: 494/1000 / time=0.314 sec
I0321 13:31:13.229038 140058691233600 base_trainer.py:771] Perf 103508.88 samples/s
I0321 13:31:13.538045 140058691233600 base_trainer.py:769] Step: 495 Lr 0.0224481 Loss scale 4096
I0321 13:31:13.538259 140058691233600 base_trainer.py:770] Train Step: 495/1000 / time=0.306 sec
I0321 13:31:13.538343 140058691233600 base_trainer.py:771] Perf 106014.07 samples/s
I0321 13:31:13.855963 140058691233600 base_trainer.py:769] Step: 496 Lr 0.0224066 Loss scale 4096
I0321 13:31:13.856225 140058691233600 base_trainer.py:770] Train Step: 496/1000 / time=0.315 sec
I0321 13:31:13.856332 140058691233600 base_trainer.py:771] Perf 103095.58 samples/s
I0321 13:31:14.170669 140058691233600 base_trainer.py:769] Step: 497 Lr 0.0223651 Loss scale 4096
I0321 13:31:14.170884 140058691233600 base_trainer.py:770] Train Step: 497/1000 / time=0.312 sec
I0321 13:31:14.170974 140058691233600 base_trainer.py:771] Perf 104077.66 samples/s
I0321 13:31:14.491040 140058691233600 base_trainer.py:769] Step: 498 Lr 0.0223237 Loss scale 4096
I0321 13:31:14.491261 140058691233600 base_trainer.py:770] Train Step: 498/1000 / time=0.317 sec
I0321 13:31:14.491356 140058691233600 base_trainer.py:771] Perf 102317.08 samples/s
I0321 13:31:14.799113 140058691233600 base_trainer.py:769] Step: 499 Lr 0.0222822 Loss scale 4096
I0321 13:31:14.799335 140058691233600 base_trainer.py:770] Train Step: 499/1000 / time=0.305 sec
I0321 13:31:14.799419 140058691233600 base_trainer.py:771] Perf 106371.12 samples/s
I0321 13:31:15.126367 140058691233600 base_trainer.py:769] Step: 500 Lr 0.0222407 Loss scale 4096
I0321 13:31:15.126590 140058691233600 base_trainer.py:770] Train Step: 500/1000 / time=0.324 sec
I0321 13:31:15.126675 140058691233600 base_trainer.py:771] Perf 100126.80 samples/s
I0321 13:31:15.439150 140058691233600 base_trainer.py:769] Step: 501 Lr 0.0221992 Loss scale 4096
I0321 13:31:15.439373 140058691233600 base_trainer.py:770] Train Step: 501/1000 / time=0.310 sec
I0321 13:31:15.439453 140058691233600 base_trainer.py:771] Perf 104754.76 samples/s
I0321 13:31:15.747968 140058691233600 base_trainer.py:769] Step: 502 Lr 0.0221577 Loss scale 4096
I0321 13:31:15.748189 140058691233600 base_trainer.py:770] Train Step: 502/1000 / time=0.306 sec
I0321 13:31:15.748285 140058691233600 base_trainer.py:771] Perf 106115.67 samples/s
I0321 13:31:16.054408 140058691233600 base_trainer.py:769] Step: 503 Lr 0.0221162 Loss scale 4096
I0321 13:31:16.054625 140058691233600 base_trainer.py:770] Train Step: 503/1000 / time=0.303 sec
I0321 13:31:16.054702 140058691233600 base_trainer.py:771] Perf 106936.66 samples/s
I0321 13:31:16.362701 140058691233600 base_trainer.py:769] Step: 504 Lr 0.0220747 Loss scale 4096
I0321 13:31:16.362910 140058691233600 base_trainer.py:770] Train Step: 504/1000 / time=0.305 sec
I0321 13:31:16.362986 140058691233600 base_trainer.py:771] Perf 106238.45 samples/s
I0321 13:31:16.687093 140058691233600 base_trainer.py:769] Step: 505 Lr 0.0220332 Loss scale 4096
I0321 13:31:16.687316 140058691233600 base_trainer.py:770] Train Step: 505/1000 / time=0.322 sec
I0321 13:31:16.687398 140058691233600 base_trainer.py:771] Perf 101042.53 samples/s
I0321 13:31:17.002886 140058691233600 base_trainer.py:769] Step: 506 Lr 0.0219917 Loss scale 4096
I0321 13:31:17.003098 140058691233600 base_trainer.py:770] Train Step: 506/1000 / time=0.313 sec
I0321 13:31:17.003173 140058691233600 base_trainer.py:771] Perf 103726.91 samples/s
I0321 13:31:17.307041 140058691233600 base_trainer.py:769] Step: 507 Lr 0.0219502 Loss scale 4096
I0321 13:31:17.307257 140058691233600 base_trainer.py:770] Train Step: 507/1000 / time=0.301 sec
I0321 13:31:17.307339 140058691233600 base_trainer.py:771] Perf 107782.08 samples/s
I0321 13:31:17.621213 140058691233600 base_trainer.py:769] Step: 508 Lr 0.0219087 Loss scale 4096
I0321 13:31:17.621428 140058691233600 base_trainer.py:770] Train Step: 508/1000 / time=0.311 sec
I0321 13:31:17.621505 140058691233600 base_trainer.py:771] Perf 104356.40 samples/s
I0321 13:31:17.938814 140058691233600 base_trainer.py:769] Step: 509 Lr 0.0218672 Loss scale 4096
I0321 13:31:17.939042 140058691233600 base_trainer.py:770] Train Step: 509/1000 / time=0.315 sec
I0321 13:31:17.939121 140058691233600 base_trainer.py:771] Perf 103155.62 samples/s
I0321 13:31:18.257934 140058691233600 base_trainer.py:769] Step: 510 Lr 0.0218257 Loss scale 4096
I0321 13:31:18.258151 140058691233600 base_trainer.py:770] Train Step: 510/1000 / time=0.316 sec
I0321 13:31:18.258232 140058691233600 base_trainer.py:771] Perf 102624.79 samples/s
I0321 13:31:18.560841 140058691233600 base_trainer.py:769] Step: 511 Lr 0.0217842 Loss scale 4096
I0321 13:31:18.561054 140058691233600 base_trainer.py:770] Train Step: 511/1000 / time=0.300 sec
I0321 13:31:18.561131 140058691233600 base_trainer.py:771] Perf 108189.92 samples/s
I0321 13:31:18.879276 140058691233600 base_trainer.py:769] Step: 512 Lr 0.0217427 Loss scale 4096
I0321 13:31:18.879498 140058691233600 base_trainer.py:770] Train Step: 512/1000 / time=0.315 sec
I0321 13:31:18.879577 140058691233600 base_trainer.py:771] Perf 102945.38 samples/s
I0321 13:31:19.194165 140058691233600 base_trainer.py:769] Step: 513 Lr 0.0217012 Loss scale 4096
I0321 13:31:19.194380 140058691233600 base_trainer.py:770] Train Step: 513/1000 / time=0.312 sec
I0321 13:31:19.194455 140058691233600 base_trainer.py:771] Perf 103994.53 samples/s
I0321 13:31:19.510022 140058691233600 base_trainer.py:769] Step: 514 Lr 0.0216598 Loss scale 4096
I0321 13:31:19.510227 140058691233600 base_trainer.py:770] Train Step: 514/1000 / time=0.313 sec
I0321 13:31:19.510306 140058691233600 base_trainer.py:771] Perf 103742.78 samples/s
I0321 13:31:19.827225 140058691233600 base_trainer.py:769] Step: 515 Lr 0.0216183 Loss scale 4096
I0321 13:31:19.827454 140058691233600 base_trainer.py:770] Train Step: 515/1000 / time=0.314 sec
I0321 13:31:19.827535 140058691233600 base_trainer.py:771] Perf 103388.04 samples/s
I0321 13:31:20.141160 140058691233600 base_trainer.py:769] Step: 516 Lr 0.0215768 Loss scale 4096
I0321 13:31:20.141379 140058691233600 base_trainer.py:770] Train Step: 516/1000 / time=0.311 sec
I0321 13:31:20.141463 140058691233600 base_trainer.py:771] Perf 104375.41 samples/s
I0321 13:31:20.458329 140058691233600 base_trainer.py:769] Step: 517 Lr 0.0215353 Loss scale 4096
I0321 13:31:20.458598 140058691233600 base_trainer.py:770] Train Step: 517/1000 / time=0.314 sec
I0321 13:31:20.458701 140058691233600 base_trainer.py:771] Perf 103382.56 samples/s
I0321 13:31:20.798517 140058691233600 base_trainer.py:769] Step: 518 Lr 0.0214938 Loss scale 4096
I0321 13:31:20.798727 140058691233600 base_trainer.py:770] Train Step: 518/1000 / time=0.337 sec
I0321 13:31:20.798810 140058691233600 base_trainer.py:771] Perf 96217.09 samples/s
I0321 13:31:21.108229 140058691233600 base_trainer.py:769] Step: 519 Lr 0.0214523 Loss scale 4096
I0321 13:31:21.108466 140058691233600 base_trainer.py:770] Train Step: 519/1000 / time=0.307 sec
I0321 13:31:21.108545 140058691233600 base_trainer.py:771] Perf 105849.64 samples/s
I0321 13:31:21.413290 140058691233600 base_trainer.py:769] Step: 520 Lr 0.0214108 Loss scale 4096
I0321 13:31:21.413511 140058691233600 base_trainer.py:770] Train Step: 520/1000 / time=0.302 sec
I0321 13:31:21.413601 140058691233600 base_trainer.py:771] Perf 107425.93 samples/s
I0321 13:31:21.732549 140058691233600 base_trainer.py:769] Step: 521 Lr 0.0213693 Loss scale 4096
I0321 13:31:21.732766 140058691233600 base_trainer.py:770] Train Step: 521/1000 / time=0.316 sec
I0321 13:31:21.732842 140058691233600 base_trainer.py:771] Perf 102648.92 samples/s
I0321 13:31:22.042874 140058691233600 base_trainer.py:769] Step: 522 Lr 0.0213278 Loss scale 4096
I0321 13:31:22.043095 140058691233600 base_trainer.py:770] Train Step: 522/1000 / time=0.307 sec
I0321 13:31:22.043177 140058691233600 base_trainer.py:771] Perf 105564.83 samples/s
I0321 13:31:22.347998 140058691233600 base_trainer.py:769] Step: 523 Lr 0.0212863 Loss scale 4096
I0321 13:31:22.348218 140058691233600 base_trainer.py:770] Train Step: 523/1000 / time=0.302 sec
I0321 13:31:22.348308 140058691233600 base_trainer.py:771] Perf 107412.12 samples/s
I0321 13:31:22.662484 140058691233600 base_trainer.py:769] Step: 524 Lr 0.0212448 Loss scale 4096
I0321 13:31:22.662696 140058691233600 base_trainer.py:770] Train Step: 524/1000 / time=0.312 sec
I0321 13:31:22.662771 140058691233600 base_trainer.py:771] Perf 104125.62 samples/s
I0321 13:31:22.975416 140058691233600 base_trainer.py:769] Step: 525 Lr 0.0212033 Loss scale 4096
I0321 13:31:22.975634 140058691233600 base_trainer.py:770] Train Step: 525/1000 / time=0.310 sec
I0321 13:31:22.975715 140058691233600 base_trainer.py:771] Perf 104775.62 samples/s
I0321 13:31:23.290334 140058691233600 base_trainer.py:769] Step: 526 Lr 0.0211618 Loss scale 4096
I0321 13:31:23.290547 140058691233600 base_trainer.py:770] Train Step: 526/1000 / time=0.312 sec
I0321 13:31:23.290624 140058691233600 base_trainer.py:771] Perf 104002.96 samples/s
I0321 13:31:23.603761 140058691233600 base_trainer.py:769] Step: 527 Lr 0.0211203 Loss scale 4096
I0321 13:31:23.603973 140058691233600 base_trainer.py:770] Train Step: 527/1000 / time=0.311 sec
I0321 13:31:23.604049 140058691233600 base_trainer.py:771] Perf 104542.40 samples/s
I0321 13:31:23.919796 140058691233600 base_trainer.py:769] Step: 528 Lr 0.0210788 Loss scale 4096
I0321 13:31:23.920031 140058691233600 base_trainer.py:770] Train Step: 528/1000 / time=0.313 sec
I0321 13:31:23.920115 140058691233600 base_trainer.py:771] Perf 103760.51 samples/s
I0321 13:31:24.230459 140058691233600 base_trainer.py:769] Step: 529 Lr 0.0210373 Loss scale 4096
I0321 13:31:24.230681 140058691233600 base_trainer.py:770] Train Step: 529/1000 / time=0.308 sec
I0321 13:31:24.230764 140058691233600 base_trainer.py:771] Perf 105488.94 samples/s
I0321 13:31:24.544560 140058691233600 base_trainer.py:769] Step: 530 Lr 0.0209959 Loss scale 4096
I0321 13:31:24.544790 140058691233600 base_trainer.py:770] Train Step: 530/1000 / time=0.311 sec
I0321 13:31:24.544877 140058691233600 base_trainer.py:771] Perf 104337.68 samples/s
I0321 13:31:24.857795 140058691233600 base_trainer.py:769] Step: 531 Lr 0.0209544 Loss scale 4096
I0321 13:31:24.858010 140058691233600 base_trainer.py:770] Train Step: 531/1000 / time=0.310 sec
I0321 13:31:24.858085 140058691233600 base_trainer.py:771] Perf 104538.39 samples/s
I0321 13:31:25.181045 140058691233600 base_trainer.py:769] Step: 532 Lr 0.0209129 Loss scale 4096
I0321 13:31:25.181286 140058691233600 base_trainer.py:770] Train Step: 532/1000 / time=0.320 sec
I0321 13:31:25.181368 140058691233600 base_trainer.py:771] Perf 101489.93 samples/s
I0321 13:31:25.500938 140058691233600 base_trainer.py:769] Step: 533 Lr 0.0208714 Loss scale 4096
I0321 13:31:25.501166 140058691233600 base_trainer.py:770] Train Step: 533/1000 / time=0.317 sec
I0321 13:31:25.501253 140058691233600 base_trainer.py:771] Perf 102403.28 samples/s
I0321 13:31:25.822933 140058691233600 base_trainer.py:769] Step: 534 Lr 0.0208299 Loss scale 4096
I0321 13:31:25.823143 140058691233600 base_trainer.py:770] Train Step: 534/1000 / time=0.319 sec
I0321 13:31:25.823220 140058691233600 base_trainer.py:771] Perf 101670.31 samples/s
I0321 13:31:26.140370 140058691233600 base_trainer.py:769] Step: 535 Lr 0.0207884 Loss scale 4096
I0321 13:31:26.140588 140058691233600 base_trainer.py:770] Train Step: 535/1000 / time=0.315 sec
I0321 13:31:26.140665 140058691233600 base_trainer.py:771] Perf 103274.10 samples/s
I0321 13:31:26.447219 140058691233600 base_trainer.py:769] Step: 536 Lr 0.0207469 Loss scale 4096
I0321 13:31:26.447450 140058691233600 base_trainer.py:770] Train Step: 536/1000 / time=0.304 sec
I0321 13:31:26.447531 140058691233600 base_trainer.py:771] Perf 106810.55 samples/s
I0321 13:31:26.760667 140058691233600 base_trainer.py:769] Step: 537 Lr 0.0207054 Loss scale 4096
I0321 13:31:26.760887 140058691233600 base_trainer.py:770] Train Step: 537/1000 / time=0.310 sec
I0321 13:31:26.760970 140058691233600 base_trainer.py:771] Perf 104541.32 samples/s
I0321 13:31:27.077718 140058691233600 base_trainer.py:769] Step: 538 Lr 0.0206639 Loss scale 4096
I0321 13:31:27.077941 140058691233600 base_trainer.py:770] Train Step: 538/1000 / time=0.314 sec
I0321 13:31:27.078020 140058691233600 base_trainer.py:771] Perf 103350.55 samples/s
I0321 13:31:27.397414 140058691233600 base_trainer.py:769] Step: 539 Lr 0.0206224 Loss scale 4096
I0321 13:31:27.397634 140058691233600 base_trainer.py:770] Train Step: 539/1000 / time=0.317 sec
I0321 13:31:27.397709 140058691233600 base_trainer.py:771] Perf 102438.20 samples/s
I0321 13:31:27.714341 140058691233600 base_trainer.py:769] Step: 540 Lr 0.0205809 Loss scale 4096
I0321 13:31:27.714560 140058691233600 base_trainer.py:770] Train Step: 540/1000 / time=0.314 sec
I0321 13:31:27.714642 140058691233600 base_trainer.py:771] Perf 103452.14 samples/s
I0321 13:31:28.022884 140058691233600 base_trainer.py:769] Step: 541 Lr 0.0205394 Loss scale 4096
I0321 13:31:28.023111 140058691233600 base_trainer.py:770] Train Step: 541/1000 / time=0.306 sec
I0321 13:31:28.023192 140058691233600 base_trainer.py:771] Perf 106212.15 samples/s
I0321 13:31:28.347861 140058691233600 base_trainer.py:769] Step: 542 Lr 0.0204979 Loss scale 4096
I0321 13:31:28.348081 140058691233600 base_trainer.py:770] Train Step: 542/1000 / time=0.322 sec
I0321 13:31:28.348162 140058691233600 base_trainer.py:771] Perf 100823.97 samples/s
I0321 13:31:28.649566 140058691233600 base_trainer.py:769] Step: 543 Lr 0.0204564 Loss scale 4096
I0321 13:31:28.649782 140058691233600 base_trainer.py:770] Train Step: 543/1000 / time=0.299 sec
I0321 13:31:28.649864 140058691233600 base_trainer.py:771] Perf 108623.06 samples/s
I0321 13:31:28.992417 140058691233600 base_trainer.py:769] Step: 544 Lr 0.0204149 Loss scale 4096
I0321 13:31:28.992639 140058691233600 base_trainer.py:770] Train Step: 544/1000 / time=0.340 sec
I0321 13:31:28.992714 140058691233600 base_trainer.py:771] Perf 95537.57 samples/s
I0321 13:31:29.313153 140058691233600 base_trainer.py:769] Step: 545 Lr 0.0203734 Loss scale 4096
I0321 13:31:29.313369 140058691233600 base_trainer.py:770] Train Step: 545/1000 / time=0.318 sec
I0321 13:31:29.313453 140058691233600 base_trainer.py:771] Perf 102203.91 samples/s
I0321 13:31:29.633373 140058691233600 base_trainer.py:769] Step: 546 Lr 0.020332 Loss scale 4096
I0321 13:31:29.633677 140058691233600 base_trainer.py:770] Train Step: 546/1000 / time=0.317 sec
I0321 13:31:29.633769 140058691233600 base_trainer.py:771] Perf 102385.04 samples/s
I0321 13:31:29.944726 140058691233600 base_trainer.py:769] Step: 547 Lr 0.0202905 Loss scale 4096
I0321 13:31:29.944949 140058691233600 base_trainer.py:770] Train Step: 547/1000 / time=0.308 sec
I0321 13:31:29.945033 140058691233600 base_trainer.py:771] Perf 105195.27 samples/s
I0321 13:31:30.256244 140058691233600 base_trainer.py:769] Step: 548 Lr 0.020249 Loss scale 4096
I0321 13:31:30.256497 140058691233600 base_trainer.py:770] Train Step: 548/1000 / time=0.309 sec
I0321 13:31:30.256581 140058691233600 base_trainer.py:771] Perf 105188.60 samples/s
I0321 13:31:30.570002 140058691233600 base_trainer.py:769] Step: 549 Lr 0.0202075 Loss scale 4096
I0321 13:31:30.570223 140058691233600 base_trainer.py:770] Train Step: 549/1000 / time=0.311 sec
I0321 13:31:30.570300 140058691233600 base_trainer.py:771] Perf 104428.76 samples/s
I0321 13:31:30.889044 140058691233600 base_trainer.py:769] Step: 550 Lr 0.020166 Loss scale 4096
I0321 13:31:30.889258 140058691233600 base_trainer.py:770] Train Step: 550/1000 / time=0.316 sec
I0321 13:31:30.889343 140058691233600 base_trainer.py:771] Perf 102725.97 samples/s
I0321 13:31:31.209444 140058691233600 base_trainer.py:769] Step: 551 Lr 0.0201245 Loss scale 4096
I0321 13:31:31.209655 140058691233600 base_trainer.py:770] Train Step: 551/1000 / time=0.318 sec
I0321 13:31:31.209733 140058691233600 base_trainer.py:771] Perf 102219.85 samples/s
I0321 13:31:31.516548 140058691233600 base_trainer.py:769] Step: 552 Lr 0.020083 Loss scale 4096
I0321 13:31:31.516761 140058691233600 base_trainer.py:770] Train Step: 552/1000 / time=0.304 sec
I0321 13:31:31.516840 140058691233600 base_trainer.py:771] Perf 106741.79 samples/s
I0321 13:31:31.827654 140058691233600 base_trainer.py:769] Step: 553 Lr 0.0200415 Loss scale 4096
I0321 13:31:31.827875 140058691233600 base_trainer.py:770] Train Step: 553/1000 / time=0.308 sec
I0321 13:31:31.827960 140058691233600 base_trainer.py:771] Perf 105333.31 samples/s
I0321 13:31:32.139040 140058691233600 base_trainer.py:769] Step: 554 Lr 0.02 Loss scale 4096
I0321 13:31:32.139249 140058691233600 base_trainer.py:770] Train Step: 554/1000 / time=0.309 sec
I0321 13:31:32.139326 140058691233600 base_trainer.py:771] Perf 105180.27 samples/s
I0321 13:31:32.462419 140058691233600 base_trainer.py:769] Step: 555 Lr 0.0199585 Loss scale 4096
I0321 13:31:32.462646 140058691233600 base_trainer.py:770] Train Step: 555/1000 / time=0.320 sec
I0321 13:31:32.462727 140058691233600 base_trainer.py:771] Perf 101404.18 samples/s
I0321 13:31:32.766090 140058691233600 base_trainer.py:769] Step: 556 Lr 0.019917 Loss scale 4096
I0321 13:31:32.766306 140058691233600 base_trainer.py:770] Train Step: 556/1000 / time=0.301 sec
I0321 13:31:32.766388 140058691233600 base_trainer.py:771] Perf 107852.29 samples/s
I0321 13:31:33.090182 140058691233600 base_trainer.py:769] Step: 557 Lr 0.0198755 Loss scale 4096
I0321 13:31:33.090407 140058691233600 base_trainer.py:770] Train Step: 557/1000 / time=0.321 sec
I0321 13:31:33.090494 140058691233600 base_trainer.py:771] Perf 101110.82 samples/s
I0321 13:31:33.410677 140058691233600 base_trainer.py:769] Step: 558 Lr 0.019834 Loss scale 4096
I0321 13:31:33.410906 140058691233600 base_trainer.py:770] Train Step: 558/1000 / time=0.317 sec
I0321 13:31:33.410985 140058691233600 base_trainer.py:771] Perf 102280.55 samples/s
I0321 13:31:33.728615 140058691233600 base_trainer.py:769] Step: 559 Lr 0.0197925 Loss scale 4096
I0321 13:31:33.728828 140058691233600 base_trainer.py:770] Train Step: 559/1000 / time=0.315 sec
I0321 13:31:33.728904 140058691233600 base_trainer.py:771] Perf 103016.05 samples/s
I0321 13:31:34.046288 140058691233600 base_trainer.py:769] Step: 560 Lr 0.019751 Loss scale 4096
I0321 13:31:34.046509 140058691233600 base_trainer.py:770] Train Step: 560/1000 / time=0.315 sec
I0321 13:31:34.046588 140058691233600 base_trainer.py:771] Perf 103212.80 samples/s
I0321 13:31:34.358252 140058691233600 base_trainer.py:769] Step: 561 Lr 0.0197095 Loss scale 4096
I0321 13:31:34.358459 140058691233600 base_trainer.py:770] Train Step: 561/1000 / time=0.309 sec
I0321 13:31:34.358534 140058691233600 base_trainer.py:771] Perf 104943.54 samples/s
I0321 13:31:34.668521 140058691233600 base_trainer.py:769] Step: 562 Lr 0.0196681 Loss scale 4096
I0321 13:31:34.668745 140058691233600 base_trainer.py:770] Train Step: 562/1000 / time=0.307 sec
I0321 13:31:34.668824 140058691233600 base_trainer.py:771] Perf 105699.19 samples/s
I0321 13:31:34.980091 140058691233600 base_trainer.py:769] Step: 563 Lr 0.0196266 Loss scale 4096
I0321 13:31:34.980331 140058691233600 base_trainer.py:770] Train Step: 563/1000 / time=0.308 sec
I0321 13:31:34.980422 140058691233600 base_trainer.py:771] Perf 105220.32 samples/s
I0321 13:31:35.297637 140058691233600 base_trainer.py:769] Step: 564 Lr 0.0195851 Loss scale 4096
I0321 13:31:35.297854 140058691233600 base_trainer.py:770] Train Step: 564/1000 / time=0.315 sec
I0321 13:31:35.297945 140058691233600 base_trainer.py:771] Perf 103152.06 samples/s
I0321 13:31:35.616959 140058691233600 base_trainer.py:769] Step: 565 Lr 0.0195436 Loss scale 4096
I0321 13:31:35.617180 140058691233600 base_trainer.py:770] Train Step: 565/1000 / time=0.316 sec
I0321 13:31:35.617265 140058691233600 base_trainer.py:771] Perf 102624.49 samples/s
I0321 13:31:35.925358 140058691233600 base_trainer.py:769] Step: 566 Lr 0.0195021 Loss scale 4096
I0321 13:31:35.925572 140058691233600 base_trainer.py:770] Train Step: 566/1000 / time=0.305 sec
I0321 13:31:35.925652 140058691233600 base_trainer.py:771] Perf 106241.38 samples/s
I0321 13:31:36.234897 140058691233600 base_trainer.py:769] Step: 567 Lr 0.0194606 Loss scale 4096
I0321 13:31:36.235111 140058691233600 base_trainer.py:770] Train Step: 567/1000 / time=0.307 sec
I0321 13:31:36.235194 140058691233600 base_trainer.py:771] Perf 105883.53 samples/s
I0321 13:31:36.560886 140058691233600 base_trainer.py:769] Step: 568 Lr 0.0194191 Loss scale 4096
I0321 13:31:36.561259 140058691233600 base_trainer.py:770] Train Step: 568/1000 / time=0.323 sec
I0321 13:31:36.561397 140058691233600 base_trainer.py:771] Perf 100662.61 samples/s
I0321 13:31:36.872825 140058691233600 base_trainer.py:769] Step: 569 Lr 0.0193776 Loss scale 4096
I0321 13:31:36.873055 140058691233600 base_trainer.py:770] Train Step: 569/1000 / time=0.309 sec
I0321 13:31:36.873134 140058691233600 base_trainer.py:771] Perf 104907.83 samples/s
I0321 13:31:37.212811 140058691233600 base_trainer.py:769] Step: 570 Lr 0.0193361 Loss scale 4096
I0321 13:31:37.213032 140058691233600 base_trainer.py:770] Train Step: 570/1000 / time=0.337 sec
I0321 13:31:37.213116 140058691233600 base_trainer.py:771] Perf 96359.61 samples/s
I0321 13:31:37.525757 140058691233600 base_trainer.py:769] Step: 571 Lr 0.0192946 Loss scale 4096
I0321 13:31:37.525970 140058691233600 base_trainer.py:770] Train Step: 571/1000 / time=0.310 sec
I0321 13:31:37.526047 140058691233600 base_trainer.py:771] Perf 104673.38 samples/s
I0321 13:31:37.835843 140058691233600 base_trainer.py:769] Step: 572 Lr 0.0192531 Loss scale 4096
I0321 13:31:37.836055 140058691233600 base_trainer.py:770] Train Step: 572/1000 / time=0.307 sec
I0321 13:31:37.836131 140058691233600 base_trainer.py:771] Perf 105644.30 samples/s
I0321 13:31:38.139610 140058691233600 base_trainer.py:769] Step: 573 Lr 0.0192116 Loss scale 4096
I0321 13:31:38.139822 140058691233600 base_trainer.py:770] Train Step: 573/1000 / time=0.301 sec
I0321 13:31:38.139900 140058691233600 base_trainer.py:771] Perf 107868.46 samples/s
I0321 13:31:38.457886 140058691233600 base_trainer.py:769] Step: 574 Lr 0.0191701 Loss scale 4096
I0321 13:31:38.458101 140058691233600 base_trainer.py:770] Train Step: 574/1000 / time=0.315 sec
I0321 13:31:38.458177 140058691233600 base_trainer.py:771] Perf 102973.71 samples/s
I0321 13:31:38.770779 140058691233600 base_trainer.py:769] Step: 575 Lr 0.0191286 Loss scale 4096
I0321 13:31:38.770992 140058691233600 base_trainer.py:770] Train Step: 575/1000 / time=0.310 sec
I0321 13:31:38.771066 140058691233600 base_trainer.py:771] Perf 104709.36 samples/s
I0321 13:31:39.083818 140058691233600 base_trainer.py:769] Step: 576 Lr 0.0190871 Loss scale 4096
I0321 13:31:39.084036 140058691233600 base_trainer.py:770] Train Step: 576/1000 / time=0.310 sec
I0321 13:31:39.084133 140058691233600 base_trainer.py:771] Perf 104755.44 samples/s
I0321 13:31:39.397300 140058691233600 base_trainer.py:769] Step: 577 Lr 0.0190456 Loss scale 4096
I0321 13:31:39.397516 140058691233600 base_trainer.py:770] Train Step: 577/1000 / time=0.311 sec
I0321 13:31:39.397599 140058691233600 base_trainer.py:771] Perf 104517.98 samples/s
I0321 13:31:39.707954 140058691233600 base_trainer.py:769] Step: 578 Lr 0.0190041 Loss scale 4096
I0321 13:31:39.708190 140058691233600 base_trainer.py:770] Train Step: 578/1000 / time=0.307 sec
I0321 13:31:39.708292 140058691233600 base_trainer.py:771] Perf 105548.09 samples/s
I0321 13:31:40.023732 140058691233600 base_trainer.py:769] Step: 579 Lr 0.0189627 Loss scale 4096
I0321 13:31:40.023969 140058691233600 base_trainer.py:770] Train Step: 579/1000 / time=0.313 sec
I0321 13:31:40.024048 140058691233600 base_trainer.py:771] Perf 103730.49 samples/s
I0321 13:31:40.333930 140058691233600 base_trainer.py:769] Step: 580 Lr 0.0189212 Loss scale 4096
I0321 13:31:40.334164 140058691233600 base_trainer.py:770] Train Step: 580/1000 / time=0.307 sec
I0321 13:31:40.334248 140058691233600 base_trainer.py:771] Perf 105636.59 samples/s
I0321 13:31:40.652233 140058691233600 base_trainer.py:769] Step: 581 Lr 0.0188797 Loss scale 4096
I0321 13:31:40.652468 140058691233600 base_trainer.py:770] Train Step: 581/1000 / time=0.315 sec
I0321 13:31:40.652552 140058691233600 base_trainer.py:771] Perf 102970.78 samples/s
I0321 13:31:40.971303 140058691233600 base_trainer.py:769] Step: 582 Lr 0.0188382 Loss scale 4096
I0321 13:31:40.971529 140058691233600 base_trainer.py:770] Train Step: 582/1000 / time=0.316 sec
I0321 13:31:40.971615 140058691233600 base_trainer.py:771] Perf 102653.37 samples/s
I0321 13:31:41.285161 140058691233600 base_trainer.py:769] Step: 583 Lr 0.0187967 Loss scale 4096
I0321 13:31:41.285380 140058691233600 base_trainer.py:770] Train Step: 583/1000 / time=0.311 sec
I0321 13:31:41.285463 140058691233600 base_trainer.py:771] Perf 104415.87 samples/s
I0321 13:31:41.605207 140058691233600 base_trainer.py:769] Step: 584 Lr 0.0187552 Loss scale 4096
I0321 13:31:41.605437 140058691233600 base_trainer.py:770] Train Step: 584/1000 / time=0.317 sec
I0321 13:31:41.605523 140058691233600 base_trainer.py:771] Perf 102422.59 samples/s
I0321 13:31:41.922162 140058691233600 base_trainer.py:769] Step: 585 Lr 0.0187137 Loss scale 4096
I0321 13:31:41.922386 140058691233600 base_trainer.py:770] Train Step: 585/1000 / time=0.314 sec
I0321 13:31:41.922467 140058691233600 base_trainer.py:771] Perf 103350.25 samples/s
I0321 13:31:42.252957 140058691233600 base_trainer.py:769] Step: 586 Lr 0.0186722 Loss scale 4096
I0321 13:31:42.253167 140058691233600 base_trainer.py:770] Train Step: 586/1000 / time=0.328 sec
I0321 13:31:42.253244 140058691233600 base_trainer.py:771] Perf 99016.39 samples/s
I0321 13:31:42.567651 140058691233600 base_trainer.py:769] Step: 587 Lr 0.0186307 Loss scale 4096
I0321 13:31:42.567879 140058691233600 base_trainer.py:770] Train Step: 587/1000 / time=0.312 sec
I0321 13:31:42.567959 140058691233600 base_trainer.py:771] Perf 104177.00 samples/s
I0321 13:31:42.877551 140058691233600 base_trainer.py:769] Step: 588 Lr 0.0185892 Loss scale 4096
I0321 13:31:42.877763 140058691233600 base_trainer.py:770] Train Step: 588/1000 / time=0.307 sec
I0321 13:31:42.877841 140058691233600 base_trainer.py:771] Perf 105678.76 samples/s
I0321 13:31:43.188411 140058691233600 base_trainer.py:769] Step: 589 Lr 0.0185477 Loss scale 4096
I0321 13:31:43.188637 140058691233600 base_trainer.py:770] Train Step: 589/1000 / time=0.308 sec
I0321 13:31:43.188724 140058691233600 base_trainer.py:771] Perf 105506.56 samples/s
I0321 13:31:43.492382 140058691233600 base_trainer.py:769] Step: 590 Lr 0.0185062 Loss scale 4096
I0321 13:31:43.492610 140058691233600 base_trainer.py:770] Train Step: 590/1000 / time=0.301 sec
I0321 13:31:43.492693 140058691233600 base_trainer.py:771] Perf 107780.61 samples/s
I0321 13:31:43.817343 140058691233600 base_trainer.py:769] Step: 591 Lr 0.0184647 Loss scale 4096
I0321 13:31:43.817573 140058691233600 base_trainer.py:770] Train Step: 591/1000 / time=0.322 sec
I0321 13:31:43.817659 140058691233600 base_trainer.py:771] Perf 100901.12 samples/s
I0321 13:31:44.137587 140058691233600 base_trainer.py:769] Step: 592 Lr 0.0184232 Loss scale 4096
I0321 13:31:44.137814 140058691233600 base_trainer.py:770] Train Step: 592/1000 / time=0.317 sec
I0321 13:31:44.137898 140058691233600 base_trainer.py:771] Perf 102262.99 samples/s
I0321 13:31:44.445844 140058691233600 base_trainer.py:769] Step: 593 Lr 0.0183817 Loss scale 4096
I0321 13:31:44.446069 140058691233600 base_trainer.py:770] Train Step: 593/1000 / time=0.305 sec
I0321 13:31:44.446148 140058691233600 base_trainer.py:771] Perf 106302.21 samples/s
I0321 13:31:44.757977 140058691233600 base_trainer.py:769] Step: 594 Lr 0.0183402 Loss scale 4096
I0321 13:31:44.758198 140058691233600 base_trainer.py:770] Train Step: 594/1000 / time=0.309 sec
I0321 13:31:44.758288 140058691233600 base_trainer.py:771] Perf 104971.89 samples/s
I0321 13:31:45.081626 140058691233600 base_trainer.py:769] Step: 595 Lr 0.0182988 Loss scale 4096
I0321 13:31:45.081843 140058691233600 base_trainer.py:770] Train Step: 595/1000 / time=0.321 sec
I0321 13:31:45.081924 140058691233600 base_trainer.py:771] Perf 101239.79 samples/s
I0321 13:31:45.404771 140058691233600 base_trainer.py:769] Step: 596 Lr 0.0182573 Loss scale 4096
I0321 13:31:45.404984 140058691233600 base_trainer.py:770] Train Step: 596/1000 / time=0.320 sec
I0321 13:31:45.405070 140058691233600 base_trainer.py:771] Perf 101378.43 samples/s
I0321 13:31:45.754306 140058691233600 base_trainer.py:769] Step: 597 Lr 0.0182158 Loss scale 4096
I0321 13:31:45.754531 140058691233600 base_trainer.py:770] Train Step: 597/1000 / time=0.347 sec
I0321 13:31:45.754615 140058691233600 base_trainer.py:771] Perf 93785.82 samples/s
I0321 13:31:46.078752 140058691233600 base_trainer.py:769] Step: 598 Lr 0.0181743 Loss scale 4096
I0321 13:31:46.078963 140058691233600 base_trainer.py:770] Train Step: 598/1000 / time=0.322 sec
I0321 13:31:46.079038 140058691233600 base_trainer.py:771] Perf 100919.12 samples/s
I0321 13:31:46.401227 140058691233600 base_trainer.py:769] Step: 599 Lr 0.0181328 Loss scale 4096
I0321 13:31:46.401440 140058691233600 base_trainer.py:770] Train Step: 599/1000 / time=0.319 sec
I0321 13:31:46.401525 140058691233600 base_trainer.py:771] Perf 101709.47 samples/s
I0321 13:31:46.715281 140058691233600 base_trainer.py:769] Step: 600 Lr 0.0180913 Loss scale 4096
I0321 13:31:46.715510 140058691233600 base_trainer.py:770] Train Step: 600/1000 / time=0.311 sec
I0321 13:31:46.715594 140058691233600 base_trainer.py:771] Perf 104312.23 samples/s
I0321 13:31:47.037299 140058691233600 base_trainer.py:769] Step: 601 Lr 0.0180498 Loss scale 4096
I0321 13:31:47.037526 140058691233600 base_trainer.py:770] Train Step: 601/1000 / time=0.319 sec
I0321 13:31:47.037611 140058691233600 base_trainer.py:771] Perf 101783.70 samples/s
I0321 13:31:47.344457 140058691233600 base_trainer.py:769] Step: 602 Lr 0.0180083 Loss scale 4096
I0321 13:31:47.344678 140058691233600 base_trainer.py:770] Train Step: 602/1000 / time=0.304 sec
I0321 13:31:47.344763 140058691233600 base_trainer.py:771] Perf 106650.53 samples/s
I0321 13:31:47.672447 140058691233600 base_trainer.py:769] Step: 603 Lr 0.0179668 Loss scale 4096
I0321 13:31:47.672657 140058691233600 base_trainer.py:770] Train Step: 603/1000 / time=0.325 sec
I0321 13:31:47.672736 140058691233600 base_trainer.py:771] Perf 99847.21 samples/s
I0321 13:31:47.988978 140058691233600 base_trainer.py:769] Step: 604 Lr 0.0179253 Loss scale 4096
I0321 13:31:47.989194 140058691233600 base_trainer.py:770] Train Step: 604/1000 / time=0.314 sec
I0321 13:31:47.989280 140058691233600 base_trainer.py:771] Perf 103592.56 samples/s
I0321 13:31:48.305064 140058691233600 base_trainer.py:769] Step: 605 Lr 0.0178838 Loss scale 4096
I0321 13:31:48.305289 140058691233600 base_trainer.py:770] Train Step: 605/1000 / time=0.313 sec
I0321 13:31:48.305373 140058691233600 base_trainer.py:771] Perf 103664.36 samples/s
I0321 13:31:48.621049 140058691233600 base_trainer.py:769] Step: 606 Lr 0.0178423 Loss scale 4096
I0321 13:31:48.621279 140058691233600 base_trainer.py:770] Train Step: 606/1000 / time=0.313 sec
I0321 13:31:48.621360 140058691233600 base_trainer.py:771] Perf 103743.14 samples/s
I0321 13:31:48.924331 140058691233600 base_trainer.py:769] Step: 607 Lr 0.0178008 Loss scale 4096
I0321 13:31:48.924560 140058691233600 base_trainer.py:770] Train Step: 607/1000 / time=0.300 sec
I0321 13:31:48.924642 140058691233600 base_trainer.py:771] Perf 108007.76 samples/s
I0321 13:31:49.227540 140058691233600 base_trainer.py:769] Step: 608 Lr 0.0177593 Loss scale 4096
I0321 13:31:49.227765 140058691233600 base_trainer.py:770] Train Step: 608/1000 / time=0.300 sec
I0321 13:31:49.227851 140058691233600 base_trainer.py:771] Perf 108072.08 samples/s
I0321 13:31:49.539637 140058691233600 base_trainer.py:769] Step: 609 Lr 0.0177178 Loss scale 4096
I0321 13:31:49.539859 140058691233600 base_trainer.py:770] Train Step: 609/1000 / time=0.309 sec
I0321 13:31:49.539943 140058691233600 base_trainer.py:771] Perf 105034.58 samples/s
I0321 13:31:49.847842 140058691233600 base_trainer.py:769] Step: 610 Lr 0.0176763 Loss scale 4096
I0321 13:31:49.848070 140058691233600 base_trainer.py:770] Train Step: 610/1000 / time=0.305 sec
I0321 13:31:49.848151 140058691233600 base_trainer.py:771] Perf 106280.59 samples/s
I0321 13:31:50.153873 140058691233600 base_trainer.py:769] Step: 611 Lr 0.0176349 Loss scale 4096
I0321 13:31:50.154102 140058691233600 base_trainer.py:770] Train Step: 611/1000 / time=0.303 sec
I0321 13:31:50.154186 140058691233600 base_trainer.py:771] Perf 107075.69 samples/s
I0321 13:31:50.476715 140058691233600 base_trainer.py:769] Step: 612 Lr 0.0175934 Loss scale 4096
I0321 13:31:50.476936 140058691233600 base_trainer.py:770] Train Step: 612/1000 / time=0.320 sec
I0321 13:31:50.477018 140058691233600 base_trainer.py:771] Perf 101499.61 samples/s
I0321 13:31:50.791471 140058691233600 base_trainer.py:769] Step: 613 Lr 0.0175519 Loss scale 4096
I0321 13:31:50.791683 140058691233600 base_trainer.py:770] Train Step: 613/1000 / time=0.312 sec
I0321 13:31:50.791758 140058691233600 base_trainer.py:771] Perf 104043.76 samples/s
I0321 13:31:51.101961 140058691233600 base_trainer.py:769] Step: 614 Lr 0.0175104 Loss scale 4096
I0321 13:31:51.102188 140058691233600 base_trainer.py:770] Train Step: 614/1000 / time=0.308 sec
I0321 13:31:51.102270 140058691233600 base_trainer.py:771] Perf 105608.63 samples/s
I0321 13:31:51.423820 140058691233600 base_trainer.py:769] Step: 615 Lr 0.0174689 Loss scale 4096
I0321 13:31:51.424030 140058691233600 base_trainer.py:770] Train Step: 615/1000 / time=0.319 sec
I0321 13:31:51.424104 140058691233600 base_trainer.py:771] Perf 101742.92 samples/s
I0321 13:31:51.746984 140058691233600 base_trainer.py:769] Step: 616 Lr 0.0174274 Loss scale 4096
I0321 13:31:51.747212 140058691233600 base_trainer.py:770] Train Step: 616/1000 / time=0.320 sec
I0321 13:31:51.747291 140058691233600 base_trainer.py:771] Perf 101462.57 samples/s
I0321 13:31:52.064384 140058691233600 base_trainer.py:769] Step: 617 Lr 0.0173859 Loss scale 4096
I0321 13:31:52.064736 140058691233600 base_trainer.py:770] Train Step: 617/1000 / time=0.314 sec
I0321 13:31:52.064823 140058691233600 base_trainer.py:771] Perf 103252.25 samples/s
I0321 13:31:52.366859 140058691233600 base_trainer.py:769] Step: 618 Lr 0.0173444 Loss scale 4096
I0321 13:31:52.367084 140058691233600 base_trainer.py:770] Train Step: 618/1000 / time=0.299 sec
I0321 13:31:52.367167 140058691233600 base_trainer.py:771] Perf 108316.96 samples/s
I0321 13:31:52.690614 140058691233600 base_trainer.py:769] Step: 619 Lr 0.0173029 Loss scale 4096
I0321 13:31:52.690836 140058691233600 base_trainer.py:770] Train Step: 619/1000 / time=0.321 sec
I0321 13:31:52.690912 140058691233600 base_trainer.py:771] Perf 101215.87 samples/s
I0321 13:31:53.010885 140058691233600 base_trainer.py:769] Step: 620 Lr 0.0172614 Loss scale 4096
I0321 13:31:53.011110 140058691233600 base_trainer.py:770] Train Step: 620/1000 / time=0.317 sec
I0321 13:31:53.011195 140058691233600 base_trainer.py:771] Perf 102298.89 samples/s
I0321 13:31:53.323582 140058691233600 base_trainer.py:769] Step: 621 Lr 0.0172199 Loss scale 4096
I0321 13:31:53.323799 140058691233600 base_trainer.py:770] Train Step: 621/1000 / time=0.310 sec
I0321 13:31:53.323881 140058691233600 base_trainer.py:771] Perf 104814.75 samples/s
I0321 13:31:53.635555 140058691233600 base_trainer.py:769] Step: 622 Lr 0.0171784 Loss scale 4096
I0321 13:31:53.635782 140058691233600 base_trainer.py:770] Train Step: 622/1000 / time=0.309 sec
I0321 13:31:53.635864 140058691233600 base_trainer.py:771] Perf 105037.24 samples/s
I0321 13:31:53.982079 140058691233600 base_trainer.py:769] Step: 623 Lr 0.0171369 Loss scale 4096
I0321 13:31:53.982312 140058691233600 base_trainer.py:770] Train Step: 623/1000 / time=0.340 sec
I0321 13:31:53.982400 140058691233600 base_trainer.py:771] Perf 95601.85 samples/s
I0321 13:31:54.302654 140058691233600 base_trainer.py:769] Step: 624 Lr 0.0170954 Loss scale 4096
I0321 13:31:54.302878 140058691233600 base_trainer.py:770] Train Step: 624/1000 / time=0.317 sec
I0321 13:31:54.302955 140058691233600 base_trainer.py:771] Perf 101203.05 samples/s
I0321 13:31:54.617692 140058691233600 base_trainer.py:769] Step: 625 Lr 0.0170539 Loss scale 4096
I0321 13:31:54.617900 140058691233600 base_trainer.py:770] Train Step: 625/1000 / time=0.311 sec
I0321 13:31:54.617975 140058691233600 base_trainer.py:771] Perf 103981.95 samples/s
I0321 13:31:54.937031 140058691233600 base_trainer.py:769] Step: 626 Lr 0.0170124 Loss scale 4096
I0321 13:31:54.937263 140058691233600 base_trainer.py:770] Train Step: 626/1000 / time=0.316 sec
I0321 13:31:54.937347 140058691233600 base_trainer.py:771] Perf 102502.11 samples/s
I0321 13:31:55.254077 140058691233600 base_trainer.py:769] Step: 627 Lr 0.016971 Loss scale 4096
I0321 13:31:55.254299 140058691233600 base_trainer.py:770] Train Step: 627/1000 / time=0.314 sec
I0321 13:31:55.254389 140058691233600 base_trainer.py:771] Perf 103353.17 samples/s
I0321 13:31:55.568565 140058691233600 base_trainer.py:769] Step: 628 Lr 0.0169295 Loss scale 4096
I0321 13:31:55.568786 140058691233600 base_trainer.py:770] Train Step: 628/1000 / time=0.312 sec
I0321 13:31:55.568871 140058691233600 base_trainer.py:771] Perf 104160.44 samples/s
I0321 13:31:55.887594 140058691233600 base_trainer.py:769] Step: 629 Lr 0.016888 Loss scale 4096
I0321 13:31:55.887814 140058691233600 base_trainer.py:770] Train Step: 629/1000 / time=0.316 sec
I0321 13:31:55.887902 140058691233600 base_trainer.py:771] Perf 102720.41 samples/s
I0321 13:31:56.205288 140058691233600 base_trainer.py:769] Step: 630 Lr 0.0168465 Loss scale 4096
I0321 13:31:56.205498 140058691233600 base_trainer.py:770] Train Step: 630/1000 / time=0.315 sec
I0321 13:31:56.205580 140058691233600 base_trainer.py:771] Perf 103200.85 samples/s
I0321 13:31:56.508718 140058691233600 base_trainer.py:769] Step: 631 Lr 0.016805 Loss scale 4096
I0321 13:31:56.508934 140058691233600 base_trainer.py:770] Train Step: 631/1000 / time=0.300 sec
I0321 13:31:56.509017 140058691233600 base_trainer.py:771] Perf 107932.68 samples/s
I0321 13:31:56.829924 140058691233600 base_trainer.py:769] Step: 632 Lr 0.0167635 Loss scale 4096
I0321 13:31:56.830132 140058691233600 base_trainer.py:770] Train Step: 632/1000 / time=0.319 sec
I0321 13:31:56.830208 140058691233600 base_trainer.py:771] Perf 101953.36 samples/s
I0321 13:31:57.143878 140058691233600 base_trainer.py:769] Step: 633 Lr 0.016722 Loss scale 4096
I0321 13:31:57.144096 140058691233600 base_trainer.py:770] Train Step: 633/1000 / time=0.311 sec
I0321 13:31:57.144173 140058691233600 base_trainer.py:771] Perf 104431.99 samples/s
I0321 13:31:57.460272 140058691233600 base_trainer.py:769] Step: 634 Lr 0.0166805 Loss scale 4096
I0321 13:31:57.460505 140058691233600 base_trainer.py:770] Train Step: 634/1000 / time=0.314 sec
I0321 13:31:57.460586 140058691233600 base_trainer.py:771] Perf 103551.00 samples/s
I0321 13:31:57.771045 140058691233600 base_trainer.py:769] Step: 635 Lr 0.016639 Loss scale 4096
I0321 13:31:57.771262 140058691233600 base_trainer.py:770] Train Step: 635/1000 / time=0.308 sec
I0321 13:31:57.771347 140058691233600 base_trainer.py:771] Perf 105468.75 samples/s
I0321 13:31:58.094479 140058691233600 base_trainer.py:769] Step: 636 Lr 0.0165975 Loss scale 4096
I0321 13:31:58.094711 140058691233600 base_trainer.py:770] Train Step: 636/1000 / time=0.320 sec
I0321 13:31:58.094794 140058691233600 base_trainer.py:771] Perf 101343.13 samples/s
I0321 13:31:58.412080 140058691233600 base_trainer.py:769] Step: 637 Lr 0.016556 Loss scale 4096
I0321 13:31:58.412318 140058691233600 base_trainer.py:770] Train Step: 637/1000 / time=0.314 sec
I0321 13:31:58.412399 140058691233600 base_trainer.py:771] Perf 103224.43 samples/s
I0321 13:31:58.716735 140058691233600 base_trainer.py:769] Step: 638 Lr 0.0165145 Loss scale 4096
I0321 13:31:58.716957 140058691233600 base_trainer.py:770] Train Step: 638/1000 / time=0.302 sec
I0321 13:31:58.717040 140058691233600 base_trainer.py:771] Perf 107506.66 samples/s
I0321 13:31:59.026918 140058691233600 base_trainer.py:769] Step: 639 Lr 0.016473 Loss scale 4096
I0321 13:31:59.027140 140058691233600 base_trainer.py:770] Train Step: 639/1000 / time=0.307 sec
I0321 13:31:59.027222 140058691233600 base_trainer.py:771] Perf 105611.67 samples/s
I0321 13:31:59.337430 140058691233600 base_trainer.py:769] Step: 640 Lr 0.0164315 Loss scale 4096
I0321 13:31:59.337648 140058691233600 base_trainer.py:770] Train Step: 640/1000 / time=0.307 sec
I0321 13:31:59.337730 140058691233600 base_trainer.py:771] Perf 105560.75 samples/s
I0321 13:31:59.643772 140058691233600 base_trainer.py:769] Step: 641 Lr 0.01639 Loss scale 4096
I0321 13:31:59.643977 140058691233600 base_trainer.py:770] Train Step: 641/1000 / time=0.304 sec
I0321 13:31:59.644052 140058691233600 base_trainer.py:771] Perf 106867.11 samples/s
I0321 13:31:59.963974 140058691233600 base_trainer.py:769] Step: 642 Lr 0.0163485 Loss scale 4096
I0321 13:31:59.964202 140058691233600 base_trainer.py:770] Train Step: 642/1000 / time=0.317 sec
I0321 13:31:59.964299 140058691233600 base_trainer.py:771] Perf 102549.17 samples/s
I0321 13:32:00.296011 140058691233600 base_trainer.py:769] Step: 643 Lr 0.0163071 Loss scale 4096
I0321 13:32:00.296271 140058691233600 base_trainer.py:770] Train Step: 643/1000 / time=0.329 sec
I0321 13:32:00.296377 140058691233600 base_trainer.py:771] Perf 98553.35 samples/s
I0321 13:32:00.605014 140058691233600 base_trainer.py:769] Step: 644 Lr 0.0162656 Loss scale 4096
I0321 13:32:00.605226 140058691233600 base_trainer.py:770] Train Step: 644/1000 / time=0.306 sec
I0321 13:32:00.605312 140058691233600 base_trainer.py:771] Perf 106064.41 samples/s
I0321 13:32:00.921650 140058691233600 base_trainer.py:769] Step: 645 Lr 0.0162241 Loss scale 4096
I0321 13:32:00.921864 140058691233600 base_trainer.py:770] Train Step: 645/1000 / time=0.314 sec
I0321 13:32:00.921941 140058691233600 base_trainer.py:771] Perf 103435.88 samples/s
I0321 13:32:01.233401 140058691233600 base_trainer.py:769] Step: 646 Lr 0.0161826 Loss scale 4096
I0321 13:32:01.233620 140058691233600 base_trainer.py:770] Train Step: 646/1000 / time=0.309 sec
I0321 13:32:01.233705 140058691233600 base_trainer.py:771] Perf 105159.54 samples/s
I0321 13:32:01.544607 140058691233600 base_trainer.py:769] Step: 647 Lr 0.0161411 Loss scale 4096
I0321 13:32:01.544815 140058691233600 base_trainer.py:770] Train Step: 647/1000 / time=0.308 sec
I0321 13:32:01.544890 140058691233600 base_trainer.py:771] Perf 105232.60 samples/s
I0321 13:32:01.851848 140058691233600 base_trainer.py:769] Step: 648 Lr 0.0160996 Loss scale 4096
I0321 13:32:01.852076 140058691233600 base_trainer.py:770] Train Step: 648/1000 / time=0.304 sec
I0321 13:32:01.852160 140058691233600 base_trainer.py:771] Perf 106739.66 samples/s
I0321 13:32:02.200022 140058691233600 base_trainer.py:769] Step: 649 Lr 0.0160581 Loss scale 4096
I0321 13:32:02.200237 140058691233600 base_trainer.py:770] Train Step: 649/1000 / time=0.345 sec
I0321 13:32:02.200335 140058691233600 base_trainer.py:771] Perf 94097.14 samples/s
I0321 13:32:02.520085 140058691233600 base_trainer.py:769] Step: 650 Lr 0.0160166 Loss scale 4096
I0321 13:32:02.520327 140058691233600 base_trainer.py:770] Train Step: 650/1000 / time=0.317 sec
I0321 13:32:02.520420 140058691233600 base_trainer.py:771] Perf 102405.75 samples/s
I0321 13:32:02.830932 140058691233600 base_trainer.py:769] Step: 651 Lr 0.0159751 Loss scale 4096
I0321 13:32:02.831161 140058691233600 base_trainer.py:770] Train Step: 651/1000 / time=0.308 sec
I0321 13:32:02.831245 140058691233600 base_trainer.py:771] Perf 105416.07 samples/s
I0321 13:32:03.142622 140058691233600 base_trainer.py:769] Step: 652 Lr 0.0159336 Loss scale 4096
I0321 13:32:03.142835 140058691233600 base_trainer.py:770] Train Step: 652/1000 / time=0.309 sec
I0321 13:32:03.142917 140058691233600 base_trainer.py:771] Perf 105111.29 samples/s
I0321 13:32:03.448584 140058691233600 base_trainer.py:769] Step: 653 Lr 0.0158921 Loss scale 4096
I0321 13:32:03.448816 140058691233600 base_trainer.py:770] Train Step: 653/1000 / time=0.303 sec
I0321 13:32:03.448898 140058691233600 base_trainer.py:771] Perf 107112.94 samples/s
I0321 13:32:03.765389 140058691233600 base_trainer.py:769] Step: 654 Lr 0.0158506 Loss scale 4096
I0321 13:32:03.765626 140058691233600 base_trainer.py:770] Train Step: 654/1000 / time=0.314 sec
I0321 13:32:03.765709 140058691233600 base_trainer.py:771] Perf 103454.00 samples/s
I0321 13:32:04.087384 140058691233600 base_trainer.py:769] Step: 655 Lr 0.0158091 Loss scale 4096
I0321 13:32:04.087622 140058691233600 base_trainer.py:770] Train Step: 655/1000 / time=0.319 sec
I0321 13:32:04.087721 140058691233600 base_trainer.py:771] Perf 101792.24 samples/s
I0321 13:32:04.401995 140058691233600 base_trainer.py:769] Step: 656 Lr 0.0157676 Loss scale 4096
I0321 13:32:04.402207 140058691233600 base_trainer.py:770] Train Step: 656/1000 / time=0.312 sec
I0321 13:32:04.402295 140058691233600 base_trainer.py:771] Perf 104099.83 samples/s
I0321 13:32:04.705680 140058691233600 base_trainer.py:769] Step: 657 Lr 0.0157261 Loss scale 4096
I0321 13:32:04.705899 140058691233600 base_trainer.py:770] Train Step: 657/1000 / time=0.301 sec
I0321 13:32:04.705980 140058691233600 base_trainer.py:771] Perf 107893.50 samples/s
I0321 13:32:05.010671 140058691233600 base_trainer.py:769] Step: 658 Lr 0.0156846 Loss scale 4096
I0321 13:32:05.010889 140058691233600 base_trainer.py:770] Train Step: 658/1000 / time=0.302 sec
I0321 13:32:05.010975 140058691233600 base_trainer.py:771] Perf 107471.00 samples/s
I0321 13:32:05.337533 140058691233600 base_trainer.py:769] Step: 659 Lr 0.0156432 Loss scale 4096
I0321 13:32:05.337754 140058691233600 base_trainer.py:770] Train Step: 659/1000 / time=0.324 sec
I0321 13:32:05.337837 140058691233600 base_trainer.py:771] Perf 100220.86 samples/s
I0321 13:32:05.648097 140058691233600 base_trainer.py:769] Step: 660 Lr 0.0156017 Loss scale 4096
I0321 13:32:05.648318 140058691233600 base_trainer.py:770] Train Step: 660/1000 / time=0.308 sec
I0321 13:32:05.648395 140058691233600 base_trainer.py:771] Perf 105456.60 samples/s
I0321 13:32:05.954532 140058691233600 base_trainer.py:769] Step: 661 Lr 0.0155602 Loss scale 4096
I0321 13:32:05.954751 140058691233600 base_trainer.py:770] Train Step: 661/1000 / time=0.303 sec
I0321 13:32:05.954835 140058691233600 base_trainer.py:771] Perf 107004.96 samples/s
I0321 13:32:06.274470 140058691233600 base_trainer.py:769] Step: 662 Lr 0.0155187 Loss scale 4096
I0321 13:32:06.274681 140058691233600 base_trainer.py:770] Train Step: 662/1000 / time=0.317 sec
I0321 13:32:06.274768 140058691233600 base_trainer.py:771] Perf 102415.33 samples/s
I0321 13:32:06.587955 140058691233600 base_trainer.py:769] Step: 663 Lr 0.0154772 Loss scale 4096
I0321 13:32:06.588162 140058691233600 base_trainer.py:770] Train Step: 663/1000 / time=0.311 sec
I0321 13:32:06.588238 140058691233600 base_trainer.py:771] Perf 104467.32 samples/s
I0321 13:32:06.903549 140058691233600 base_trainer.py:769] Step: 664 Lr 0.0154357 Loss scale 4096
I0321 13:32:06.903758 140058691233600 base_trainer.py:770] Train Step: 664/1000 / time=0.313 sec
I0321 13:32:06.903837 140058691233600 base_trainer.py:771] Perf 103828.71 samples/s
I0321 13:32:07.224899 140058691233600 base_trainer.py:769] Step: 665 Lr 0.0153942 Loss scale 4096
I0321 13:32:07.225125 140058691233600 base_trainer.py:770] Train Step: 665/1000 / time=0.318 sec
I0321 13:32:07.225208 140058691233600 base_trainer.py:771] Perf 102057.35 samples/s
I0321 13:32:07.544463 140058691233600 base_trainer.py:769] Step: 666 Lr 0.0153527 Loss scale 4096
I0321 13:32:07.544683 140058691233600 base_trainer.py:770] Train Step: 666/1000 / time=0.317 sec
I0321 13:32:07.544769 140058691233600 base_trainer.py:771] Perf 102543.34 samples/s
I0321 13:32:07.862053 140058691233600 base_trainer.py:769] Step: 667 Lr 0.0153112 Loss scale 4096
I0321 13:32:07.862259 140058691233600 base_trainer.py:770] Train Step: 667/1000 / time=0.315 sec
I0321 13:32:07.862336 140058691233600 base_trainer.py:771] Perf 103107.06 samples/s
I0321 13:32:08.186548 140058691233600 base_trainer.py:769] Step: 668 Lr 0.0152697 Loss scale 4096
I0321 13:32:08.186753 140058691233600 base_trainer.py:770] Train Step: 668/1000 / time=0.322 sec
I0321 13:32:08.186829 140058691233600 base_trainer.py:771] Perf 100966.56 samples/s
I0321 13:32:08.497609 140058691233600 base_trainer.py:769] Step: 669 Lr 0.0152282 Loss scale 4096
I0321 13:32:08.497830 140058691233600 base_trainer.py:770] Train Step: 669/1000 / time=0.308 sec
I0321 13:32:08.497911 140058691233600 base_trainer.py:771] Perf 105403.83 samples/s
I0321 13:32:08.814470 140058691233600 base_trainer.py:769] Step: 670 Lr 0.0151867 Loss scale 4096
I0321 13:32:08.814701 140058691233600 base_trainer.py:770] Train Step: 670/1000 / time=0.314 sec
I0321 13:32:08.814783 140058691233600 base_trainer.py:771] Perf 103451.97 samples/s
I0321 13:32:09.121102 140058691233600 base_trainer.py:769] Step: 671 Lr 0.0151452 Loss scale 4096
I0321 13:32:09.121323 140058691233600 base_trainer.py:770] Train Step: 671/1000 / time=0.304 sec
I0321 13:32:09.121405 140058691233600 base_trainer.py:771] Perf 106852.07 samples/s
I0321 13:32:09.444210 140058691233600 base_trainer.py:769] Step: 672 Lr 0.0151037 Loss scale 4096
I0321 13:32:09.444435 140058691233600 base_trainer.py:770] Train Step: 672/1000 / time=0.320 sec
I0321 13:32:09.444518 140058691233600 base_trainer.py:771] Perf 101366.64 samples/s
I0321 13:32:09.758782 140058691233600 base_trainer.py:769] Step: 673 Lr 0.0150622 Loss scale 4096
I0321 13:32:09.758996 140058691233600 base_trainer.py:770] Train Step: 673/1000 / time=0.312 sec
I0321 13:32:09.759074 140058691233600 base_trainer.py:771] Perf 104157.34 samples/s
I0321 13:32:10.062589 140058691233600 base_trainer.py:769] Step: 674 Lr 0.0150207 Loss scale 4096
I0321 13:32:10.062797 140058691233600 base_trainer.py:770] Train Step: 674/1000 / time=0.301 sec
I0321 13:32:10.062872 140058691233600 base_trainer.py:771] Perf 107836.23 samples/s
I0321 13:32:10.414473 140058691233600 base_trainer.py:769] Step: 675 Lr 0.0149793 Loss scale 4096
I0321 13:32:10.414689 140058691233600 base_trainer.py:770] Train Step: 675/1000 / time=0.349 sec
I0321 13:32:10.414772 140058691233600 base_trainer.py:771] Perf 93178.33 samples/s
I0321 13:32:10.733686 140058691233600 base_trainer.py:769] Step: 676 Lr 0.0149378 Loss scale 4096
I0321 13:32:10.733894 140058691233600 base_trainer.py:770] Train Step: 676/1000 / time=0.316 sec
I0321 13:32:10.733970 140058691233600 base_trainer.py:771] Perf 102607.92 samples/s
I0321 13:32:11.044239 140058691233600 base_trainer.py:769] Step: 677 Lr 0.0148963 Loss scale 4096
I0321 13:32:11.044469 140058691233600 base_trainer.py:770] Train Step: 677/1000 / time=0.308 sec
I0321 13:32:11.044551 140058691233600 base_trainer.py:771] Perf 105585.72 samples/s
I0321 13:32:11.348729 140058691233600 base_trainer.py:769] Step: 678 Lr 0.0148548 Loss scale 4096
I0321 13:32:11.348947 140058691233600 base_trainer.py:770] Train Step: 678/1000 / time=0.302 sec
I0321 13:32:11.349024 140058691233600 base_trainer.py:771] Perf 107612.69 samples/s
I0321 13:32:11.668361 140058691233600 base_trainer.py:769] Step: 679 Lr 0.0148133 Loss scale 4096
I0321 13:32:11.668581 140058691233600 base_trainer.py:770] Train Step: 679/1000 / time=0.316 sec
I0321 13:32:11.668666 140058691233600 base_trainer.py:771] Perf 102676.95 samples/s
I0321 13:32:11.977941 140058691233600 base_trainer.py:769] Step: 680 Lr 0.0147718 Loss scale 4096
I0321 13:32:11.978186 140058691233600 base_trainer.py:770] Train Step: 680/1000 / time=0.306 sec
I0321 13:32:11.978279 140058691233600 base_trainer.py:771] Perf 105803.98 samples/s
I0321 13:32:12.283090 140058691233600 base_trainer.py:769] Step: 681 Lr 0.0147303 Loss scale 4096
I0321 13:32:12.283315 140058691233600 base_trainer.py:770] Train Step: 681/1000 / time=0.302 sec
I0321 13:32:12.283400 140058691233600 base_trainer.py:771] Perf 107269.08 samples/s
I0321 13:32:12.592979 140058691233600 base_trainer.py:769] Step: 682 Lr 0.0146888 Loss scale 4096
I0321 13:32:12.593198 140058691233600 base_trainer.py:770] Train Step: 682/1000 / time=0.307 sec
I0321 13:32:12.593281 140058691233600 base_trainer.py:771] Perf 105693.56 samples/s
I0321 13:32:12.913815 140058691233600 base_trainer.py:769] Step: 683 Lr 0.0146473 Loss scale 4096
I0321 13:32:12.914026 140058691233600 base_trainer.py:770] Train Step: 683/1000 / time=0.318 sec
I0321 13:32:12.914104 140058691233600 base_trainer.py:771] Perf 102196.38 samples/s
I0321 13:32:13.222481 140058691233600 base_trainer.py:769] Step: 684 Lr 0.0146058 Loss scale 4096
I0321 13:32:13.222700 140058691233600 base_trainer.py:770] Train Step: 684/1000 / time=0.306 sec
I0321 13:32:13.222780 140058691233600 base_trainer.py:771] Perf 106106.57 samples/s
I0321 13:32:13.530337 140058691233600 base_trainer.py:769] Step: 685 Lr 0.0145643 Loss scale 4096
I0321 13:32:13.530550 140058691233600 base_trainer.py:770] Train Step: 685/1000 / time=0.305 sec
I0321 13:32:13.530692 140058691233600 base_trainer.py:771] Perf 106470.67 samples/s
I0321 13:32:13.835615 140058691233600 base_trainer.py:769] Step: 686 Lr 0.0145228 Loss scale 4096
I0321 13:32:13.835832 140058691233600 base_trainer.py:770] Train Step: 686/1000 / time=0.302 sec
I0321 13:32:13.835913 140058691233600 base_trainer.py:771] Perf 107345.18 samples/s
I0321 13:32:14.156423 140058691233600 base_trainer.py:769] Step: 687 Lr 0.0144813 Loss scale 4096
I0321 13:32:14.156916 140058691233600 base_trainer.py:770] Train Step: 687/1000 / time=0.317 sec
I0321 13:32:14.157242 140058691233600 base_trainer.py:771] Perf 102329.52 samples/s
I0321 13:32:14.466033 140058691233600 base_trainer.py:769] Step: 688 Lr 0.0144398 Loss scale 4096
I0321 13:32:14.466257 140058691233600 base_trainer.py:770] Train Step: 688/1000 / time=0.306 sec
I0321 13:32:14.466338 140058691233600 base_trainer.py:771] Perf 105646.49 samples/s
I0321 13:32:14.772983 140058691233600 base_trainer.py:769] Step: 689 Lr 0.0143983 Loss scale 4096
I0321 13:32:14.773207 140058691233600 base_trainer.py:770] Train Step: 689/1000 / time=0.304 sec
I0321 13:32:14.773291 140058691233600 base_trainer.py:771] Perf 106743.46 samples/s
I0321 13:32:15.094688 140058691233600 base_trainer.py:769] Step: 690 Lr 0.0143568 Loss scale 4096
I0321 13:32:15.094951 140058691233600 base_trainer.py:770] Train Step: 690/1000 / time=0.318 sec
I0321 13:32:15.095040 140058691233600 base_trainer.py:771] Perf 101950.00 samples/s
I0321 13:32:15.395937 140058691233600 base_trainer.py:769] Step: 691 Lr 0.0143154 Loss scale 4096
I0321 13:32:15.396446 140058691233600 base_trainer.py:770] Train Step: 691/1000 / time=0.298 sec
I0321 13:32:15.396687 140058691233600 base_trainer.py:771] Perf 108635.29 samples/s
I0321 13:32:15.709900 140058691233600 base_trainer.py:769] Step: 692 Lr 0.0142739 Loss scale 4096
I0321 13:32:15.710160 140058691233600 base_trainer.py:770] Train Step: 692/1000 / time=0.310 sec
I0321 13:32:15.710243 140058691233600 base_trainer.py:771] Perf 104495.72 samples/s
I0321 13:32:16.016016 140058691233600 base_trainer.py:769] Step: 693 Lr 0.0142324 Loss scale 4096
I0321 13:32:16.016228 140058691233600 base_trainer.py:770] Train Step: 693/1000 / time=0.303 sec
I0321 13:32:16.016324 140058691233600 base_trainer.py:771] Perf 106924.12 samples/s
I0321 13:32:16.349532 140058691233600 base_trainer.py:769] Step: 694 Lr 0.0141909 Loss scale 4096
I0321 13:32:16.349778 140058691233600 base_trainer.py:770] Train Step: 694/1000 / time=0.330 sec
I0321 13:32:16.349867 140058691233600 base_trainer.py:771] Perf 98378.06 samples/s
I0321 13:32:16.667427 140058691233600 base_trainer.py:769] Step: 695 Lr 0.0141494 Loss scale 4096
I0321 13:32:16.667737 140058691233600 base_trainer.py:770] Train Step: 695/1000 / time=0.315 sec
I0321 13:32:16.667844 140058691233600 base_trainer.py:771] Perf 103011.72 samples/s
I0321 13:32:16.963348 140058691233600 base_trainer.py:769] Step: 696 Lr 0.0141079 Loss scale 4096
I0321 13:32:16.963573 140058691233600 base_trainer.py:770] Train Step: 696/1000 / time=0.293 sec
I0321 13:32:16.963652 140058691233600 base_trainer.py:771] Perf 110703.50 samples/s
I0321 13:32:17.265307 140058691233600 base_trainer.py:769] Step: 697 Lr 0.0140664 Loss scale 4096
I0321 13:32:17.265538 140058691233600 base_trainer.py:770] Train Step: 697/1000 / time=0.299 sec
I0321 13:32:17.265618 140058691233600 base_trainer.py:771] Perf 108557.46 samples/s
I0321 13:32:17.585207 140058691233600 base_trainer.py:769] Step: 698 Lr 0.0140249 Loss scale 4096
I0321 13:32:17.585427 140058691233600 base_trainer.py:770] Train Step: 698/1000 / time=0.317 sec
I0321 13:32:17.585512 140058691233600 base_trainer.py:771] Perf 102376.13 samples/s
I0321 13:32:17.889112 140058691233600 base_trainer.py:769] Step: 699 Lr 0.0139834 Loss scale 4096
I0321 13:32:17.889332 140058691233600 base_trainer.py:770] Train Step: 699/1000 / time=0.301 sec
I0321 13:32:17.889454 140058691233600 base_trainer.py:771] Perf 107820.76 samples/s
I0321 13:32:18.203719 140058691233600 base_trainer.py:769] Step: 700 Lr 0.0139419 Loss scale 4096
I0321 13:32:18.203935 140058691233600 base_trainer.py:770] Train Step: 700/1000 / time=0.312 sec
I0321 13:32:18.204013 140058691233600 base_trainer.py:771] Perf 104133.12 samples/s
I0321 13:32:18.518049 140058691233600 base_trainer.py:769] Step: 701 Lr 0.0139004 Loss scale 4096
I0321 13:32:18.518283 140058691233600 base_trainer.py:770] Train Step: 701/1000 / time=0.311 sec
I0321 13:32:18.518365 140058691233600 base_trainer.py:771] Perf 104302.21 samples/s
I0321 13:32:18.859677 140058691233600 base_trainer.py:769] Step: 702 Lr 0.0138589 Loss scale 4096
I0321 13:32:18.859888 140058691233600 base_trainer.py:770] Train Step: 702/1000 / time=0.339 sec
I0321 13:32:18.859964 140058691233600 base_trainer.py:771] Perf 95845.74 samples/s
I0321 13:32:19.175068 140058691233600 base_trainer.py:769] Step: 703 Lr 0.0138174 Loss scale 4096
I0321 13:32:19.175288 140058691233600 base_trainer.py:770] Train Step: 703/1000 / time=0.312 sec
I0321 13:32:19.175366 140058691233600 base_trainer.py:771] Perf 103960.89 samples/s
I0321 13:32:19.483529 140058691233600 base_trainer.py:769] Step: 704 Lr 0.0137759 Loss scale 4096
I0321 13:32:19.483741 140058691233600 base_trainer.py:770] Train Step: 704/1000 / time=0.306 sec
I0321 13:32:19.483823 140058691233600 base_trainer.py:771] Perf 106237.59 samples/s
I0321 13:32:19.795981 140058691233600 base_trainer.py:769] Step: 705 Lr 0.0137344 Loss scale 4096
I0321 13:32:19.796235 140058691233600 base_trainer.py:770] Train Step: 705/1000 / time=0.309 sec
I0321 13:32:19.796354 140058691233600 base_trainer.py:771] Perf 104903.00 samples/s
I0321 13:32:20.097323 140058691233600 base_trainer.py:769] Step: 706 Lr 0.0136929 Loss scale 4096
I0321 13:32:20.097538 140058691233600 base_trainer.py:770] Train Step: 706/1000 / time=0.298 sec
I0321 13:32:20.097626 140058691233600 base_trainer.py:771] Perf 108699.74 samples/s
I0321 13:32:20.410883 140058691233600 base_trainer.py:769] Step: 707 Lr 0.0136515 Loss scale 4096
I0321 13:32:20.411520 140058691233600 base_trainer.py:770] Train Step: 707/1000 / time=0.311 sec
I0321 13:32:20.411681 140058691233600 base_trainer.py:771] Perf 104489.66 samples/s
I0321 13:32:20.715014 140058691233600 base_trainer.py:769] Step: 708 Lr 0.01361 Loss scale 4096
I0321 13:32:20.715248 140058691233600 base_trainer.py:770] Train Step: 708/1000 / time=0.301 sec
I0321 13:32:20.715344 140058691233600 base_trainer.py:771] Perf 107799.03 samples/s
I0321 13:32:21.023103 140058691233600 base_trainer.py:769] Step: 709 Lr 0.0135685 Loss scale 4096
I0321 13:32:21.023325 140058691233600 base_trainer.py:770] Train Step: 709/1000 / time=0.305 sec
I0321 13:32:21.023403 140058691233600 base_trainer.py:771] Perf 106293.43 samples/s
I0321 13:32:21.339859 140058691233600 base_trainer.py:769] Step: 710 Lr 0.013527 Loss scale 4096
I0321 13:32:21.340082 140058691233600 base_trainer.py:770] Train Step: 710/1000 / time=0.314 sec
I0321 13:32:21.340165 140058691233600 base_trainer.py:771] Perf 103502.40 samples/s
I0321 13:32:21.645931 140058691233600 base_trainer.py:769] Step: 711 Lr 0.0134855 Loss scale 4096
I0321 13:32:21.646266 140058691233600 base_trainer.py:770] Train Step: 711/1000 / time=0.303 sec
I0321 13:32:21.646398 140058691233600 base_trainer.py:771] Perf 107038.23 samples/s
I0321 13:32:21.982328 140058691233600 base_trainer.py:769] Step: 712 Lr 0.013444 Loss scale 4096
I0321 13:32:21.982554 140058691233600 base_trainer.py:770] Train Step: 712/1000 / time=0.333 sec
I0321 13:32:21.982641 140058691233600 base_trainer.py:771] Perf 97471.83 samples/s
I0321 13:32:22.296932 140058691233600 base_trainer.py:769] Step: 713 Lr 0.0134025 Loss scale 4096
I0321 13:32:22.297163 140058691233600 base_trainer.py:770] Train Step: 713/1000 / time=0.312 sec
I0321 13:32:22.297242 140058691233600 base_trainer.py:771] Perf 104049.33 samples/s
I0321 13:32:22.610225 140058691233600 base_trainer.py:769] Step: 714 Lr 0.013361 Loss scale 4096
I0321 13:32:22.610445 140058691233600 base_trainer.py:770] Train Step: 714/1000 / time=0.310 sec
I0321 13:32:22.610527 140058691233600 base_trainer.py:771] Perf 104658.12 samples/s
I0321 13:32:22.922053 140058691233600 base_trainer.py:769] Step: 715 Lr 0.0133195 Loss scale 4096
I0321 13:32:22.922273 140058691233600 base_trainer.py:770] Train Step: 715/1000 / time=0.309 sec
I0321 13:32:22.922352 140058691233600 base_trainer.py:771] Perf 105070.77 samples/s
I0321 13:32:23.238368 140058691233600 base_trainer.py:769] Step: 716 Lr 0.013278 Loss scale 4096
I0321 13:32:23.238590 140058691233600 base_trainer.py:770] Train Step: 716/1000 / time=0.314 sec
I0321 13:32:23.238664 140058691233600 base_trainer.py:771] Perf 103512.07 samples/s
I0321 13:32:23.544979 140058691233600 base_trainer.py:769] Step: 717 Lr 0.0132365 Loss scale 4096
I0321 13:32:23.545199 140058691233600 base_trainer.py:770] Train Step: 717/1000 / time=0.304 sec
I0321 13:32:23.545280 140058691233600 base_trainer.py:771] Perf 106971.98 samples/s
I0321 13:32:23.857066 140058691233600 base_trainer.py:769] Step: 718 Lr 0.013195 Loss scale 4096
I0321 13:32:23.857277 140058691233600 base_trainer.py:770] Train Step: 718/1000 / time=0.309 sec
I0321 13:32:23.857352 140058691233600 base_trainer.py:771] Perf 104945.24 samples/s
I0321 13:32:24.168591 140058691233600 base_trainer.py:769] Step: 719 Lr 0.0131535 Loss scale 4096
I0321 13:32:24.168797 140058691233600 base_trainer.py:770] Train Step: 719/1000 / time=0.309 sec
I0321 13:32:24.168873 140058691233600 base_trainer.py:771] Perf 105170.98 samples/s
I0321 13:32:24.481860 140058691233600 base_trainer.py:769] Step: 720 Lr 0.013112 Loss scale 4096
I0321 13:32:24.482066 140058691233600 base_trainer.py:770] Train Step: 720/1000 / time=0.311 sec
I0321 13:32:24.482142 140058691233600 base_trainer.py:771] Perf 104602.18 samples/s
I0321 13:32:24.793134 140058691233600 base_trainer.py:769] Step: 721 Lr 0.0130705 Loss scale 4096
I0321 13:32:24.793358 140058691233600 base_trainer.py:770] Train Step: 721/1000 / time=0.308 sec
I0321 13:32:24.793437 140058691233600 base_trainer.py:771] Perf 105345.39 samples/s
I0321 13:32:25.104831 140058691233600 base_trainer.py:769] Step: 722 Lr 0.013029 Loss scale 4096
I0321 13:32:25.105042 140058691233600 base_trainer.py:770] Train Step: 722/1000 / time=0.309 sec
I0321 13:32:25.105122 140058691233600 base_trainer.py:771] Perf 105130.21 samples/s
I0321 13:32:25.418313 140058691233600 base_trainer.py:769] Step: 723 Lr 0.0129876 Loss scale 4096
I0321 13:32:25.418538 140058691233600 base_trainer.py:770] Train Step: 723/1000 / time=0.310 sec
I0321 13:32:25.418618 140058691233600 base_trainer.py:771] Perf 104541.01 samples/s
I0321 13:32:25.730103 140058691233600 base_trainer.py:769] Step: 724 Lr 0.0129461 Loss scale 4096
I0321 13:32:25.730313 140058691233600 base_trainer.py:770] Train Step: 724/1000 / time=0.309 sec
I0321 13:32:25.730389 140058691233600 base_trainer.py:771] Perf 105025.59 samples/s
I0321 13:32:26.041437 140058691233600 base_trainer.py:769] Step: 725 Lr 0.0129046 Loss scale 4096
I0321 13:32:26.041649 140058691233600 base_trainer.py:770] Train Step: 725/1000 / time=0.309 sec
I0321 13:32:26.041724 140058691233600 base_trainer.py:771] Perf 105267.31 samples/s
I0321 13:32:26.351211 140058691233600 base_trainer.py:769] Step: 726 Lr 0.0128631 Loss scale 4096
I0321 13:32:26.351447 140058691233600 base_trainer.py:770] Train Step: 726/1000 / time=0.307 sec
I0321 13:32:26.351537 140058691233600 base_trainer.py:771] Perf 105891.69 samples/s
I0321 13:32:26.679739 140058691233600 base_trainer.py:769] Step: 727 Lr 0.0128216 Loss scale 4096
I0321 13:32:26.679960 140058691233600 base_trainer.py:770] Train Step: 727/1000 / time=0.326 sec
I0321 13:32:26.680038 140058691233600 base_trainer.py:771] Perf 99640.70 samples/s
I0321 13:32:27.022727 140058691233600 base_trainer.py:769] Step: 728 Lr 0.0127801 Loss scale 4096
I0321 13:32:27.022953 140058691233600 base_trainer.py:770] Train Step: 728/1000 / time=0.340 sec
I0321 13:32:27.023035 140058691233600 base_trainer.py:771] Perf 95567.47 samples/s
I0321 13:32:27.344900 140058691233600 base_trainer.py:769] Step: 729 Lr 0.0127386 Loss scale 4096
I0321 13:32:27.345120 140058691233600 base_trainer.py:770] Train Step: 729/1000 / time=0.319 sec
I0321 13:32:27.345204 140058691233600 base_trainer.py:771] Perf 101730.86 samples/s
I0321 13:32:27.407658 140058691233600 base_trainer.py:769] Step: 730 Lr 0.0126971 Loss scale 2048
I0321 13:32:27.407871 140058691233600 base_trainer.py:770] Train Step: 730/1000 / time=0.060 sec
I0321 13:32:27.407948 140058691233600 base_trainer.py:771] Perf 521701.71 samples/s
I0321 13:32:27.700907 140058691233600 base_trainer.py:769] Step: 731 Lr 0.0126556 Loss scale 2048
I0321 13:32:27.701138 140058691233600 base_trainer.py:770] Train Step: 731/1000 / time=0.290 sec
I0321 13:32:27.701219 140058691233600 base_trainer.py:771] Perf 111775.62 samples/s
I0321 13:32:28.010356 140058691233600 base_trainer.py:769] Step: 732 Lr 0.0126141 Loss scale 2048
I0321 13:32:28.010564 140058691233600 base_trainer.py:770] Train Step: 732/1000 / time=0.307 sec
I0321 13:32:28.010640 140058691233600 base_trainer.py:771] Perf 105804.38 samples/s
I0321 13:32:28.301786 140058691233600 base_trainer.py:769] Step: 733 Lr 0.0125726 Loss scale 2048
I0321 13:32:28.302016 140058691233600 base_trainer.py:770] Train Step: 733/1000 / time=0.288 sec
I0321 13:32:28.302102 140058691233600 base_trainer.py:771] Perf 112584.93 samples/s
I0321 13:32:28.616729 140058691233600 base_trainer.py:769] Step: 734 Lr 0.0125311 Loss scale 2048
I0321 13:32:28.616951 140058691233600 base_trainer.py:770] Train Step: 734/1000 / time=0.312 sec
I0321 13:32:28.617036 140058691233600 base_trainer.py:771] Perf 103999.73 samples/s
I0321 13:32:28.912414 140058691233600 base_trainer.py:769] Step: 735 Lr 0.0124896 Loss scale 2048
I0321 13:32:28.912627 140058691233600 base_trainer.py:770] Train Step: 735/1000 / time=0.293 sec
I0321 13:32:28.912709 140058691233600 base_trainer.py:771] Perf 110776.78 samples/s
I0321 13:32:29.213224 140058691233600 base_trainer.py:769] Step: 736 Lr 0.0124481 Loss scale 2048
I0321 13:32:29.213436 140058691233600 base_trainer.py:770] Train Step: 736/1000 / time=0.298 sec
I0321 13:32:29.213529 140058691233600 base_trainer.py:771] Perf 108958.15 samples/s
I0321 13:32:29.518909 140058691233600 base_trainer.py:769] Step: 737 Lr 0.0124066 Loss scale 2048
I0321 13:32:29.519139 140058691233600 base_trainer.py:770] Train Step: 737/1000 / time=0.303 sec
I0321 13:32:29.519222 140058691233600 base_trainer.py:771] Perf 107218.04 samples/s
I0321 13:32:29.814496 140058691233600 base_trainer.py:769] Step: 738 Lr 0.0123651 Loss scale 2048
I0321 13:32:29.814706 140058691233600 base_trainer.py:770] Train Step: 738/1000 / time=0.293 sec
I0321 13:32:29.814783 140058691233600 base_trainer.py:771] Perf 110776.32 samples/s
I0321 13:32:30.117042 140058691233600 base_trainer.py:769] Step: 739 Lr 0.0123237 Loss scale 2048
I0321 13:32:30.117259 140058691233600 base_trainer.py:770] Train Step: 739/1000 / time=0.300 sec
I0321 13:32:30.117337 140058691233600 base_trainer.py:771] Perf 108289.26 samples/s
I0321 13:32:30.417525 140058691233600 base_trainer.py:769] Step: 740 Lr 0.0122822 Loss scale 2048
I0321 13:32:30.417746 140058691233600 base_trainer.py:770] Train Step: 740/1000 / time=0.298 sec
I0321 13:32:30.417822 140058691233600 base_trainer.py:771] Perf 109046.29 samples/s
I0321 13:32:30.715004 140058691233600 base_trainer.py:769] Step: 741 Lr 0.0122407 Loss scale 2048
I0321 13:32:30.715228 140058691233600 base_trainer.py:770] Train Step: 741/1000 / time=0.294 sec
I0321 13:32:30.715312 140058691233600 base_trainer.py:771] Perf 110277.52 samples/s
I0321 13:32:31.013417 140058691233600 base_trainer.py:769] Step: 742 Lr 0.0121992 Loss scale 2048
I0321 13:32:31.013626 140058691233600 base_trainer.py:770] Train Step: 742/1000 / time=0.296 sec
I0321 13:32:31.013702 140058691233600 base_trainer.py:771] Perf 109732.41 samples/s
I0321 13:32:31.320765 140058691233600 base_trainer.py:769] Step: 743 Lr 0.0121577 Loss scale 2048
I0321 13:32:31.320997 140058691233600 base_trainer.py:770] Train Step: 743/1000 / time=0.304 sec
I0321 13:32:31.321079 140058691233600 base_trainer.py:771] Perf 106703.74 samples/s
I0321 13:32:31.622951 140058691233600 base_trainer.py:769] Step: 744 Lr 0.0121162 Loss scale 2048
I0321 13:32:31.623168 140058691233600 base_trainer.py:770] Train Step: 744/1000 / time=0.299 sec
I0321 13:32:31.623246 140058691233600 base_trainer.py:771] Perf 108416.19 samples/s
I0321 13:32:31.916611 140058691233600 base_trainer.py:769] Step: 745 Lr 0.0120747 Loss scale 2048
I0321 13:32:31.916872 140058691233600 base_trainer.py:770] Train Step: 745/1000 / time=0.290 sec
I0321 13:32:31.916960 140058691233600 base_trainer.py:771] Perf 111715.18 samples/s
I0321 13:32:32.210857 140058691233600 base_trainer.py:769] Step: 746 Lr 0.0120332 Loss scale 2048
I0321 13:32:32.211071 140058691233600 base_trainer.py:770] Train Step: 746/1000 / time=0.291 sec
I0321 13:32:32.211151 140058691233600 base_trainer.py:771] Perf 111206.41 samples/s
I0321 13:32:32.509943 140058691233600 base_trainer.py:769] Step: 747 Lr 0.0119917 Loss scale 2048
I0321 13:32:32.510153 140058691233600 base_trainer.py:770] Train Step: 747/1000 / time=0.296 sec
I0321 13:32:32.510230 140058691233600 base_trainer.py:771] Perf 109514.54 samples/s
I0321 13:32:32.809682 140058691233600 base_trainer.py:769] Step: 748 Lr 0.0119502 Loss scale 2048
I0321 13:32:32.810773 140058691233600 base_trainer.py:770] Train Step: 748/1000 / time=0.297 sec
I0321 13:32:32.811040 140058691233600 base_trainer.py:771] Perf 109486.03 samples/s
I0321 13:32:33.116217 140058691233600 base_trainer.py:769] Step: 749 Lr 0.0119087 Loss scale 2048
I0321 13:32:33.116453 140058691233600 base_trainer.py:770] Train Step: 749/1000 / time=0.302 sec
I0321 13:32:33.116540 140058691233600 base_trainer.py:771] Perf 106816.99 samples/s
I0321 13:32:33.428427 140058691233600 base_trainer.py:769] Step: 750 Lr 0.0118672 Loss scale 2048
I0321 13:32:33.428662 140058691233600 base_trainer.py:770] Train Step: 750/1000 / time=0.309 sec
I0321 13:32:33.428750 140058691233600 base_trainer.py:771] Perf 104988.04 samples/s
I0321 13:32:33.743027 140058691233600 base_trainer.py:769] Step: 751 Lr 0.0118257 Loss scale 2048
I0321 13:32:33.743234 140058691233600 base_trainer.py:770] Train Step: 751/1000 / time=0.312 sec
I0321 13:32:33.743309 140058691233600 base_trainer.py:771] Perf 104050.97 samples/s
I0321 13:32:34.039199 140058691233600 base_trainer.py:769] Step: 752 Lr 0.0117842 Loss scale 2048
I0321 13:32:34.039413 140058691233600 base_trainer.py:770] Train Step: 752/1000 / time=0.293 sec
I0321 13:32:34.039489 140058691233600 base_trainer.py:771] Perf 110690.82 samples/s
I0321 13:32:34.349481 140058691233600 base_trainer.py:769] Step: 753 Lr 0.0117427 Loss scale 2048
I0321 13:32:34.349717 140058691233600 base_trainer.py:770] Train Step: 753/1000 / time=0.307 sec
I0321 13:32:34.349803 140058691233600 base_trainer.py:771] Perf 105661.13 samples/s
I0321 13:32:34.652341 140058691233600 base_trainer.py:769] Step: 754 Lr 0.0117012 Loss scale 2048
I0321 13:32:34.652550 140058691233600 base_trainer.py:770] Train Step: 754/1000 / time=0.300 sec
I0321 13:32:34.652627 140058691233600 base_trainer.py:771] Perf 108105.75 samples/s
I0321 13:32:34.954602 140058691233600 base_trainer.py:769] Step: 755 Lr 0.0116598 Loss scale 2048
I0321 13:32:34.954822 140058691233600 base_trainer.py:770] Train Step: 755/1000 / time=0.299 sec
I0321 13:32:34.954906 140058691233600 base_trainer.py:771] Perf 108463.93 samples/s
I0321 13:32:35.285534 140058691233600 base_trainer.py:769] Step: 756 Lr 0.0116183 Loss scale 2048
I0321 13:32:35.285759 140058691233600 base_trainer.py:770] Train Step: 756/1000 / time=0.328 sec
I0321 13:32:35.285844 140058691233600 base_trainer.py:771] Perf 99033.56 samples/s
I0321 13:32:35.585042 140058691233600 base_trainer.py:769] Step: 757 Lr 0.0115768 Loss scale 2048
I0321 13:32:35.585254 140058691233600 base_trainer.py:770] Train Step: 757/1000 / time=0.297 sec
I0321 13:32:35.585332 140058691233600 base_trainer.py:771] Perf 109337.15 samples/s
I0321 13:32:35.884944 140058691233600 base_trainer.py:769] Step: 758 Lr 0.0115353 Loss scale 2048
I0321 13:32:35.885168 140058691233600 base_trainer.py:770] Train Step: 758/1000 / time=0.297 sec
I0321 13:32:35.885251 140058691233600 base_trainer.py:771] Perf 109337.12 samples/s
I0321 13:32:36.192102 140058691233600 base_trainer.py:769] Step: 759 Lr 0.0114938 Loss scale 2048
I0321 13:32:36.192343 140058691233600 base_trainer.py:770] Train Step: 759/1000 / time=0.304 sec
I0321 13:32:36.192439 140058691233600 base_trainer.py:771] Perf 106830.68 samples/s
I0321 13:32:36.497592 140058691233600 base_trainer.py:769] Step: 760 Lr 0.0114523 Loss scale 2048
I0321 13:32:36.497846 140058691233600 base_trainer.py:770] Train Step: 760/1000 / time=0.302 sec
I0321 13:32:36.497962 140058691233600 base_trainer.py:771] Perf 107215.20 samples/s
I0321 13:32:36.801344 140058691233600 base_trainer.py:769] Step: 761 Lr 0.0114108 Loss scale 2048
I0321 13:32:36.801573 140058691233600 base_trainer.py:770] Train Step: 761/1000 / time=0.301 sec
I0321 13:32:36.801665 140058691233600 base_trainer.py:771] Perf 107853.79 samples/s
I0321 13:32:37.099821 140058691233600 base_trainer.py:769] Step: 762 Lr 0.0113693 Loss scale 2048
I0321 13:32:37.100029 140058691233600 base_trainer.py:770] Train Step: 762/1000 / time=0.296 sec
I0321 13:32:37.100106 140058691233600 base_trainer.py:771] Perf 109636.56 samples/s
I0321 13:32:37.401349 140058691233600 base_trainer.py:769] Step: 763 Lr 0.0113278 Loss scale 2048
I0321 13:32:37.401582 140058691233600 base_trainer.py:770] Train Step: 763/1000 / time=0.298 sec
I0321 13:32:37.401668 140058691233600 base_trainer.py:771] Perf 108802.56 samples/s
I0321 13:32:37.707686 140058691233600 base_trainer.py:769] Step: 764 Lr 0.0112863 Loss scale 2048
I0321 13:32:37.707900 140058691233600 base_trainer.py:770] Train Step: 764/1000 / time=0.304 sec
I0321 13:32:37.707977 140058691233600 base_trainer.py:771] Perf 106857.04 samples/s
I0321 13:32:38.008589 140058691233600 base_trainer.py:769] Step: 765 Lr 0.0112448 Loss scale 2048
I0321 13:32:38.008797 140058691233600 base_trainer.py:770] Train Step: 765/1000 / time=0.298 sec
I0321 13:32:38.008878 140058691233600 base_trainer.py:771] Perf 108897.56 samples/s
I0321 13:32:38.306976 140058691233600 base_trainer.py:769] Step: 766 Lr 0.0112033 Loss scale 2048
I0321 13:32:38.307195 140058691233600 base_trainer.py:770] Train Step: 766/1000 / time=0.295 sec
I0321 13:32:38.307278 140058691233600 base_trainer.py:771] Perf 109875.74 samples/s
I0321 13:32:38.609882 140058691233600 base_trainer.py:769] Step: 767 Lr 0.0111618 Loss scale 2048
I0321 13:32:38.610111 140058691233600 base_trainer.py:770] Train Step: 767/1000 / time=0.300 sec
I0321 13:32:38.610195 140058691233600 base_trainer.py:771] Perf 108187.70 samples/s
I0321 13:32:38.913250 140058691233600 base_trainer.py:769] Step: 768 Lr 0.0111203 Loss scale 2048
I0321 13:32:38.913622 140058691233600 base_trainer.py:770] Train Step: 768/1000 / time=0.300 sec
I0321 13:32:38.913707 140058691233600 base_trainer.py:771] Perf 108054.40 samples/s
I0321 13:32:39.219574 140058691233600 base_trainer.py:769] Step: 769 Lr 0.0110788 Loss scale 2048
I0321 13:32:39.219797 140058691233600 base_trainer.py:770] Train Step: 769/1000 / time=0.303 sec
I0321 13:32:39.219880 140058691233600 base_trainer.py:771] Perf 106937.34 samples/s
I0321 13:32:39.527058 140058691233600 base_trainer.py:769] Step: 770 Lr 0.0110373 Loss scale 2048
I0321 13:32:39.527264 140058691233600 base_trainer.py:770] Train Step: 770/1000 / time=0.305 sec
I0321 13:32:39.527341 140058691233600 base_trainer.py:771] Perf 106498.66 samples/s
I0321 13:32:39.836102 140058691233600 base_trainer.py:769] Step: 771 Lr 0.0109958 Loss scale 2048
I0321 13:32:39.836339 140058691233600 base_trainer.py:770] Train Step: 771/1000 / time=0.306 sec
I0321 13:32:39.836424 140058691233600 base_trainer.py:771] Perf 106100.04 samples/s
I0321 13:32:40.139576 140058691233600 base_trainer.py:769] Step: 772 Lr 0.0109544 Loss scale 2048
I0321 13:32:40.139789 140058691233600 base_trainer.py:770] Train Step: 772/1000 / time=0.301 sec
I0321 13:32:40.139866 140058691233600 base_trainer.py:771] Perf 107953.87 samples/s
I0321 13:32:40.439820 140058691233600 base_trainer.py:769] Step: 773 Lr 0.0109129 Loss scale 2048
I0321 13:32:40.440038 140058691233600 base_trainer.py:770] Train Step: 773/1000 / time=0.297 sec
I0321 13:32:40.440119 140058691233600 base_trainer.py:771] Perf 109162.66 samples/s
I0321 13:32:40.749842 140058691233600 base_trainer.py:769] Step: 774 Lr 0.0108714 Loss scale 2048
I0321 13:32:40.750060 140058691233600 base_trainer.py:770] Train Step: 774/1000 / time=0.307 sec
I0321 13:32:40.750141 140058691233600 base_trainer.py:771] Perf 105705.97 samples/s
I0321 13:32:41.051844 140058691233600 base_trainer.py:769] Step: 775 Lr 0.0108299 Loss scale 2048
I0321 13:32:41.052071 140058691233600 base_trainer.py:770] Train Step: 775/1000 / time=0.299 sec
I0321 13:32:41.052156 140058691233600 base_trainer.py:771] Perf 108492.33 samples/s
I0321 13:32:41.357404 140058691233600 base_trainer.py:769] Step: 776 Lr 0.0107884 Loss scale 2048
I0321 13:32:41.357623 140058691233600 base_trainer.py:770] Train Step: 776/1000 / time=0.303 sec
I0321 13:32:41.357707 140058691233600 base_trainer.py:771] Perf 107238.88 samples/s
I0321 13:32:41.657454 140058691233600 base_trainer.py:769] Step: 777 Lr 0.0107469 Loss scale 2048
I0321 13:32:41.657672 140058691233600 base_trainer.py:770] Train Step: 777/1000 / time=0.297 sec
I0321 13:32:41.657757 140058691233600 base_trainer.py:771] Perf 109223.56 samples/s
I0321 13:32:41.954308 140058691233600 base_trainer.py:769] Step: 778 Lr 0.0107054 Loss scale 2048
I0321 13:32:41.954532 140058691233600 base_trainer.py:770] Train Step: 778/1000 / time=0.294 sec
I0321 13:32:41.954609 140058691233600 base_trainer.py:771] Perf 110378.46 samples/s
I0321 13:32:42.251755 140058691233600 base_trainer.py:769] Step: 779 Lr 0.0106639 Loss scale 2048
I0321 13:32:42.251983 140058691233600 base_trainer.py:770] Train Step: 779/1000 / time=0.294 sec
I0321 13:32:42.252066 140058691233600 base_trainer.py:771] Perf 110188.98 samples/s
I0321 13:32:42.547267 140058691233600 base_trainer.py:769] Step: 780 Lr 0.0106224 Loss scale 2048
I0321 13:32:42.547484 140058691233600 base_trainer.py:770] Train Step: 780/1000 / time=0.293 sec
I0321 13:32:42.547567 140058691233600 base_trainer.py:771] Perf 110868.83 samples/s
I0321 13:32:42.847702 140058691233600 base_trainer.py:769] Step: 781 Lr 0.0105809 Loss scale 2048
I0321 13:32:42.847930 140058691233600 base_trainer.py:770] Train Step: 781/1000 / time=0.297 sec
I0321 13:32:42.848014 140058691233600 base_trainer.py:771] Perf 109081.50 samples/s
I0321 13:32:43.154409 140058691233600 base_trainer.py:769] Step: 782 Lr 0.0105394 Loss scale 2048
I0321 13:32:43.154618 140058691233600 base_trainer.py:770] Train Step: 782/1000 / time=0.304 sec
I0321 13:32:43.154742 140058691233600 base_trainer.py:771] Perf 106763.81 samples/s
I0321 13:32:43.446625 140058691233600 base_trainer.py:769] Step: 783 Lr 0.0104979 Loss scale 2048
I0321 13:32:43.446849 140058691233600 base_trainer.py:770] Train Step: 783/1000 / time=0.289 sec
I0321 13:32:43.446933 140058691233600 base_trainer.py:771] Perf 112217.65 samples/s
I0321 13:32:43.773967 140058691233600 base_trainer.py:769] Step: 784 Lr 0.0104564 Loss scale 2048
I0321 13:32:43.774178 140058691233600 base_trainer.py:770] Train Step: 784/1000 / time=0.325 sec
I0321 13:32:43.774255 140058691233600 base_trainer.py:771] Perf 100048.47 samples/s
I0321 13:32:44.071964 140058691233600 base_trainer.py:769] Step: 785 Lr 0.0104149 Loss scale 2048
I0321 13:32:44.072190 140058691233600 base_trainer.py:770] Train Step: 785/1000 / time=0.295 sec
I0321 13:32:44.072292 140058691233600 base_trainer.py:771] Perf 110036.46 samples/s
I0321 13:32:44.377069 140058691233600 base_trainer.py:769] Step: 786 Lr 0.0103734 Loss scale 2048
I0321 13:32:44.377299 140058691233600 base_trainer.py:770] Train Step: 786/1000 / time=0.302 sec
I0321 13:32:44.377381 140058691233600 base_trainer.py:771] Perf 107438.03 samples/s
I0321 13:32:44.667674 140058691233600 base_trainer.py:769] Step: 787 Lr 0.010332 Loss scale 2048
I0321 13:32:44.667891 140058691233600 base_trainer.py:770] Train Step: 787/1000 / time=0.288 sec
I0321 13:32:44.667967 140058691233600 base_trainer.py:771] Perf 112682.10 samples/s
I0321 13:32:44.971433 140058691233600 base_trainer.py:769] Step: 788 Lr 0.0102905 Loss scale 2048
I0321 13:32:44.971671 140058691233600 base_trainer.py:770] Train Step: 788/1000 / time=0.300 sec
I0321 13:32:44.971757 140058691233600 base_trainer.py:771] Perf 108046.24 samples/s
I0321 13:32:45.257170 140058691233600 base_trainer.py:769] Step: 789 Lr 0.010249 Loss scale 2048
I0321 13:32:45.257532 140058691233600 base_trainer.py:770] Train Step: 789/1000 / time=0.282 sec
I0321 13:32:45.257670 140058691233600 base_trainer.py:771] Perf 114748.33 samples/s
I0321 13:32:45.557247 140058691233600 base_trainer.py:769] Step: 790 Lr 0.0102075 Loss scale 2048
I0321 13:32:45.557685 140058691233600 base_trainer.py:770] Train Step: 790/1000 / time=0.296 sec
I0321 13:32:45.558068 140058691233600 base_trainer.py:771] Perf 109131.67 samples/s
I0321 13:32:45.866500 140058691233600 base_trainer.py:769] Step: 791 Lr 0.010166 Loss scale 2048
I0321 13:32:45.866724 140058691233600 base_trainer.py:770] Train Step: 791/1000 / time=0.306 sec
I0321 13:32:45.866803 140058691233600 base_trainer.py:771] Perf 105838.89 samples/s
I0321 13:32:46.173118 140058691233600 base_trainer.py:769] Step: 792 Lr 0.0101245 Loss scale 2048
I0321 13:32:46.173341 140058691233600 base_trainer.py:770] Train Step: 792/1000 / time=0.304 sec
I0321 13:32:46.173424 140058691233600 base_trainer.py:771] Perf 106872.03 samples/s
I0321 13:32:46.483693 140058691233600 base_trainer.py:769] Step: 793 Lr 0.010083 Loss scale 2048
I0321 13:32:46.483903 140058691233600 base_trainer.py:770] Train Step: 793/1000 / time=0.308 sec
I0321 13:32:46.483982 140058691233600 base_trainer.py:771] Perf 105455.97 samples/s
I0321 13:32:46.776170 140058691233600 base_trainer.py:769] Step: 794 Lr 0.0100415 Loss scale 2048
I0321 13:32:46.776402 140058691233600 base_trainer.py:770] Train Step: 794/1000 / time=0.290 sec
I0321 13:32:46.776483 140058691233600 base_trainer.py:771] Perf 112087.43 samples/s
I0321 13:32:47.073604 140058691233600 base_trainer.py:769] Step: 795 Lr 0.01 Loss scale 2048
I0321 13:32:47.073816 140058691233600 base_trainer.py:770] Train Step: 795/1000 / time=0.295 sec
I0321 13:32:47.073900 140058691233600 base_trainer.py:771] Perf 110157.44 samples/s
I0321 13:32:47.369610 140058691233600 base_trainer.py:769] Step: 796 Lr 0.00995851 Loss scale 2048
I0321 13:32:47.369829 140058691233600 base_trainer.py:770] Train Step: 796/1000 / time=0.293 sec
I0321 13:32:47.369911 140058691233600 base_trainer.py:771] Perf 110726.08 samples/s
I0321 13:32:47.683176 140058691233600 base_trainer.py:769] Step: 797 Lr 0.00991701 Loss scale 2048
I0321 13:32:47.683393 140058691233600 base_trainer.py:770] Train Step: 797/1000 / time=0.311 sec
I0321 13:32:47.683478 140058691233600 base_trainer.py:771] Perf 104471.35 samples/s
I0321 13:32:47.986449 140058691233600 base_trainer.py:769] Step: 798 Lr 0.00987552 Loss scale 2048
I0321 13:32:47.986671 140058691233600 base_trainer.py:770] Train Step: 798/1000 / time=0.300 sec
I0321 13:32:47.986755 140058691233600 base_trainer.py:771] Perf 108083.33 samples/s
I0321 13:32:48.287033 140058691233600 base_trainer.py:769] Step: 799 Lr 0.00983402 Loss scale 2048
I0321 13:32:48.287247 140058691233600 base_trainer.py:770] Train Step: 799/1000 / time=0.298 sec
I0321 13:32:48.287323 140058691233600 base_trainer.py:771] Perf 108965.89 samples/s
I0321 13:32:48.589455 140058691233600 base_trainer.py:769] Step: 800 Lr 0.00979253 Loss scale 2048
I0321 13:32:48.589672 140058691233600 base_trainer.py:770] Train Step: 800/1000 / time=0.300 sec
I0321 13:32:48.589754 140058691233600 base_trainer.py:771] Perf 108392.06 samples/s
I0321 13:32:48.885119 140058691233600 base_trainer.py:769] Step: 801 Lr 0.00975104 Loss scale 2048
I0321 13:32:48.885336 140058691233600 base_trainer.py:770] Train Step: 801/1000 / time=0.293 sec
I0321 13:32:48.885419 140058691233600 base_trainer.py:771] Perf 110838.08 samples/s
I0321 13:32:49.182400 140058691233600 base_trainer.py:769] Step: 802 Lr 0.00970954 Loss scale 2048
I0321 13:32:49.182622 140058691233600 base_trainer.py:770] Train Step: 802/1000 / time=0.294 sec
I0321 13:32:49.182711 140058691233600 base_trainer.py:771] Perf 110226.83 samples/s
I0321 13:32:49.485681 140058691233600 base_trainer.py:769] Step: 803 Lr 0.00966805 Loss scale 2048
I0321 13:32:49.485905 140058691233600 base_trainer.py:770] Train Step: 803/1000 / time=0.301 sec
I0321 13:32:49.485983 140058691233600 base_trainer.py:771] Perf 107981.38 samples/s
I0321 13:32:49.783189 140058691233600 base_trainer.py:769] Step: 804 Lr 0.00962656 Loss scale 2048
I0321 13:32:49.783421 140058691233600 base_trainer.py:770] Train Step: 804/1000 / time=0.295 sec
I0321 13:32:49.783503 140058691233600 base_trainer.py:771] Perf 110233.53 samples/s
I0321 13:32:50.086667 140058691233600 base_trainer.py:769] Step: 805 Lr 0.00958506 Loss scale 2048
I0321 13:32:50.086901 140058691233600 base_trainer.py:770] Train Step: 805/1000 / time=0.300 sec
I0321 13:32:50.086985 140058691233600 base_trainer.py:771] Perf 107988.40 samples/s
I0321 13:32:50.379761 140058691233600 base_trainer.py:769] Step: 806 Lr 0.00954357 Loss scale 2048
I0321 13:32:50.379991 140058691233600 base_trainer.py:770] Train Step: 806/1000 / time=0.290 sec
I0321 13:32:50.380078 140058691233600 base_trainer.py:771] Perf 111782.39 samples/s
I0321 13:32:50.681940 140058691233600 base_trainer.py:769] Step: 807 Lr 0.00950207 Loss scale 2048
I0321 13:32:50.682150 140058691233600 base_trainer.py:770] Train Step: 807/1000 / time=0.299 sec
I0321 13:32:50.682225 140058691233600 base_trainer.py:771] Perf 108358.58 samples/s
I0321 13:32:50.989730 140058691233600 base_trainer.py:769] Step: 808 Lr 0.00946058 Loss scale 2048
I0321 13:32:50.989946 140058691233600 base_trainer.py:770] Train Step: 808/1000 / time=0.305 sec
I0321 13:32:50.990026 140058691233600 base_trainer.py:771] Perf 106442.28 samples/s
I0321 13:32:51.284810 140058691233600 base_trainer.py:769] Step: 809 Lr 0.00941909 Loss scale 2048
I0321 13:32:51.285030 140058691233600 base_trainer.py:770] Train Step: 809/1000 / time=0.292 sec
I0321 13:32:51.285110 140058691233600 base_trainer.py:771] Perf 111147.32 samples/s
I0321 13:32:51.599983 140058691233600 base_trainer.py:769] Step: 810 Lr 0.00937759 Loss scale 2048
I0321 13:32:51.600190 140058691233600 base_trainer.py:770] Train Step: 810/1000 / time=0.312 sec
I0321 13:32:51.600273 140058691233600 base_trainer.py:771] Perf 103912.52 samples/s
I0321 13:32:51.923100 140058691233600 base_trainer.py:769] Step: 811 Lr 0.0093361 Loss scale 2048
I0321 13:32:51.923329 140058691233600 base_trainer.py:770] Train Step: 811/1000 / time=0.320 sec
I0321 13:32:51.923413 140058691233600 base_trainer.py:771] Perf 101473.92 samples/s
I0321 13:32:52.224749 140058691233600 base_trainer.py:769] Step: 812 Lr 0.0092946 Loss scale 2048
I0321 13:32:52.224978 140058691233600 base_trainer.py:770] Train Step: 812/1000 / time=0.298 sec
I0321 13:32:52.225071 140058691233600 base_trainer.py:771] Perf 108725.39 samples/s
I0321 13:32:52.523189 140058691233600 base_trainer.py:769] Step: 813 Lr 0.00925311 Loss scale 2048
I0321 13:32:52.523412 140058691233600 base_trainer.py:770] Train Step: 813/1000 / time=0.295 sec
I0321 13:32:52.523496 140058691233600 base_trainer.py:771] Perf 109704.71 samples/s
I0321 13:32:52.831144 140058691233600 base_trainer.py:769] Step: 814 Lr 0.00921162 Loss scale 2048
I0321 13:32:52.831372 140058691233600 base_trainer.py:770] Train Step: 814/1000 / time=0.305 sec
I0321 13:32:52.831470 140058691233600 base_trainer.py:771] Perf 106471.78 samples/s
I0321 13:32:53.113888 140058691233600 base_trainer.py:769] Step: 815 Lr 0.00917013 Loss scale 2048
I0321 13:32:53.114116 140058691233600 base_trainer.py:770] Train Step: 815/1000 / time=0.280 sec
I0321 13:32:53.114199 140058691233600 base_trainer.py:771] Perf 115834.68 samples/s
I0321 13:32:53.415339 140058691233600 base_trainer.py:769] Step: 816 Lr 0.00912863 Loss scale 2048
I0321 13:32:53.415547 140058691233600 base_trainer.py:770] Train Step: 816/1000 / time=0.299 sec
I0321 13:32:53.415624 140058691233600 base_trainer.py:771] Perf 108629.66 samples/s
I0321 13:32:53.724298 140058691233600 base_trainer.py:769] Step: 817 Lr 0.00908714 Loss scale 2048
I0321 13:32:53.724509 140058691233600 base_trainer.py:770] Train Step: 817/1000 / time=0.306 sec
I0321 13:32:53.724584 140058691233600 base_trainer.py:771] Perf 106071.47 samples/s
I0321 13:32:54.029368 140058691233600 base_trainer.py:769] Step: 818 Lr 0.00904564 Loss scale 2048
I0321 13:32:54.029624 140058691233600 base_trainer.py:770] Train Step: 818/1000 / time=0.302 sec
I0321 13:32:54.029740 140058691233600 base_trainer.py:771] Perf 107571.81 samples/s
I0321 13:32:54.335032 140058691233600 base_trainer.py:769] Step: 819 Lr 0.00900415 Loss scale 2048
I0321 13:32:54.335281 140058691233600 base_trainer.py:770] Train Step: 819/1000 / time=0.302 sec
I0321 13:32:54.335387 140058691233600 base_trainer.py:771] Perf 107193.73 samples/s
I0321 13:32:54.635080 140058691233600 base_trainer.py:769] Step: 820 Lr 0.00896266 Loss scale 2048
I0321 13:32:54.635301 140058691233600 base_trainer.py:770] Train Step: 820/1000 / time=0.297 sec
I0321 13:32:54.635387 140058691233600 base_trainer.py:771] Perf 109113.78 samples/s
I0321 13:32:54.934143 140058691233600 base_trainer.py:769] Step: 821 Lr 0.00892116 Loss scale 2048
I0321 13:32:54.934362 140058691233600 base_trainer.py:770] Train Step: 821/1000 / time=0.296 sec
I0321 13:32:54.934441 140058691233600 base_trainer.py:771] Perf 109572.84 samples/s
I0321 13:32:55.235146 140058691233600 base_trainer.py:769] Step: 822 Lr 0.00887967 Loss scale 2048
I0321 13:32:55.235353 140058691233600 base_trainer.py:770] Train Step: 822/1000 / time=0.298 sec
I0321 13:32:55.235429 140058691233600 base_trainer.py:771] Perf 108786.55 samples/s
I0321 13:32:55.530173 140058691233600 base_trainer.py:769] Step: 823 Lr 0.00883817 Loss scale 2048
I0321 13:32:55.530392 140058691233600 base_trainer.py:770] Train Step: 823/1000 / time=0.292 sec
I0321 13:32:55.530472 140058691233600 base_trainer.py:771] Perf 111168.73 samples/s
I0321 13:32:55.831760 140058691233600 base_trainer.py:769] Step: 824 Lr 0.00879668 Loss scale 2048
I0321 13:32:55.831984 140058691233600 base_trainer.py:770] Train Step: 824/1000 / time=0.299 sec
I0321 13:32:55.832063 140058691233600 base_trainer.py:771] Perf 108621.17 samples/s
I0321 13:32:56.144176 140058691233600 base_trainer.py:769] Step: 825 Lr 0.00875519 Loss scale 2048
I0321 13:32:56.144409 140058691233600 base_trainer.py:770] Train Step: 825/1000 / time=0.309 sec
I0321 13:32:56.144489 140058691233600 base_trainer.py:771] Perf 104963.75 samples/s
I0321 13:32:56.443754 140058691233600 base_trainer.py:769] Step: 826 Lr 0.00871369 Loss scale 2048
I0321 13:32:56.443970 140058691233600 base_trainer.py:770] Train Step: 826/1000 / time=0.296 sec
I0321 13:32:56.444048 140058691233600 base_trainer.py:771] Perf 109381.50 samples/s
I0321 13:32:56.746919 140058691233600 base_trainer.py:769] Step: 827 Lr 0.0086722 Loss scale 2048
I0321 13:32:56.747134 140058691233600 base_trainer.py:770] Train Step: 827/1000 / time=0.299 sec
I0321 13:32:56.747213 140058691233600 base_trainer.py:771] Perf 108348.42 samples/s
I0321 13:32:57.049365 140058691233600 base_trainer.py:769] Step: 828 Lr 0.00863071 Loss scale 2048
I0321 13:32:57.049619 140058691233600 base_trainer.py:770] Train Step: 828/1000 / time=0.299 sec
I0321 13:32:57.049732 140058691233600 base_trainer.py:771] Perf 108132.68 samples/s
I0321 13:32:57.347322 140058691233600 base_trainer.py:769] Step: 829 Lr 0.00858921 Loss scale 2048
I0321 13:32:57.347599 140058691233600 base_trainer.py:770] Train Step: 829/1000 / time=0.295 sec
I0321 13:32:57.347701 140058691233600 base_trainer.py:771] Perf 110001.55 samples/s
I0321 13:32:57.645876 140058691233600 base_trainer.py:769] Step: 830 Lr 0.00854772 Loss scale 2048
I0321 13:32:57.646097 140058691233600 base_trainer.py:770] Train Step: 830/1000 / time=0.295 sec
I0321 13:32:57.646176 140058691233600 base_trainer.py:771] Perf 109640.31 samples/s
I0321 13:32:57.948023 140058691233600 base_trainer.py:769] Step: 831 Lr 0.00850622 Loss scale 2048
I0321 13:32:57.948248 140058691233600 base_trainer.py:770] Train Step: 831/1000 / time=0.299 sec
I0321 13:32:57.948344 140058691233600 base_trainer.py:771] Perf 108422.21 samples/s
I0321 13:32:58.255421 140058691233600 base_trainer.py:769] Step: 832 Lr 0.00846473 Loss scale 2048
I0321 13:32:58.255642 140058691233600 base_trainer.py:770] Train Step: 832/1000 / time=0.304 sec
I0321 13:32:58.255726 140058691233600 base_trainer.py:771] Perf 106607.24 samples/s
I0321 13:32:58.561243 140058691233600 base_trainer.py:769] Step: 833 Lr 0.00842324 Loss scale 2048
I0321 13:32:58.561517 140058691233600 base_trainer.py:770] Train Step: 833/1000 / time=0.303 sec
I0321 13:32:58.561603 140058691233600 base_trainer.py:771] Perf 107256.37 samples/s
I0321 13:32:58.877209 140058691233600 base_trainer.py:769] Step: 834 Lr 0.00838174 Loss scale 2048
I0321 13:32:58.877437 140058691233600 base_trainer.py:770] Train Step: 834/1000 / time=0.313 sec
I0321 13:32:58.877518 140058691233600 base_trainer.py:771] Perf 103639.32 samples/s
I0321 13:32:59.178554 140058691233600 base_trainer.py:769] Step: 835 Lr 0.00834025 Loss scale 2048
I0321 13:32:59.178778 140058691233600 base_trainer.py:770] Train Step: 835/1000 / time=0.298 sec
I0321 13:32:59.178858 140058691233600 base_trainer.py:771] Perf 108709.46 samples/s
I0321 13:32:59.482423 140058691233600 base_trainer.py:769] Step: 836 Lr 0.00829876 Loss scale 2048
I0321 13:32:59.482642 140058691233600 base_trainer.py:770] Train Step: 836/1000 / time=0.301 sec
I0321 13:32:59.482728 140058691233600 base_trainer.py:771] Perf 107844.20 samples/s
I0321 13:32:59.800387 140058691233600 base_trainer.py:769] Step: 837 Lr 0.00825726 Loss scale 2048
I0321 13:32:59.800598 140058691233600 base_trainer.py:770] Train Step: 837/1000 / time=0.315 sec
I0321 13:32:59.800677 140058691233600 base_trainer.py:771] Perf 103021.87 samples/s
I0321 13:33:00.105643 140058691233600 base_trainer.py:769] Step: 838 Lr 0.00821577 Loss scale 2048
I0321 13:33:00.105892 140058691233600 base_trainer.py:770] Train Step: 838/1000 / time=0.302 sec
I0321 13:33:00.105983 140058691233600 base_trainer.py:771] Perf 107500.08 samples/s
I0321 13:33:00.428640 140058691233600 base_trainer.py:769] Step: 839 Lr 0.00817428 Loss scale 2048
I0321 13:33:00.428855 140058691233600 base_trainer.py:770] Train Step: 839/1000 / time=0.320 sec
I0321 13:33:00.428939 140058691233600 base_trainer.py:771] Perf 101326.05 samples/s
I0321 13:33:00.726304 140058691233600 base_trainer.py:769] Step: 840 Lr 0.00813278 Loss scale 2048
I0321 13:33:00.726510 140058691233600 base_trainer.py:770] Train Step: 840/1000 / time=0.295 sec
I0321 13:33:00.726588 140058691233600 base_trainer.py:771] Perf 110078.21 samples/s
I0321 13:33:01.028437 140058691233600 base_trainer.py:769] Step: 841 Lr 0.00809129 Loss scale 2048
I0321 13:33:01.028649 140058691233600 base_trainer.py:770] Train Step: 841/1000 / time=0.299 sec
I0321 13:33:01.028736 140058691233600 base_trainer.py:771] Perf 108483.31 samples/s
I0321 13:33:01.328499 140058691233600 base_trainer.py:769] Step: 842 Lr 0.00804979 Loss scale 2048
I0321 13:33:01.328720 140058691233600 base_trainer.py:770] Train Step: 842/1000 / time=0.297 sec
I0321 13:33:01.328799 140058691233600 base_trainer.py:771] Perf 109219.63 samples/s
I0321 13:33:01.643411 140058691233600 base_trainer.py:769] Step: 843 Lr 0.0080083 Loss scale 2048
I0321 13:33:01.643631 140058691233600 base_trainer.py:770] Train Step: 843/1000 / time=0.312 sec
I0321 13:33:01.643716 140058691233600 base_trainer.py:771] Perf 104039.74 samples/s
I0321 13:33:01.942962 140058691233600 base_trainer.py:769] Step: 844 Lr 0.0079668 Loss scale 2048
I0321 13:33:01.943171 140058691233600 base_trainer.py:770] Train Step: 844/1000 / time=0.297 sec
I0321 13:33:01.943247 140058691233600 base_trainer.py:771] Perf 109340.36 samples/s
I0321 13:33:02.246538 140058691233600 base_trainer.py:769] Step: 845 Lr 0.00792531 Loss scale 2048
I0321 13:33:02.246763 140058691233600 base_trainer.py:770] Train Step: 845/1000 / time=0.301 sec
I0321 13:33:02.246849 140058691233600 base_trainer.py:771] Perf 107998.97 samples/s
I0321 13:33:02.553620 140058691233600 base_trainer.py:769] Step: 846 Lr 0.00788382 Loss scale 2048
I0321 13:33:02.553848 140058691233600 base_trainer.py:770] Train Step: 846/1000 / time=0.304 sec
I0321 13:33:02.553934 140058691233600 base_trainer.py:771] Perf 106734.92 samples/s
I0321 13:33:02.854575 140058691233600 base_trainer.py:769] Step: 847 Lr 0.00784232 Loss scale 2048
I0321 13:33:02.854806 140058691233600 base_trainer.py:770] Train Step: 847/1000 / time=0.298 sec
I0321 13:33:02.854901 140058691233600 base_trainer.py:771] Perf 108939.10 samples/s
I0321 13:33:03.148539 140058691233600 base_trainer.py:769] Step: 848 Lr 0.00780083 Loss scale 2048
I0321 13:33:03.148758 140058691233600 base_trainer.py:770] Train Step: 848/1000 / time=0.291 sec
I0321 13:33:03.148840 140058691233600 base_trainer.py:771] Perf 111386.22 samples/s
I0321 13:33:03.439384 140058691233600 base_trainer.py:769] Step: 849 Lr 0.00775934 Loss scale 2048
I0321 13:33:03.439659 140058691233600 base_trainer.py:770] Train Step: 849/1000 / time=0.288 sec
I0321 13:33:03.439769 140058691233600 base_trainer.py:771] Perf 112806.22 samples/s
I0321 13:33:03.731826 140058691233600 base_trainer.py:769] Step: 850 Lr 0.00771784 Loss scale 2048
I0321 13:33:03.732087 140058691233600 base_trainer.py:770] Train Step: 850/1000 / time=0.289 sec
I0321 13:33:03.732205 140058691233600 base_trainer.py:771] Perf 112038.98 samples/s
I0321 13:33:04.036059 140058691233600 base_trainer.py:769] Step: 851 Lr 0.00767635 Loss scale 2048
I0321 13:33:04.036327 140058691233600 base_trainer.py:770] Train Step: 851/1000 / time=0.301 sec
I0321 13:33:04.036445 140058691233600 base_trainer.py:771] Perf 107700.71 samples/s
I0321 13:33:04.340096 140058691233600 base_trainer.py:769] Step: 852 Lr 0.00763485 Loss scale 2048
I0321 13:33:04.340328 140058691233600 base_trainer.py:770] Train Step: 852/1000 / time=0.301 sec
I0321 13:33:04.340414 140058691233600 base_trainer.py:771] Perf 107712.21 samples/s
I0321 13:33:04.640265 140058691233600 base_trainer.py:769] Step: 853 Lr 0.00759336 Loss scale 2048
I0321 13:33:04.640481 140058691233600 base_trainer.py:770] Train Step: 853/1000 / time=0.297 sec
I0321 13:33:04.640564 140058691233600 base_trainer.py:771] Perf 109144.50 samples/s
I0321 13:33:04.938330 140058691233600 base_trainer.py:769] Step: 854 Lr 0.00755187 Loss scale 2048
I0321 13:33:04.938546 140058691233600 base_trainer.py:770] Train Step: 854/1000 / time=0.295 sec
I0321 13:33:04.938627 140058691233600 base_trainer.py:771] Perf 109928.04 samples/s
I0321 13:33:05.240467 140058691233600 base_trainer.py:769] Step: 855 Lr 0.00751037 Loss scale 2048
I0321 13:33:05.240703 140058691233600 base_trainer.py:770] Train Step: 855/1000 / time=0.299 sec
I0321 13:33:05.240787 140058691233600 base_trainer.py:771] Perf 108426.75 samples/s
I0321 13:33:05.547379 140058691233600 base_trainer.py:769] Step: 856 Lr 0.00746888 Loss scale 2048
I0321 13:33:05.547592 140058691233600 base_trainer.py:770] Train Step: 856/1000 / time=0.304 sec
I0321 13:33:05.547666 140058691233600 base_trainer.py:771] Perf 106760.48 samples/s
I0321 13:33:05.858483 140058691233600 base_trainer.py:769] Step: 857 Lr 0.00742739 Loss scale 2048
I0321 13:33:05.858698 140058691233600 base_trainer.py:770] Train Step: 857/1000 / time=0.308 sec
I0321 13:33:05.858774 140058691233600 base_trainer.py:771] Perf 105430.94 samples/s
I0321 13:33:06.170877 140058691233600 base_trainer.py:769] Step: 858 Lr 0.00738589 Loss scale 2048
I0321 13:33:06.171104 140058691233600 base_trainer.py:770] Train Step: 858/1000 / time=0.310 sec
I0321 13:33:06.171187 140058691233600 base_trainer.py:771] Perf 104743.57 samples/s
I0321 13:33:06.465745 140058691233600 base_trainer.py:769] Step: 859 Lr 0.0073444 Loss scale 2048
I0321 13:33:06.465963 140058691233600 base_trainer.py:770] Train Step: 859/1000 / time=0.292 sec
I0321 13:33:06.466053 140058691233600 base_trainer.py:771] Perf 111238.05 samples/s
I0321 13:33:06.769721 140058691233600 base_trainer.py:769] Step: 860 Lr 0.0073029 Loss scale 2048
I0321 13:33:06.769936 140058691233600 base_trainer.py:770] Train Step: 860/1000 / time=0.301 sec
I0321 13:33:06.770014 140058691233600 base_trainer.py:771] Perf 107743.91 samples/s
I0321 13:33:07.057913 140058691233600 base_trainer.py:769] Step: 861 Lr 0.00726141 Loss scale 2048
I0321 13:33:07.058128 140058691233600 base_trainer.py:770] Train Step: 861/1000 / time=0.285 sec
I0321 13:33:07.058212 140058691233600 base_trainer.py:771] Perf 113759.58 samples/s
I0321 13:33:07.357395 140058691233600 base_trainer.py:769] Step: 862 Lr 0.00721992 Loss scale 2048
I0321 13:33:07.357611 140058691233600 base_trainer.py:770] Train Step: 862/1000 / time=0.296 sec
I0321 13:33:07.357696 140058691233600 base_trainer.py:771] Perf 109437.42 samples/s
I0321 13:33:07.663743 140058691233600 base_trainer.py:769] Step: 863 Lr 0.00717842 Loss scale 2048
I0321 13:33:07.663967 140058691233600 base_trainer.py:770] Train Step: 863/1000 / time=0.303 sec
I0321 13:33:07.664057 140058691233600 base_trainer.py:771] Perf 106951.31 samples/s
I0321 13:33:07.958925 140058691233600 base_trainer.py:769] Step: 864 Lr 0.00713693 Loss scale 2048
I0321 13:33:07.959157 140058691233600 base_trainer.py:770] Train Step: 864/1000 / time=0.292 sec
I0321 13:33:07.959236 140058691233600 base_trainer.py:771] Perf 111008.31 samples/s
I0321 13:33:08.255866 140058691233600 base_trainer.py:769] Step: 865 Lr 0.00709544 Loss scale 2048
I0321 13:33:08.256071 140058691233600 base_trainer.py:770] Train Step: 865/1000 / time=0.294 sec
I0321 13:33:08.256153 140058691233600 base_trainer.py:771] Perf 110275.44 samples/s
I0321 13:33:08.583047 140058691233600 base_trainer.py:769] Step: 866 Lr 0.00705394 Loss scale 2048
I0321 13:33:08.583255 140058691233600 base_trainer.py:770] Train Step: 866/1000 / time=0.324 sec
I0321 13:33:08.583333 140058691233600 base_trainer.py:771] Perf 100154.35 samples/s
I0321 13:33:08.879916 140058691233600 base_trainer.py:769] Step: 867 Lr 0.00701245 Loss scale 2048
I0321 13:33:08.880125 140058691233600 base_trainer.py:770] Train Step: 867/1000 / time=0.294 sec
I0321 13:33:08.880202 140058691233600 base_trainer.py:771] Perf 110381.60 samples/s
I0321 13:33:09.183043 140058691233600 base_trainer.py:769] Step: 868 Lr 0.00697095 Loss scale 2048
I0321 13:33:09.183266 140058691233600 base_trainer.py:770] Train Step: 868/1000 / time=0.300 sec
I0321 13:33:09.183350 140058691233600 base_trainer.py:771] Perf 108156.42 samples/s
I0321 13:33:09.481852 140058691233600 base_trainer.py:769] Step: 869 Lr 0.00692946 Loss scale 2048
I0321 13:33:09.482078 140058691233600 base_trainer.py:770] Train Step: 869/1000 / time=0.296 sec
I0321 13:33:09.482162 140058691233600 base_trainer.py:771] Perf 109670.98 samples/s
I0321 13:33:09.777105 140058691233600 base_trainer.py:769] Step: 870 Lr 0.00688797 Loss scale 2048
I0321 13:33:09.777327 140058691233600 base_trainer.py:770] Train Step: 870/1000 / time=0.292 sec
I0321 13:33:09.777414 140058691233600 base_trainer.py:771] Perf 110996.51 samples/s
I0321 13:33:10.072603 140058691233600 base_trainer.py:769] Step: 871 Lr 0.00684647 Loss scale 2048
I0321 13:33:10.072831 140058691233600 base_trainer.py:770] Train Step: 871/1000 / time=0.293 sec
I0321 13:33:10.072935 140058691233600 base_trainer.py:771] Perf 110894.90 samples/s
I0321 13:33:10.381132 140058691233600 base_trainer.py:769] Step: 872 Lr 0.00680498 Loss scale 2048
I0321 13:33:10.381356 140058691233600 base_trainer.py:770] Train Step: 872/1000 / time=0.306 sec
I0321 13:33:10.381452 140058691233600 base_trainer.py:771] Perf 106204.52 samples/s
I0321 13:33:10.678521 140058691233600 base_trainer.py:769] Step: 873 Lr 0.00676349 Loss scale 2048
I0321 13:33:10.678746 140058691233600 base_trainer.py:770] Train Step: 873/1000 / time=0.294 sec
I0321 13:33:10.678828 140058691233600 base_trainer.py:771] Perf 110238.91 samples/s
I0321 13:33:10.989025 140058691233600 base_trainer.py:769] Step: 874 Lr 0.00672199 Loss scale 2048
I0321 13:33:10.989245 140058691233600 base_trainer.py:770] Train Step: 874/1000 / time=0.308 sec
I0321 13:33:10.989329 140058691233600 base_trainer.py:771] Perf 105485.21 samples/s
I0321 13:33:11.300031 140058691233600 base_trainer.py:769] Step: 875 Lr 0.0066805 Loss scale 2048
I0321 13:33:11.300268 140058691233600 base_trainer.py:770] Train Step: 875/1000 / time=0.308 sec
I0321 13:33:11.300354 140058691233600 base_trainer.py:771] Perf 105366.39 samples/s
I0321 13:33:11.605678 140058691233600 base_trainer.py:769] Step: 876 Lr 0.00663901 Loss scale 2048
I0321 13:33:11.605917 140058691233600 base_trainer.py:770] Train Step: 876/1000 / time=0.303 sec
I0321 13:33:11.605999 140058691233600 base_trainer.py:771] Perf 107231.11 samples/s
I0321 13:33:11.904654 140058691233600 base_trainer.py:769] Step: 877 Lr 0.00659751 Loss scale 2048
I0321 13:33:11.904880 140058691233600 base_trainer.py:770] Train Step: 877/1000 / time=0.296 sec
I0321 13:33:11.904969 140058691233600 base_trainer.py:771] Perf 109603.95 samples/s
I0321 13:33:12.211717 140058691233600 base_trainer.py:769] Step: 878 Lr 0.00655602 Loss scale 2048
I0321 13:33:12.211952 140058691233600 base_trainer.py:770] Train Step: 878/1000 / time=0.304 sec
I0321 13:33:12.212040 140058691233600 base_trainer.py:771] Perf 106744.86 samples/s
I0321 13:33:12.523918 140058691233600 base_trainer.py:769] Step: 879 Lr 0.00651452 Loss scale 2048
I0321 13:33:12.524141 140058691233600 base_trainer.py:770] Train Step: 879/1000 / time=0.309 sec
I0321 13:33:12.524226 140058691233600 base_trainer.py:771] Perf 104914.18 samples/s
I0321 13:33:12.832686 140058691233600 base_trainer.py:769] Step: 880 Lr 0.00647303 Loss scale 2048
I0321 13:33:12.833145 140058691233600 base_trainer.py:770] Train Step: 880/1000 / time=0.305 sec
I0321 13:33:12.833338 140058691233600 base_trainer.py:771] Perf 106290.35 samples/s
I0321 13:33:13.143413 140058691233600 base_trainer.py:769] Step: 881 Lr 0.00643153 Loss scale 2048
I0321 13:33:13.143677 140058691233600 base_trainer.py:770] Train Step: 881/1000 / time=0.307 sec
I0321 13:33:13.143767 140058691233600 base_trainer.py:771] Perf 105455.67 samples/s
I0321 13:33:13.441162 140058691233600 base_trainer.py:769] Step: 882 Lr 0.00639004 Loss scale 2048
I0321 13:33:13.441398 140058691233600 base_trainer.py:770] Train Step: 882/1000 / time=0.295 sec
I0321 13:33:13.441484 140058691233600 base_trainer.py:771] Perf 109940.09 samples/s
I0321 13:33:13.732694 140058691233600 base_trainer.py:769] Step: 883 Lr 0.00634855 Loss scale 2048
I0321 13:33:13.732919 140058691233600 base_trainer.py:770] Train Step: 883/1000 / time=0.288 sec
I0321 13:33:13.732998 140058691233600 base_trainer.py:771] Perf 112423.06 samples/s
I0321 13:33:14.044327 140058691233600 base_trainer.py:769] Step: 884 Lr 0.00630705 Loss scale 2048
I0321 13:33:14.044560 140058691233600 base_trainer.py:770] Train Step: 884/1000 / time=0.309 sec
I0321 13:33:14.044650 140058691233600 base_trainer.py:771] Perf 105099.22 samples/s
I0321 13:33:14.349556 140058691233600 base_trainer.py:769] Step: 885 Lr 0.00626556 Loss scale 2048
I0321 13:33:14.349769 140058691233600 base_trainer.py:770] Train Step: 885/1000 / time=0.302 sec
I0321 13:33:14.349854 140058691233600 base_trainer.py:771] Perf 107324.60 samples/s
I0321 13:33:14.655141 140058691233600 base_trainer.py:769] Step: 886 Lr 0.00622407 Loss scale 2048
I0321 13:33:14.655349 140058691233600 base_trainer.py:770] Train Step: 886/1000 / time=0.303 sec
I0321 13:33:14.655427 140058691233600 base_trainer.py:771] Perf 107244.04 samples/s
I0321 13:33:14.960586 140058691233600 base_trainer.py:769] Step: 887 Lr 0.00618257 Loss scale 2048
I0321 13:33:14.960812 140058691233600 base_trainer.py:770] Train Step: 887/1000 / time=0.302 sec
I0321 13:33:14.960896 140058691233600 base_trainer.py:771] Perf 107292.05 samples/s
I0321 13:33:15.265893 140058691233600 base_trainer.py:769] Step: 888 Lr 0.00614108 Loss scale 2048
I0321 13:33:15.266106 140058691233600 base_trainer.py:770] Train Step: 888/1000 / time=0.302 sec
I0321 13:33:15.266184 140058691233600 base_trainer.py:771] Perf 107304.20 samples/s
I0321 13:33:15.568653 140058691233600 base_trainer.py:769] Step: 889 Lr 0.00609959 Loss scale 2048
I0321 13:33:15.568877 140058691233600 base_trainer.py:770] Train Step: 889/1000 / time=0.300 sec
I0321 13:33:15.568960 140058691233600 base_trainer.py:771] Perf 108240.09 samples/s
I0321 13:33:15.865592 140058691233600 base_trainer.py:769] Step: 890 Lr 0.00605809 Loss scale 2048
I0321 13:33:15.865812 140058691233600 base_trainer.py:770] Train Step: 890/1000 / time=0.294 sec
I0321 13:33:15.865893 140058691233600 base_trainer.py:771] Perf 110349.50 samples/s
I0321 13:33:16.165891 140058691233600 base_trainer.py:769] Step: 891 Lr 0.0060166 Loss scale 2048
I0321 13:33:16.166113 140058691233600 base_trainer.py:770] Train Step: 891/1000 / time=0.297 sec
I0321 13:33:16.166198 140058691233600 base_trainer.py:771] Perf 109138.56 samples/s
I0321 13:33:16.474542 140058691233600 base_trainer.py:769] Step: 892 Lr 0.0059751 Loss scale 2048
I0321 13:33:16.474779 140058691233600 base_trainer.py:770] Train Step: 892/1000 / time=0.305 sec
I0321 13:33:16.474870 140058691233600 base_trainer.py:771] Perf 106232.40 samples/s
I0321 13:33:16.791511 140058691233600 base_trainer.py:769] Step: 893 Lr 0.00593361 Loss scale 2048
I0321 13:33:16.791744 140058691233600 base_trainer.py:770] Train Step: 893/1000 / time=0.314 sec
I0321 13:33:16.791842 140058691233600 base_trainer.py:771] Perf 103381.10 samples/s
I0321 13:33:17.117554 140058691233600 base_trainer.py:769] Step: 894 Lr 0.00589212 Loss scale 2048
I0321 13:33:17.117774 140058691233600 base_trainer.py:770] Train Step: 894/1000 / time=0.323 sec
I0321 13:33:17.117856 140058691233600 base_trainer.py:771] Perf 100440.42 samples/s
I0321 13:33:17.418713 140058691233600 base_trainer.py:769] Step: 895 Lr 0.00585062 Loss scale 2048
I0321 13:33:17.418920 140058691233600 base_trainer.py:770] Train Step: 895/1000 / time=0.298 sec
I0321 13:33:17.418995 140058691233600 base_trainer.py:771] Perf 108730.01 samples/s
I0321 13:33:17.717613 140058691233600 base_trainer.py:769] Step: 896 Lr 0.00580913 Loss scale 2048
I0321 13:33:17.717828 140058691233600 base_trainer.py:770] Train Step: 896/1000 / time=0.296 sec
I0321 13:33:17.717905 140058691233600 base_trainer.py:771] Perf 109674.83 samples/s
I0321 13:33:18.014864 140058691233600 base_trainer.py:769] Step: 897 Lr 0.00576763 Loss scale 2048
I0321 13:33:18.015091 140058691233600 base_trainer.py:770] Train Step: 897/1000 / time=0.294 sec
I0321 13:33:18.015171 140058691233600 base_trainer.py:771] Perf 110282.87 samples/s
I0321 13:33:18.319276 140058691233600 base_trainer.py:769] Step: 898 Lr 0.00572614 Loss scale 2048
I0321 13:33:18.319504 140058691233600 base_trainer.py:770] Train Step: 898/1000 / time=0.302 sec
I0321 13:33:18.319576 140058691233600 base_trainer.py:771] Perf 107549.25 samples/s
I0321 13:33:18.618844 140058691233600 base_trainer.py:769] Step: 899 Lr 0.00568465 Loss scale 2048
I0321 13:33:18.619062 140058691233600 base_trainer.py:770] Train Step: 899/1000 / time=0.297 sec
I0321 13:33:18.619141 140058691233600 base_trainer.py:771] Perf 109454.37 samples/s
I0321 13:33:18.910680 140058691233600 base_trainer.py:769] Step: 900 Lr 0.00564315 Loss scale 2048
I0321 13:33:18.910908 140058691233600 base_trainer.py:770] Train Step: 900/1000 / time=0.289 sec
I0321 13:33:18.910995 140058691233600 base_trainer.py:771] Perf 112316.70 samples/s
I0321 13:33:19.211539 140058691233600 base_trainer.py:769] Step: 901 Lr 0.00560166 Loss scale 2048
I0321 13:33:19.211762 140058691233600 base_trainer.py:770] Train Step: 901/1000 / time=0.298 sec
I0321 13:33:19.211863 140058691233600 base_trainer.py:771] Perf 108960.73 samples/s
I0321 13:33:19.530889 140058691233600 base_trainer.py:769] Step: 902 Lr 0.00556017 Loss scale 2048
I0321 13:33:19.531110 140058691233600 base_trainer.py:770] Train Step: 902/1000 / time=0.316 sec
I0321 13:33:19.531191 140058691233600 base_trainer.py:771] Perf 102555.82 samples/s
I0321 13:33:19.831005 140058691233600 base_trainer.py:769] Step: 903 Lr 0.00551867 Loss scale 2048
I0321 13:33:19.831212 140058691233600 base_trainer.py:770] Train Step: 903/1000 / time=0.297 sec
I0321 13:33:19.831287 140058691233600 base_trainer.py:771] Perf 109143.17 samples/s
I0321 13:33:20.132666 140058691233600 base_trainer.py:769] Step: 904 Lr 0.00547718 Loss scale 2048
I0321 13:33:20.132886 140058691233600 base_trainer.py:770] Train Step: 904/1000 / time=0.299 sec
I0321 13:33:20.132970 140058691233600 base_trainer.py:771] Perf 108681.41 samples/s
I0321 13:33:20.435569 140058691233600 base_trainer.py:769] Step: 905 Lr 0.00543568 Loss scale 2048
I0321 13:33:20.435791 140058691233600 base_trainer.py:770] Train Step: 905/1000 / time=0.300 sec
I0321 13:33:20.435873 140058691233600 base_trainer.py:771] Perf 108151.86 samples/s
I0321 13:33:20.746845 140058691233600 base_trainer.py:769] Step: 906 Lr 0.00539419 Loss scale 2048
I0321 13:33:20.747075 140058691233600 base_trainer.py:770] Train Step: 906/1000 / time=0.308 sec
I0321 13:33:20.747159 140058691233600 base_trainer.py:771] Perf 105310.77 samples/s
I0321 13:33:21.049673 140058691233600 base_trainer.py:769] Step: 907 Lr 0.0053527 Loss scale 2048
I0321 13:33:21.049880 140058691233600 base_trainer.py:770] Train Step: 907/1000 / time=0.300 sec
I0321 13:33:21.049957 140058691233600 base_trainer.py:771] Perf 108159.99 samples/s
I0321 13:33:21.356928 140058691233600 base_trainer.py:769] Step: 908 Lr 0.0053112 Loss scale 2048
I0321 13:33:21.357150 140058691233600 base_trainer.py:770] Train Step: 908/1000 / time=0.304 sec
I0321 13:33:21.357234 140058691233600 base_trainer.py:771] Perf 106711.04 samples/s
I0321 13:33:21.641792 140058691233600 base_trainer.py:769] Step: 909 Lr 0.00526971 Loss scale 2048
I0321 13:33:21.642014 140058691233600 base_trainer.py:770] Train Step: 909/1000 / time=0.282 sec
I0321 13:33:21.642098 140058691233600 base_trainer.py:771] Perf 115006.74 samples/s
I0321 13:33:21.945461 140058691233600 base_trainer.py:769] Step: 910 Lr 0.00522822 Loss scale 2048
I0321 13:33:21.945680 140058691233600 base_trainer.py:770] Train Step: 910/1000 / time=0.301 sec
I0321 13:33:21.945764 140058691233600 base_trainer.py:771] Perf 107891.45 samples/s
I0321 13:33:22.245122 140058691233600 base_trainer.py:769] Step: 911 Lr 0.00518672 Loss scale 2048
I0321 13:33:22.245341 140058691233600 base_trainer.py:770] Train Step: 911/1000 / time=0.297 sec
I0321 13:33:22.245422 140058691233600 base_trainer.py:771] Perf 109369.07 samples/s
I0321 13:33:22.554518 140058691233600 base_trainer.py:769] Step: 912 Lr 0.00514523 Loss scale 2048
I0321 13:33:22.554736 140058691233600 base_trainer.py:770] Train Step: 912/1000 / time=0.306 sec
I0321 13:33:22.554816 140058691233600 base_trainer.py:771] Perf 105911.89 samples/s
I0321 13:33:22.856616 140058691233600 base_trainer.py:769] Step: 913 Lr 0.00510374 Loss scale 2048
I0321 13:33:22.856840 140058691233600 base_trainer.py:770] Train Step: 913/1000 / time=0.299 sec
I0321 13:33:22.856924 140058691233600 base_trainer.py:771] Perf 108457.06 samples/s
I0321 13:33:23.153655 140058691233600 base_trainer.py:769] Step: 914 Lr 0.00506224 Loss scale 2048
I0321 13:33:23.153876 140058691233600 base_trainer.py:770] Train Step: 914/1000 / time=0.294 sec
I0321 13:33:23.153949 140058691233600 base_trainer.py:771] Perf 110232.13 samples/s
I0321 13:33:23.456845 140058691233600 base_trainer.py:769] Step: 915 Lr 0.00502075 Loss scale 2048
I0321 13:33:23.457066 140058691233600 base_trainer.py:770] Train Step: 915/1000 / time=0.301 sec
I0321 13:33:23.457138 140058691233600 base_trainer.py:771] Perf 108075.82 samples/s
I0321 13:33:23.759648 140058691233600 base_trainer.py:769] Step: 916 Lr 0.00497925 Loss scale 2048
I0321 13:33:23.759875 140058691233600 base_trainer.py:770] Train Step: 916/1000 / time=0.300 sec
I0321 13:33:23.759957 140058691233600 base_trainer.py:771] Perf 108304.36 samples/s
I0321 13:33:24.062286 140058691233600 base_trainer.py:769] Step: 917 Lr 0.00493776 Loss scale 2048
I0321 13:33:24.062501 140058691233600 base_trainer.py:770] Train Step: 917/1000 / time=0.300 sec
I0321 13:33:24.062577 140058691233600 base_trainer.py:771] Perf 108244.32 samples/s
I0321 13:33:24.366348 140058691233600 base_trainer.py:769] Step: 918 Lr 0.00489626 Loss scale 2048
I0321 13:33:24.366573 140058691233600 base_trainer.py:770] Train Step: 918/1000 / time=0.301 sec
I0321 13:33:24.366646 140058691233600 base_trainer.py:771] Perf 107716.17 samples/s
I0321 13:33:24.666725 140058691233600 base_trainer.py:769] Step: 919 Lr 0.00485477 Loss scale 2048
I0321 13:33:24.667240 140058691233600 base_trainer.py:770] Train Step: 919/1000 / time=0.298 sec
I0321 13:33:24.667819 140058691233600 base_trainer.py:771] Perf 109115.64 samples/s
I0321 13:33:24.965623 140058691233600 base_trainer.py:769] Step: 920 Lr 0.00481328 Loss scale 2048
I0321 13:33:24.965858 140058691233600 base_trainer.py:770] Train Step: 920/1000 / time=0.295 sec
I0321 13:33:24.965941 140058691233600 base_trainer.py:771] Perf 109732.30 samples/s
I0321 13:33:25.289657 140058691233600 base_trainer.py:769] Step: 921 Lr 0.00477178 Loss scale 2048
I0321 13:33:25.289881 140058691233600 base_trainer.py:770] Train Step: 921/1000 / time=0.321 sec
I0321 13:33:25.289966 140058691233600 base_trainer.py:771] Perf 101148.44 samples/s
I0321 13:33:25.607116 140058691233600 base_trainer.py:769] Step: 922 Lr 0.00473029 Loss scale 2048
I0321 13:33:25.607333 140058691233600 base_trainer.py:770] Train Step: 922/1000 / time=0.315 sec
I0321 13:33:25.607420 140058691233600 base_trainer.py:771] Perf 103149.43 samples/s
I0321 13:33:25.906257 140058691233600 base_trainer.py:769] Step: 923 Lr 0.0046888 Loss scale 2048
I0321 13:33:25.906482 140058691233600 base_trainer.py:770] Train Step: 923/1000 / time=0.296 sec
I0321 13:33:25.906574 140058691233600 base_trainer.py:771] Perf 109579.07 samples/s
I0321 13:33:26.218661 140058691233600 base_trainer.py:769] Step: 924 Lr 0.0046473 Loss scale 2048
I0321 13:33:26.218872 140058691233600 base_trainer.py:770] Train Step: 924/1000 / time=0.310 sec
I0321 13:33:26.218947 140058691233600 base_trainer.py:771] Perf 104834.41 samples/s
I0321 13:33:26.524692 140058691233600 base_trainer.py:769] Step: 925 Lr 0.00460581 Loss scale 2048
I0321 13:33:26.524924 140058691233600 base_trainer.py:770] Train Step: 925/1000 / time=0.303 sec
I0321 13:33:26.525004 140058691233600 base_trainer.py:771] Perf 107141.85 samples/s
I0321 13:33:26.831934 140058691233600 base_trainer.py:769] Step: 926 Lr 0.00456432 Loss scale 2048
I0321 13:33:26.832162 140058691233600 base_trainer.py:770] Train Step: 926/1000 / time=0.304 sec
I0321 13:33:26.832246 140058691233600 base_trainer.py:771] Perf 106633.77 samples/s
I0321 13:33:27.131912 140058691233600 base_trainer.py:769] Step: 927 Lr 0.00452282 Loss scale 2048
I0321 13:33:27.132127 140058691233600 base_trainer.py:770] Train Step: 927/1000 / time=0.297 sec
I0321 13:33:27.132216 140058691233600 base_trainer.py:771] Perf 109231.95 samples/s
I0321 13:33:27.434240 140058691233600 base_trainer.py:769] Step: 928 Lr 0.00448133 Loss scale 2048
I0321 13:33:27.434459 140058691233600 base_trainer.py:770] Train Step: 928/1000 / time=0.299 sec
I0321 13:33:27.434542 140058691233600 base_trainer.py:771] Perf 108402.27 samples/s
I0321 13:33:27.732501 140058691233600 base_trainer.py:769] Step: 929 Lr 0.00443983 Loss scale 2048
I0321 13:33:27.732719 140058691233600 base_trainer.py:770] Train Step: 929/1000 / time=0.295 sec
I0321 13:33:27.732806 140058691233600 base_trainer.py:771] Perf 109876.91 samples/s
I0321 13:33:28.040923 140058691233600 base_trainer.py:769] Step: 930 Lr 0.00439834 Loss scale 2048
I0321 13:33:28.041273 140058691233600 base_trainer.py:770] Train Step: 930/1000 / time=0.305 sec
I0321 13:33:28.041438 140058691233600 base_trainer.py:771] Perf 106355.13 samples/s
I0321 13:33:28.340218 140058691233600 base_trainer.py:769] Step: 931 Lr 0.00435685 Loss scale 2048
I0321 13:33:28.340452 140058691233600 base_trainer.py:770] Train Step: 931/1000 / time=0.296 sec
I0321 13:33:28.340538 140058691233600 base_trainer.py:771] Perf 109376.43 samples/s
I0321 13:33:28.651998 140058691233600 base_trainer.py:769] Step: 932 Lr 0.00431535 Loss scale 2048
I0321 13:33:28.652215 140058691233600 base_trainer.py:770] Train Step: 932/1000 / time=0.309 sec
I0321 13:33:28.652310 140058691233600 base_trainer.py:771] Perf 105109.83 samples/s
I0321 13:33:28.960406 140058691233600 base_trainer.py:769] Step: 933 Lr 0.00427386 Loss scale 2048
I0321 13:33:28.960637 140058691233600 base_trainer.py:770] Train Step: 933/1000 / time=0.305 sec
I0321 13:33:28.960721 140058691233600 base_trainer.py:771] Perf 106226.55 samples/s
I0321 13:33:29.249571 140058691233600 base_trainer.py:769] Step: 934 Lr 0.00423236 Loss scale 2048
I0321 13:33:29.249784 140058691233600 base_trainer.py:770] Train Step: 934/1000 / time=0.286 sec
I0321 13:33:29.249862 140058691233600 base_trainer.py:771] Perf 113235.78 samples/s
I0321 13:33:29.551176 140058691233600 base_trainer.py:769] Step: 935 Lr 0.00419087 Loss scale 2048
I0321 13:33:29.551399 140058691233600 base_trainer.py:770] Train Step: 935/1000 / time=0.299 sec
I0321 13:33:29.551482 140058691233600 base_trainer.py:771] Perf 108734.48 samples/s
I0321 13:33:29.859612 140058691233600 base_trainer.py:769] Step: 936 Lr 0.00414938 Loss scale 2048
I0321 13:33:29.859837 140058691233600 base_trainer.py:770] Train Step: 936/1000 / time=0.305 sec
I0321 13:33:29.859920 140058691233600 base_trainer.py:771] Perf 106245.75 samples/s
I0321 13:33:30.153807 140058691233600 base_trainer.py:769] Step: 937 Lr 0.00410788 Loss scale 2048
I0321 13:33:30.154026 140058691233600 base_trainer.py:770] Train Step: 937/1000 / time=0.291 sec
I0321 13:33:30.154102 140058691233600 base_trainer.py:771] Perf 111316.94 samples/s
I0321 13:33:30.456076 140058691233600 base_trainer.py:769] Step: 938 Lr 0.00406639 Loss scale 2048
I0321 13:33:30.456309 140058691233600 base_trainer.py:770] Train Step: 938/1000 / time=0.299 sec
I0321 13:33:30.456393 140058691233600 base_trainer.py:771] Perf 108461.73 samples/s
I0321 13:33:30.762338 140058691233600 base_trainer.py:769] Step: 939 Lr 0.0040249 Loss scale 2048
I0321 13:33:30.762555 140058691233600 base_trainer.py:770] Train Step: 939/1000 / time=0.303 sec
I0321 13:33:30.762640 140058691233600 base_trainer.py:771] Perf 107032.38 samples/s
I0321 13:33:31.062505 140058691233600 base_trainer.py:769] Step: 940 Lr 0.0039834 Loss scale 2048
I0321 13:33:31.062717 140058691233600 base_trainer.py:770] Train Step: 940/1000 / time=0.297 sec
I0321 13:33:31.062806 140058691233600 base_trainer.py:771] Perf 109154.48 samples/s
I0321 13:33:31.360554 140058691233600 base_trainer.py:769] Step: 941 Lr 0.00394191 Loss scale 2048
I0321 13:33:31.360775 140058691233600 base_trainer.py:770] Train Step: 941/1000 / time=0.295 sec
I0321 13:33:31.360855 140058691233600 base_trainer.py:771] Perf 109836.10 samples/s
I0321 13:33:31.655284 140058691233600 base_trainer.py:769] Step: 942 Lr 0.00390041 Loss scale 2048
I0321 13:33:31.655492 140058691233600 base_trainer.py:770] Train Step: 942/1000 / time=0.292 sec
I0321 13:33:31.655568 140058691233600 base_trainer.py:771] Perf 111199.08 samples/s
I0321 13:33:31.955507 140058691233600 base_trainer.py:769] Step: 943 Lr 0.00385892 Loss scale 2048
I0321 13:33:31.955729 140058691233600 base_trainer.py:770] Train Step: 943/1000 / time=0.297 sec
I0321 13:33:31.955808 140058691233600 base_trainer.py:771] Perf 109227.60 samples/s
I0321 13:33:32.242563 140058691233600 base_trainer.py:769] Step: 944 Lr 0.00381743 Loss scale 2048
I0321 13:33:32.242777 140058691233600 base_trainer.py:770] Train Step: 944/1000 / time=0.284 sec
I0321 13:33:32.242854 140058691233600 base_trainer.py:771] Perf 114114.85 samples/s
I0321 13:33:32.551896 140058691233600 base_trainer.py:769] Step: 945 Lr 0.00377593 Loss scale 2048
I0321 13:33:32.552130 140058691233600 base_trainer.py:770] Train Step: 945/1000 / time=0.306 sec
I0321 13:33:32.552214 140058691233600 base_trainer.py:771] Perf 105960.30 samples/s
I0321 13:33:32.862845 140058691233600 base_trainer.py:769] Step: 946 Lr 0.00373444 Loss scale 2048
I0321 13:33:32.863051 140058691233600 base_trainer.py:770] Train Step: 946/1000 / time=0.308 sec
I0321 13:33:32.863126 140058691233600 base_trainer.py:771] Perf 105309.68 samples/s
I0321 13:33:33.171769 140058691233600 base_trainer.py:769] Step: 947 Lr 0.00369295 Loss scale 2048
I0321 13:33:33.171984 140058691233600 base_trainer.py:770] Train Step: 947/1000 / time=0.306 sec
I0321 13:33:33.172064 140058691233600 base_trainer.py:771] Perf 106092.71 samples/s
I0321 13:33:33.497173 140058691233600 base_trainer.py:769] Step: 948 Lr 0.00365145 Loss scale 2048
I0321 13:33:33.497398 140058691233600 base_trainer.py:770] Train Step: 948/1000 / time=0.322 sec
I0321 13:33:33.497483 140058691233600 base_trainer.py:771] Perf 100758.59 samples/s
I0321 13:33:33.791621 140058691233600 base_trainer.py:769] Step: 949 Lr 0.00360996 Loss scale 2048
I0321 13:33:33.791831 140058691233600 base_trainer.py:770] Train Step: 949/1000 / time=0.292 sec
I0321 13:33:33.791908 140058691233600 base_trainer.py:771] Perf 111196.56 samples/s
I0321 13:33:34.106985 140058691233600 base_trainer.py:769] Step: 950 Lr 0.00356847 Loss scale 2048
I0321 13:33:34.107205 140058691233600 base_trainer.py:770] Train Step: 950/1000 / time=0.312 sec
I0321 13:33:34.107290 140058691233600 base_trainer.py:771] Perf 103985.27 samples/s
I0321 13:33:34.399178 140058691233600 base_trainer.py:769] Step: 951 Lr 0.00352697 Loss scale 2048
I0321 13:33:34.399405 140058691233600 base_trainer.py:770] Train Step: 951/1000 / time=0.289 sec
I0321 13:33:34.399497 140058691233600 base_trainer.py:771] Perf 112140.94 samples/s
I0321 13:33:34.693458 140058691233600 base_trainer.py:769] Step: 952 Lr 0.00348548 Loss scale 2048
I0321 13:33:34.693672 140058691233600 base_trainer.py:770] Train Step: 952/1000 / time=0.292 sec
I0321 13:33:34.693751 140058691233600 base_trainer.py:771] Perf 111246.65 samples/s
I0321 13:33:34.997966 140058691233600 base_trainer.py:769] Step: 953 Lr 0.00344398 Loss scale 2048
I0321 13:33:34.998187 140058691233600 base_trainer.py:770] Train Step: 953/1000 / time=0.302 sec
I0321 13:33:34.998258 140058691233600 base_trainer.py:771] Perf 107618.84 samples/s
I0321 13:33:35.288245 140058691233600 base_trainer.py:769] Step: 954 Lr 0.00340249 Loss scale 2048
I0321 13:33:35.288464 140058691233600 base_trainer.py:770] Train Step: 954/1000 / time=0.288 sec
I0321 13:33:35.288541 140058691233600 base_trainer.py:771] Perf 112902.15 samples/s
I0321 13:33:35.589586 140058691233600 base_trainer.py:769] Step: 955 Lr 0.00336099 Loss scale 2048
I0321 13:33:35.589801 140058691233600 base_trainer.py:770] Train Step: 955/1000 / time=0.298 sec
I0321 13:33:35.589887 140058691233600 base_trainer.py:771] Perf 108812.63 samples/s
I0321 13:33:35.892570 140058691233600 base_trainer.py:769] Step: 956 Lr 0.0033195 Loss scale 2048
I0321 13:33:35.892788 140058691233600 base_trainer.py:770] Train Step: 956/1000 / time=0.300 sec
I0321 13:33:35.892870 140058691233600 base_trainer.py:771] Perf 108149.50 samples/s
I0321 13:33:36.196659 140058691233600 base_trainer.py:769] Step: 957 Lr 0.00327801 Loss scale 2048
I0321 13:33:36.196878 140058691233600 base_trainer.py:770] Train Step: 957/1000 / time=0.301 sec
I0321 13:33:36.196960 140058691233600 base_trainer.py:771] Perf 107790.37 samples/s
I0321 13:33:36.499120 140058691233600 base_trainer.py:769] Step: 958 Lr 0.00323651 Loss scale 2048
I0321 13:33:36.499343 140058691233600 base_trainer.py:770] Train Step: 958/1000 / time=0.300 sec
I0321 13:33:36.499425 140058691233600 base_trainer.py:771] Perf 108321.41 samples/s
I0321 13:33:36.796335 140058691233600 base_trainer.py:769] Step: 959 Lr 0.00319502 Loss scale 2048
I0321 13:33:36.796548 140058691233600 base_trainer.py:770] Train Step: 959/1000 / time=0.294 sec
I0321 13:33:36.796623 140058691233600 base_trainer.py:771] Perf 110227.06 samples/s
I0321 13:33:37.095698 140058691233600 base_trainer.py:769] Step: 960 Lr 0.00315353 Loss scale 2048
I0321 13:33:37.095913 140058691233600 base_trainer.py:770] Train Step: 960/1000 / time=0.297 sec
I0321 13:33:37.095998 140058691233600 base_trainer.py:771] Perf 109422.47 samples/s
I0321 13:33:37.406696 140058691233600 base_trainer.py:769] Step: 961 Lr 0.00311203 Loss scale 2048
I0321 13:33:37.406926 140058691233600 base_trainer.py:770] Train Step: 961/1000 / time=0.308 sec
I0321 13:33:37.407020 140058691233600 base_trainer.py:771] Perf 105503.49 samples/s
I0321 13:33:37.705530 140058691233600 base_trainer.py:769] Step: 962 Lr 0.00307054 Loss scale 2048
I0321 13:33:37.705749 140058691233600 base_trainer.py:770] Train Step: 962/1000 / time=0.296 sec
I0321 13:33:37.705830 140058691233600 base_trainer.py:771] Perf 109589.20 samples/s
I0321 13:33:38.014778 140058691233600 base_trainer.py:769] Step: 963 Lr 0.00302905 Loss scale 2048
I0321 13:33:38.015003 140058691233600 base_trainer.py:770] Train Step: 963/1000 / time=0.306 sec
I0321 13:33:38.015086 140058691233600 base_trainer.py:771] Perf 105932.04 samples/s
I0321 13:33:38.322231 140058691233600 base_trainer.py:769] Step: 964 Lr 0.00298755 Loss scale 2048
I0321 13:33:38.322463 140058691233600 base_trainer.py:770] Train Step: 964/1000 / time=0.304 sec
I0321 13:33:38.322553 140058691233600 base_trainer.py:771] Perf 106625.81 samples/s
I0321 13:33:38.630661 140058691233600 base_trainer.py:769] Step: 965 Lr 0.00294606 Loss scale 2048
I0321 13:33:38.630890 140058691233600 base_trainer.py:770] Train Step: 965/1000 / time=0.305 sec
I0321 13:33:38.630973 140058691233600 base_trainer.py:771] Perf 106222.65 samples/s
I0321 13:33:38.953099 140058691233600 base_trainer.py:769] Step: 966 Lr 0.00290456 Loss scale 2048
I0321 13:33:38.953326 140058691233600 base_trainer.py:770] Train Step: 966/1000 / time=0.319 sec
I0321 13:33:38.953413 140058691233600 base_trainer.py:771] Perf 101621.75 samples/s
I0321 13:33:39.253458 140058691233600 base_trainer.py:769] Step: 967 Lr 0.00286307 Loss scale 2048
I0321 13:33:39.253694 140058691233600 base_trainer.py:770] Train Step: 967/1000 / time=0.297 sec
I0321 13:33:39.253788 140058691233600 base_trainer.py:771] Perf 109180.07 samples/s
I0321 13:33:39.577095 140058691233600 base_trainer.py:769] Step: 968 Lr 0.00282158 Loss scale 2048
I0321 13:33:39.577310 140058691233600 base_trainer.py:770] Train Step: 968/1000 / time=0.321 sec
I0321 13:33:39.577390 140058691233600 base_trainer.py:771] Perf 101127.94 samples/s
I0321 13:33:39.868120 140058691233600 base_trainer.py:769] Step: 969 Lr 0.00278008 Loss scale 2048
I0321 13:33:39.868353 140058691233600 base_trainer.py:770] Train Step: 969/1000 / time=0.288 sec
I0321 13:33:39.868432 140058691233600 base_trainer.py:771] Perf 112690.02 samples/s
I0321 13:33:40.162753 140058691233600 base_trainer.py:769] Step: 970 Lr 0.00273859 Loss scale 2048
I0321 13:33:40.162976 140058691233600 base_trainer.py:770] Train Step: 970/1000 / time=0.292 sec
I0321 13:33:40.163064 140058691233600 base_trainer.py:771] Perf 111195.08 samples/s
I0321 13:33:40.465736 140058691233600 base_trainer.py:769] Step: 971 Lr 0.0026971 Loss scale 2048
I0321 13:33:40.465955 140058691233600 base_trainer.py:770] Train Step: 971/1000 / time=0.300 sec
I0321 13:33:40.466037 140058691233600 base_trainer.py:771] Perf 108142.96 samples/s
I0321 13:33:40.767464 140058691233600 base_trainer.py:769] Step: 972 Lr 0.0026556 Loss scale 2048
I0321 13:33:40.767679 140058691233600 base_trainer.py:770] Train Step: 972/1000 / time=0.299 sec
I0321 13:33:40.767758 140058691233600 base_trainer.py:771] Perf 108549.76 samples/s
I0321 13:33:41.071805 140058691233600 base_trainer.py:769] Step: 973 Lr 0.00261411 Loss scale 2048
I0321 13:33:41.072020 140058691233600 base_trainer.py:770] Train Step: 973/1000 / time=0.301 sec
I0321 13:33:41.072103 140058691233600 base_trainer.py:771] Perf 107717.23 samples/s
I0321 13:33:41.367097 140058691233600 base_trainer.py:769] Step: 974 Lr 0.00257261 Loss scale 2048
I0321 13:33:41.367305 140058691233600 base_trainer.py:770] Train Step: 974/1000 / time=0.293 sec
I0321 13:33:41.367379 140058691233600 base_trainer.py:771] Perf 110899.77 samples/s
I0321 13:33:41.677539 140058691233600 base_trainer.py:769] Step: 975 Lr 0.00253112 Loss scale 2048
I0321 13:33:41.677762 140058691233600 base_trainer.py:770] Train Step: 975/1000 / time=0.308 sec
I0321 13:33:41.677849 140058691233600 base_trainer.py:771] Perf 105616.75 samples/s
I0321 13:33:41.991678 140058691233600 base_trainer.py:769] Step: 976 Lr 0.00248963 Loss scale 2048
I0321 13:33:41.991900 140058691233600 base_trainer.py:770] Train Step: 976/1000 / time=0.311 sec
I0321 13:33:41.991983 140058691233600 base_trainer.py:771] Perf 104328.86 samples/s
I0321 13:33:42.291522 140058691233600 base_trainer.py:769] Step: 977 Lr 0.00244813 Loss scale 2048
I0321 13:33:42.291733 140058691233600 base_trainer.py:770] Train Step: 977/1000 / time=0.297 sec
I0321 13:33:42.291808 140058691233600 base_trainer.py:771] Perf 109217.81 samples/s
I0321 13:33:42.601613 140058691233600 base_trainer.py:769] Step: 978 Lr 0.00240664 Loss scale 2048
I0321 13:33:42.601823 140058691233600 base_trainer.py:770] Train Step: 978/1000 / time=0.307 sec
I0321 13:33:42.601899 140058691233600 base_trainer.py:771] Perf 105666.25 samples/s
I0321 13:33:42.897054 140058691233600 base_trainer.py:769] Step: 979 Lr 0.00236514 Loss scale 2048
I0321 13:33:42.897271 140058691233600 base_trainer.py:770] Train Step: 979/1000 / time=0.293 sec
I0321 13:33:42.897350 140058691233600 base_trainer.py:771] Perf 110982.43 samples/s
I0321 13:33:43.204240 140058691233600 base_trainer.py:769] Step: 980 Lr 0.00232365 Loss scale 2048
I0321 13:33:43.204478 140058691233600 base_trainer.py:770] Train Step: 980/1000 / time=0.304 sec
I0321 13:33:43.204562 140058691233600 base_trainer.py:771] Perf 106657.99 samples/s
I0321 13:33:43.507011 140058691233600 base_trainer.py:769] Step: 981 Lr 0.00228216 Loss scale 2048
I0321 13:33:43.507265 140058691233600 base_trainer.py:770] Train Step: 981/1000 / time=0.300 sec
I0321 13:33:43.507362 140058691233600 base_trainer.py:771] Perf 108286.99 samples/s
I0321 13:33:43.810590 140058691233600 base_trainer.py:769] Step: 982 Lr 0.00224066 Loss scale 2048
I0321 13:33:43.810813 140058691233600 base_trainer.py:770] Train Step: 982/1000 / time=0.301 sec
I0321 13:33:43.810908 140058691233600 base_trainer.py:771] Perf 107891.82 samples/s
I0321 13:33:44.111800 140058691233600 base_trainer.py:769] Step: 983 Lr 0.00219917 Loss scale 2048
I0321 13:33:44.112056 140058691233600 base_trainer.py:770] Train Step: 983/1000 / time=0.298 sec
I0321 13:33:44.112168 140058691233600 base_trainer.py:771] Perf 108886.41 samples/s
I0321 13:33:44.402132 140058691233600 base_trainer.py:769] Step: 984 Lr 0.00215768 Loss scale 2048
I0321 13:33:44.402374 140058691233600 base_trainer.py:770] Train Step: 984/1000 / time=0.287 sec
I0321 13:33:44.402486 140058691233600 base_trainer.py:771] Perf 112860.23 samples/s
I0321 13:33:44.709957 140058691233600 base_trainer.py:769] Step: 985 Lr 0.00211618 Loss scale 2048
I0321 13:33:44.710179 140058691233600 base_trainer.py:770] Train Step: 985/1000 / time=0.305 sec
I0321 13:33:44.710251 140058691233600 base_trainer.py:771] Perf 106289.64 samples/s
I0321 13:33:44.999431 140058691233600 base_trainer.py:769] Step: 986 Lr 0.00207469 Loss scale 2048
I0321 13:33:44.999642 140058691233600 base_trainer.py:770] Train Step: 986/1000 / time=0.287 sec
I0321 13:33:44.999717 140058691233600 base_trainer.py:771] Perf 113225.02 samples/s
I0321 13:33:45.302076 140058691233600 base_trainer.py:769] Step: 987 Lr 0.0020332 Loss scale 2048
I0321 13:33:45.302299 140058691233600 base_trainer.py:770] Train Step: 987/1000 / time=0.300 sec
I0321 13:33:45.302383 140058691233600 base_trainer.py:771] Perf 108363.62 samples/s
I0321 13:33:45.602669 140058691233600 base_trainer.py:769] Step: 988 Lr 0.0019917 Loss scale 2048
I0321 13:33:45.602893 140058691233600 base_trainer.py:770] Train Step: 988/1000 / time=0.298 sec
I0321 13:33:45.602977 140058691233600 base_trainer.py:771] Perf 109003.00 samples/s
I0321 13:33:45.904713 140058691233600 base_trainer.py:769] Step: 989 Lr 0.00195021 Loss scale 2048
I0321 13:33:45.904940 140058691233600 base_trainer.py:770] Train Step: 989/1000 / time=0.299 sec
I0321 13:33:45.905030 140058691233600 base_trainer.py:771] Perf 108462.77 samples/s
I0321 13:33:46.202381 140058691233600 base_trainer.py:769] Step: 990 Lr 0.00190871 Loss scale 2048
I0321 13:33:46.202595 140058691233600 base_trainer.py:770] Train Step: 990/1000 / time=0.295 sec
I0321 13:33:46.202670 140058691233600 base_trainer.py:771] Perf 110045.95 samples/s
I0321 13:33:46.495808 140058691233600 base_trainer.py:769] Step: 991 Lr 0.00186722 Loss scale 2048
I0321 13:33:46.496019 140058691233600 base_trainer.py:770] Train Step: 991/1000 / time=0.291 sec
I0321 13:33:46.496109 140058691233600 base_trainer.py:771] Perf 111660.73 samples/s
I0321 13:33:46.806062 140058691233600 base_trainer.py:769] Step: 992 Lr 0.00182573 Loss scale 2048
I0321 13:33:46.806286 140058691233600 base_trainer.py:770] Train Step: 992/1000 / time=0.307 sec
I0321 13:33:46.806386 140058691233600 base_trainer.py:771] Perf 105736.47 samples/s
I0321 13:33:47.106331 140058691233600 base_trainer.py:769] Step: 993 Lr 0.00178423 Loss scale 2048
I0321 13:33:47.106559 140058691233600 base_trainer.py:770] Train Step: 993/1000 / time=0.297 sec
I0321 13:33:47.106642 140058691233600 base_trainer.py:771] Perf 109081.77 samples/s
I0321 13:33:47.405421 140058691233600 base_trainer.py:769] Step: 994 Lr 0.00174274 Loss scale 2048
I0321 13:33:47.405631 140058691233600 base_trainer.py:770] Train Step: 994/1000 / time=0.296 sec
I0321 13:33:47.405707 140058691233600 base_trainer.py:771] Perf 109496.07 samples/s
I0321 13:33:47.707695 140058691233600 base_trainer.py:769] Step: 995 Lr 0.00170125 Loss scale 2048
I0321 13:33:47.707928 140058691233600 base_trainer.py:770] Train Step: 995/1000 / time=0.299 sec
I0321 13:33:47.708017 140058691233600 base_trainer.py:771] Perf 108486.05 samples/s
I0321 13:33:48.004682 140058691233600 base_trainer.py:769] Step: 996 Lr 0.00165975 Loss scale 2048
I0321 13:33:48.004891 140058691233600 base_trainer.py:770] Train Step: 996/1000 / time=0.294 sec
I0321 13:33:48.004968 140058691233600 base_trainer.py:771] Perf 110319.91 samples/s
I0321 13:33:48.313936 140058691233600 base_trainer.py:769] Step: 997 Lr 0.00161826 Loss scale 2048
I0321 13:33:48.314157 140058691233600 base_trainer.py:770] Train Step: 997/1000 / time=0.306 sec
I0321 13:33:48.314237 140058691233600 base_trainer.py:771] Perf 105962.90 samples/s
I0321 13:33:48.613874 140058691233600 base_trainer.py:769] Step: 998 Lr 0.00157676 Loss scale 2048
I0321 13:33:48.614085 140058691233600 base_trainer.py:770] Train Step: 998/1000 / time=0.297 sec
I0321 13:33:48.614161 140058691233600 base_trainer.py:771] Perf 109185.49 samples/s
I0321 13:33:48.920961 140058691233600 base_trainer.py:769] Step: 999 Lr 0.00153527 Loss scale 2048
I0321 13:33:48.921177 140058691233600 base_trainer.py:770] Train Step: 999/1000 / time=0.304 sec
I0321 13:33:48.921252 140058691233600 base_trainer.py:771] Perf 106717.36 samples/s
2023-03-21 13:33:49.217413: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2023-03-21 13:33:49.217451: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2023-03-21 13:33:49.217876: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
I0321 13:33:49.989931 140058691233600 base_trainer.py:754] Saved checkpoint to /results/tf_training_amazon_books_2014_dien_fp16_gbs32768_230321132836/ckpt-1
I0321 13:33:49.994955 140058691233600 base_trainer.py:769] Step: 1000 Lr 0.00149378 Loss scale 2048
I0321 13:33:49.995121 140058691233600 base_trainer.py:770] Train Step: 1000/1000 / time=0.293 sec
I0321 13:33:49.995214 140058691233600 base_trainer.py:771] Perf 30580.50 samples/s
I0321 13:33:50.728405 140058691233600 base_trainer.py:101] Saving model as TF checkpoint: /results/tf_training_amazon_books_2014_dien_fp16_gbs32768_230321132836/ctl_step_1000.ckpt-2
I0321 13:33:50.734570 140058691233600 base_trainer.py:127] Training Summary: 
{'total_training_steps': 1000, 'train_loss': nan, 'last_logits_auc_accumulator': 0.9435051083564758}
I0321 13:33:50.735569 140058691233600 base_trainer.py:830] -----------------------------
I0321 13:33:50.735703 140058691233600 base_trainer.py:831]   Batch size = 8192
I0321 13:33:50.735782 140058691233600 base_trainer.py:832]   Num steps = 1000
I0321 13:33:50.735861 140058691233600 base_trainer.py:833]   LR = 0.01
I0321 13:33:50.735948 140058691233600 base_trainer.py:835] Multi-GPU training with TF Horovod
I0321 13:33:50.736045 140058691233600 base_trainer.py:836] hvd.size() = 4
I0321 13:33:50.736120 140058691233600 base_trainer.py:837] Total Training Time = 305.27 for Examples = 32768000
I0321 13:33:50.736190 140058691233600 base_trainer.py:838] Throughput Average (examples/sec) with overhead = 126911.57
I0321 13:33:50.736545 140058691233600 base_trainer.py:840] Throughput Average (examples/sec) = 253506.39
I0321 13:33:50.736619 140058691233600 base_trainer.py:841] -----------------------------
DLL 2023-03-21 13:33:50.736684 -  throughput_train : 253506.387 sequences/s
DLL 2023-03-21 13:33:50.736789 -  total_loss : nan 
2023-03-21 13:33:50.736942: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_util.py:436: RuntimeWarning: overflow encountered in cast
  nparray = values.astype(dtype.as_numpy_dtype)
/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_util.py:436: RuntimeWarning: overflow encountered in cast
  nparray = values.astype(dtype.as_numpy_dtype)
/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_util.py:436: RuntimeWarning: overflow encountered in cast
  nparray = values.astype(dtype.as_numpy_dtype)
